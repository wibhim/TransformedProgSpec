{
  "metadata": {
    "summary": {
      "total_programs": 50,
      "api_requests": 50,
      "cached_results": 0,
      "errors": 0,
      "success_rate": "100.0%"
    },
    "timing": {
      "total_duration_seconds": 708.633,
      "total_duration_formatted": "11m 48.6s",
      "average_per_request_seconds": 14.173
    },
    "tokens": {
      "total": 73703,
      "input": 29346,
      "output": 44357,
      "average_per_request": 1474.1
    },
    "cost": {
      "total_usd": 0.413548,
      "average_per_request_usd": 0.008271,
      "cost_per_token_usd": 5.61e-06
    },
    "model": "gpt-4.1",
    "generation_timestamp": "2025-08-28T10:48:41.393247"
  },
  "specifications": [
    {
      "file_path": "snippet_0.py",
      "code": "import numpy as np\n\n# guard against import of a non-existent metrics module in older skimage\ntry:\n    from skimage import metrics\nexcept ImportError:\n    pass\n\n\nclass SetMetricsSuite:\n    shape = (6, 6)\n    coords_a = np.zeros(shape, dtype=bool)\n    coords_b = np.zeros(shape, dtype=bool)\n\n    def setup(self):\n        points_a = (1, 0)\n        points_b = (5, 2)\n        self.coords_a[points_a] = True\n        self.coords_b[points_b] = True\n\n    def time_hausdorff_distance(self):\n        metrics.hausdorff_distance(self.coords_a, self.coords_b)\n\n    def time_modified_hausdorff_distance(self):\n        metrics.hausdorff_distance(self.coords_a, self.coords_b, method=\"modified\")\n\n    def time_hausdorff_pair(self):\n        metrics.hausdorff_pair(self.coords_a, self.coords_b)",
      "program_specification": "```dafny\n// Dafny translation of the SetMetricsSuite Python class\n// Focuses on structure, simple setup, and method stubs with specifications\n\ndatatype Point = Point(x: int, y: int)\n\nclass SetMetricsSuite {\n  var shapeX: nat := 6\n  var shapeY: nat := 6\n  var coords_a: array2<bool>\n  var coords_b: array2<bool>\n\n  constructor () \n    ensures coords_a != null && coords_b != null\n    ensures coords_a.Length == shapeX && coords_b.Length == shapeX\n    ensures forall i :: 0 <= i < shapeX ==> coords_a[i].Length == shapeY && coords_b[i].Length == shapeY\n    ensures forall i, j :: 0 <= i < shapeX && 0 <= j < shapeY ==> !coords_a[i][j] && !coords_b[i][j]\n  {\n    coords_a := new bool[shapeX][shapeY];\n    coords_b := new bool[shapeX][shapeY];\n    var i := 0;\n    while i < shapeX\n      invariant 0 <= i <= shapeX\n      invariant coords_a != null && coords_b != null\n      invariant coords_a.Length == shapeX && coords_b.Length == shapeX\n      invariant forall k :: 0 <= k < i ==> coords_a[k].Length == shapeY && coords_b[k].Length == shapeY\n    {\n      coords_a[i] := new bool[shapeY];\n      coords_b[i] := new bool[shapeY];\n      i := i + 1;\n    }\n  }\n\n  method setup()\n    modifies coords_a, coords_b\n    ensures coords_a[1][0] == true\n    ensures coords_b[5][2] == true\n    ensures forall i, j :: (i != 1 || j != 0) ==> coords_a[i][j] == false\n    ensures forall i, j :: (i != 5 || j != 2) ==> coords_b[i][j] == false\n  {\n    // Set all to false first (redundant, but for clarity)\n    var i := 0;\n    while i < shapeX\n      invariant 0 <= i <= shapeX\n      invariant forall k, l :: 0 <= k < i && 0 <= l < shapeY ==> coords_a[k][l] == false && coords_b[k][l] == false\n    {\n      var j := 0;\n      while j < shapeY\n        invariant 0 <= j <= shapeY\n        invariant forall l :: 0 <= l < j ==> coords_a[i][l] == false && coords_b[i][l] == false\n      {\n        coords_a[i][j] := false;\n        coords_b[i][j] := false;\n        j := j + 1;\n      }\n      i := i + 1;\n    }\n    // Set points\n    coords_a[1][0] := true;\n    coords_b[5][2] := true;\n  }\n\n  method time_hausdorff_distance()\n    // Specification: would call hausdorff_distance on coords_a and coords_b\n    // Here, just a stub with a specification\n    requires coords_a != null && coords_b != null\n    // ensures result is the Hausdorff distance between coords_a and coords_b\n  {\n    // Stub: no implementation\n  }\n\n  method time_modified_hausdorff_distance()\n    // Specification: would call hausdorff_distance with method=\"modified\"\n    requires coords_a != null && coords_b != null\n    // ensures result is the modified Hausdorff distance between coords_a and coords_b\n  {\n    // Stub: no implementation\n  }\n\n  method time_hausdorff_pair()\n    // Specification: would call hausdorff_pair on coords_a and coords_b\n    requires coords_a != null && coords_b != null\n    // ensures result is a pair of points achieving the Hausdorff distance\n  {\n    // Stub: no implementation\n  }\n}\n\n// Helper for 2D array\nclass array2<T> {\n  var data: array<array<T>>\n\n  constructor(n: nat, m: nat)\n    ensures data.Length == n\n    ensures forall i :: 0 <= i < n ==> data[i].Length == m\n  {\n    data := new T[n][];\n    var i := 0;\n    while i < n\n      invariant 0 <= i <= n\n      invariant data.Length == n\n      invariant forall k :: 0 <= k < i ==> data[k] != null && data[k].Length == m\n    {\n      data[i] := new T[m];\n      i := i + 1;\n    }\n  }\n\n  function Length: nat\n  {\n    data.Length\n  }\n\n  function method this[i: nat]: array<T>\n    requires 0 <= i < data.Length\n    reads this\n  {\n    data[i]\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 15.327,
        "duration_formatted": "15.33s",
        "tokens": {
          "input": 283,
          "output": 1040,
          "total": 1323
        },
        "cost_usd": 0.008886,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:32:55.945107"
      }
    },
    {
      "file_path": "snippet_1.py",
      "code": "from collections import deque\n\n\ndef int_to_bytes_big_endian(num):\n    bytestr = deque()\n    while num > 0:\n        # list.insert(0, ...) is inefficient\n        bytestr.appendleft(num & 0xff)\n        num >>= 8\n    return bytes(bytestr)\n\n\ndef int_to_bytes_little_endian(num):\n    bytestr = []\n    while num > 0:\n        bytestr.append(num & 0xff)\n        num >>= 8\n    return bytes(bytestr)\n\n\ndef bytes_big_endian_to_int(bytestr):\n    num = 0\n    for b in bytestr:\n        num <<= 8\n        num += b\n    return num\n\n\ndef bytes_little_endian_to_int(bytestr):\n    num = 0\n    e = 0\n    for b in bytestr:\n        num += b << e\n        e += 8\n    return num",
      "program_specification": "```dafny\nmodule IntBytesConversions {\n\n  // Helper function: returns the sequence of bytes (0..255) representing n in big endian order\n  function method IntToBytesBigEndianSeq(n: nat): seq<nat>\n    decreases n\n  {\n    if n == 0 then\n      []\n    else\n      IntToBytesBigEndianSeq(n / 256) + [n % 256]\n  }\n\n  // Helper function: returns the sequence of bytes (0..255) representing n in little endian order\n  function method IntToBytesLittleEndianSeq(n: nat): seq<nat>\n    decreases n\n  {\n    if n == 0 then\n      []\n    else\n      [n % 256] + IntToBytesLittleEndianSeq(n / 256)\n  }\n\n  // Converts a non-negative integer to a sequence of bytes in big endian order (most significant byte first)\n  method IntToBytesBigEndian(num: nat) returns (bytes: seq<nat>)\n    ensures forall b :: b in bytes ==> 0 <= b < 256\n    ensures bytes == (if num == 0 then [] else IntToBytesBigEndianSeq(num))\n    decreases num\n  {\n    var res: seq<nat> := [];\n    var n := num;\n    while n > 0\n      invariant 0 <= n\n      invariant forall b :: b in res ==> 0 <= b < 256\n      invariant res == IntToBytesBigEndianSeq(num)[(|IntToBytesBigEndianSeq(num)| - |res|)..]\n      decreases n\n    {\n      res := [n % 256] + res;\n      n := n / 256;\n    }\n    bytes := if num == 0 then [] else res;\n  }\n\n  // Converts a non-negative integer to a sequence of bytes in little endian order (least significant byte first)\n  method IntToBytesLittleEndian(num: nat) returns (bytes: seq<nat>)\n    ensures forall b :: b in bytes ==> 0 <= b < 256\n    ensures bytes == (if num == 0 then [] else IntToBytesLittleEndianSeq(num))\n    decreases num\n  {\n    var res: seq<nat> := [];\n    var n := num;\n    while n > 0\n      invariant 0 <= n\n      invariant forall b :: b in res ==> 0 <= b < 256\n      invariant res == IntToBytesLittleEndianSeq(num)[..|res|]\n      decreases n\n    {\n      res := res + [n % 256];\n      n := n / 256;\n    }\n    bytes := if num == 0 then [] else res;\n  }\n\n  // Converts a sequence of bytes in big endian order to an integer\n  method BytesBigEndianToInt(bytes: seq<nat>) returns (num: nat)\n    requires forall b :: b in bytes ==> 0 <= b < 256\n    ensures num == (if |bytes| == 0 then 0 else BytesBigEndianToIntSeq(bytes))\n    decreases bytes\n  {\n    var n: nat := 0;\n    var i: int := 0;\n    while i < |bytes|\n      invariant 0 <= i <= |bytes|\n      invariant 0 <= n\n      invariant forall j :: 0 <= j < i ==> 0 <= bytes[j] < 256\n      invariant n == (if i == 0 then 0 else BytesBigEndianToIntSeq(bytes[..i]))\n      decreases |bytes| - i\n    {\n      n := n * 256 + bytes[i];\n      i := i + 1;\n    }\n    num := n;\n  }\n\n  // Helper function for specification: interprets a sequence of bytes as a big endian integer\n  function method BytesBigEndianToIntSeq(bytes: seq<nat>): nat\n    requires forall b :: b in bytes ==> 0 <= b < 256\n    decreases bytes\n  {\n    if |bytes| == 0 then 0\n    else bytes[0] * 256 ^ (|bytes| - 1) + BytesBigEndianToIntSeq(bytes[1..])\n  }\n\n  // Converts a sequence of bytes in little endian order to an integer\n  method BytesLittleEndianToInt(bytes: seq<nat>) returns (num: nat)\n    requires forall b :: b in bytes ==> 0 <= b < 256\n    ensures num == (if |bytes| == 0 then 0 else BytesLittleEndianToIntSeq(bytes))\n    decreases bytes\n  {\n    var n: nat := 0;\n    var e: nat := 0;\n    var i: int := 0;\n    while i < |bytes|\n      invariant 0 <= i <= |bytes|\n      invariant 0 <= n\n      invariant e == 8 * i\n      invariant forall j :: 0 <= j < i ==> 0 <= bytes[j] < 256\n      invariant n == (if i == 0 then 0 else BytesLittleEndianToIntSeq(bytes[..i]))\n      decreases |bytes| - i\n    {\n      n := n + bytes[i] * (1 << e);\n      e := e + 8;\n      i := i + 1;\n    }\n    num := n;\n  }\n\n  // Helper function for specification: interprets a sequence of bytes as a little endian integer\n  function method BytesLittleEndianToIntSeq(bytes: seq<nat>): nat\n    requires forall b :: b in bytes ==> 0 <= b < 256\n    decreases bytes\n  {\n    if |bytes| == 0 then 0\n    else bytes[0] + 256 * BytesLittleEndianToIntSeq(bytes[1..])\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 16.106,
        "duration_formatted": "16.11s",
        "tokens": {
          "input": 272,
          "output": 1203,
          "total": 1475
        },
        "cost_usd": 0.010168,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:33:17.083858"
      }
    },
    {
      "file_path": "snippet_2.py",
      "code": "'''\nYou are given a license key represented as a string S which consists only alphanumeric character and dashes. The string is separated into N+1 groups by N dashes.\n\nGiven a number K, we would want to reformat the strings such that each group contains exactly K characters, except for the first group which could be shorter than K, but still must contain at least one character. Furthermore, there must be a dash inserted between two groups and all lowercase letters should be converted to uppercase.\n\nGiven a non-empty string S and a number K, format the string according to the rules described above.\n\nExample 1:\nInput: S = \"5F3Z-2e-9-w\", K = 4\n\nOutput: \"5F3Z-2E9W\"\n\nExplanation: The string S has been split into two parts, each part has 4 characters.\nNote that the two extra dashes are not needed and can be removed.\nExample 2:\nInput: S = \"2-5g-3-J\", K = 2\n\nOutput: \"2-5G-3J\"\n\nExplanation: The string S has been split into three parts, each part has 2 characters except the first part as it could be shorter as mentioned above.\nNote:\nThe length of string S will not exceed 12,000, and K is a positive integer.\nString S consists only of alphanumerical characters (a-z and/or A-Z and/or 0-9) and dashes(-).\nString S is non-empty.\n'''\n\nclass Solution(object):\n    def licenseKeyFormatting(self, S, K):\n        \"\"\"\n        :type S: str\n        :type K: int\n        :rtype: str\n        \"\"\"\n        S = S.replace('-','').upper()\n        result = \"\"\n        \n        if len(S)%K == 0:\n            for index in range(0, len(S), K):\n                result += S[index:index+K] + \"-\"\n        else:\n            result = S[:len(S)%K] + \"-\"\n            for index in range(len(S)%K, len(S), K):\n                result += S[index:index+K] + \"-\"\n        return result[:-1]",
      "program_specification": "```dafny\nmethod LicenseKeyFormatting(S: string, K: int) returns (res: string)\n    requires |S| > 0\n    requires K > 0\n    requires forall i :: 0 <= i < |S| ==> (('0' <= S[i] <= '9') || ('a' <= S[i] <= 'z') || ('A' <= S[i] <= 'Z') || S[i] == '-')\n    ensures forall c :: 0 <= c < |res| ==> (('0' <= res[c] <= '9') || ('A' <= res[c] <= 'Z') || res[c] == '-')\n    ensures forall c :: 0 <= c < |res| ==> res[c] != '-' ==> ('A' <= res[c] <= 'Z' || '0' <= res[c] <= '9')\n    ensures res[0] != '-' && res[|res|-1] != '-'\n    ensures forall i :: 0 <= i < |res| ==> (res[i] == '-' ==> (i > 0 && i < |res|-1 && res[i-1] != '-' && res[i+1] != '-'))\n    ensures var groups := res.Split(\"-\"); \n            forall j :: 1 <= j < |groups| ==> |groups[j]| == K\n    ensures 1 <= |res.Split(\"-\")[0]| <= K\n{\n    // Remove dashes and convert to uppercase\n    var cleaned := \"\";\n    var i := 0;\n    while i < |S|\n        invariant 0 <= i <= |S|\n        invariant |cleaned| <= |S|\n        invariant forall j :: 0 <= j < |cleaned| ==> ('A' <= cleaned[j] <= 'Z' || '0' <= cleaned[j] <= '9')\n    {\n        if S[i] != '-' {\n            if 'a' <= S[i] <= 'z' {\n                cleaned := cleaned + [char]('A' as int + (S[i] as int - 'a' as int));\n            } else if 'A' <= S[i] <= 'Z' || '0' <= S[i] <= '9' {\n                cleaned := cleaned + S[i];\n            }\n        }\n        i := i + 1;\n    }\n\n    var n := |cleaned|;\n    var firstGroupLen := if n % K == 0 then K else n % K;\n    var idx := 0;\n    var result := \"\";\n\n    // Add the first group\n    if firstGroupLen > 0 {\n        result := cleaned[..firstGroupLen];\n        idx := firstGroupLen;\n    }\n\n    // Add remaining groups\n    while idx < n\n        invariant 0 <= idx <= n\n        invariant result == cleaned[..firstGroupLen] + (if idx > firstGroupLen then \"-\" + (cleaned[firstGroupLen..idx]).ChunkString(K, \"-\") else \"\")\n    {\n        result := result + \"-\" + cleaned[idx .. idx+K];\n        idx := idx + K;\n    }\n\n    // Remove trailing dash if present\n    if |result| > 0 && result[|result|-1] == '-' {\n        res := result[..|result|-1];\n    } else {\n        res := result;\n    }\n}\n\n// Helper function to split a string into K-sized chunks, separated by sep\nfunction method ChunkString(s: string, K: int, sep: string): string\n    requires K > 0\n    ensures var n := |s|;\n            var chunks := if n == 0 then [] else [s[0..if n < K then n else K]];\n            var i := K;\n            while i < n\n                decreases n - i\n            {\n                chunks := chunks + [s[i..if i+K < n then i+K else n]];\n                i := i + K;\n            }\n            true;\n            sep.Join(chunks) == ChunkString(s, K, sep)\n{\n    if |s| == 0 then \"\" else\n        var n := |s|;\n        var result := s[..if n < K then n else K];\n        var i := K;\n        while i < n\n            decreases n - i\n        {\n            result := result + sep + s[i..if i+K < n then i+K else n];\n            i := i + K;\n        }\n        result\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 18.672,
        "duration_formatted": "18.67s",
        "tokens": {
          "input": 532,
          "output": 928,
          "total": 1460
        },
        "cost_usd": 0.008488,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:33:40.802844"
      }
    },
    {
      "file_path": "snippet_3.py",
      "code": "'''\nGiven a 2-dimensional grid of integers, each value in the grid represents the color of the grid square at that location.\n\nTwo squares belong to the same connected component if and only if they have the same color and are next to each other in any of the 4 directions.\n\nThe border of a connected component is all the squares in the connected component that are either 4-directionally adjacent to a square not in the component, or on the boundary of the grid (the first or last row or column).\n\nGiven a square at location (r0, c0) in the grid and a color, color the border of the connected component of that square with the given color, and return the final grid.\n\nExample 1:\n\nInput: grid = [[1,1],[1,2]], r0 = 0, c0 = 0, color = 3\nOutput: [[3, 3], [3, 2]]\nExample 2:\n\nInput: grid = [[1,2,2],[2,3,2]], r0 = 0, c0 = 1, color = 3\nOutput: [[1, 3, 3], [2, 3, 3]]\nExample 3:\n\nInput: grid = [[1,1,1],[1,1,1],[1,1,1]], r0 = 1, c0 = 1, color = 2\nOutput: [[2, 2, 2], [2, 1, 2], [2, 2, 2]]\n \n\nNote:\n\n1 <= grid.length <= 50\n1 <= grid[0].length <= 50\n1 <= grid[i][j] <= 1000\n0 <= r0 < grid.length\n0 <= c0 < grid[0].length\n1 <= color <= 1000\n'''\n\nclass Solution(object):\n    def colorBorder(self, grid, r0, c0, color):\n        \"\"\"\n        :type grid: List[List[int]]\n        :type r0: int\n        :type c0: int\n        :type color: int\n        :rtype: List[List[int]]\n        \"\"\"\n        if not grid:\n            return grid\n        visited, border = [], []\n        m, n = len(grid), len(grid[0])\n        \n        def dfs(r, c):\n            if r < 0 or c < 0 or r >= m or c >= n or grid[r][c] != grid[r0][c0] or (r,c) in visited:\n                return\n            visited.append((r,c))\n            \n            # check if the current row, col index is edge of the matrix\n            # if not then check adjacent cells doesnt have same value as grid[r0][c0] then add in border\n            if (r == 0 or c == 0 or r == m-1 or c == n-1 or \n                (r+1 < m and grid[r+1][c] != grid[r0][c0]) or\n                (r-1 >= 0 and grid[r-1][c] != grid[r0][c0]) or\n                (c+1 < n and grid[r][c+1] != grid[r0][c0]) or\n                (c-1 >= 0 and grid[r][c-1] != grid[r0][c0])):\n                    border.append((r,c))\n            dfs(r-1, c)\n            dfs(r+1, c)\n            dfs(r, c-1)\n            dfs(r, c+1)\n            \n        dfs(r0, c0)\n        for (x, y) in border:\n            grid[x][y] = color\n        return grid",
      "program_specification": "```dafny\n// Dafny translation of colorBorder with formal specification\n\nmethod colorBorder(grid: seq<seq<int>>, r0: int, c0: int, color: int) returns (result: seq<seq<int>>)\n  requires |grid| > 0 && |grid[0]| > 0\n  requires forall row :: 0 <= row < |grid| ==> |grid[row]| == |grid[0]|\n  requires 1 <= r0 < |grid|\n  requires 1 <= c0 < |grid[0]|\n  requires 1 <= color <= 1000\n  requires forall row :: 0 <= row < |grid| ==> forall col :: 0 <= col < |grid[0]| ==> 1 <= grid[row][col] <= 1000\n  ensures |result| == |grid| && forall row :: 0 <= row < |grid| ==> |result[row]| == |grid[0]|\n{\n  var m := |grid|;\n  var n := |grid[0]|;\n  var origColor := grid[r0][c0];\n\n  // Mutable arrays for visited and border\n  var visited := new bool[m, n];\n  var isBorder := new bool[m, n];\n\n  // Directions for 4-connected neighbors\n  var dirs := [(-1, 0), (1, 0), (0, -1), (0, 1)];\n\n  // Helper function: check if position is in bounds\n  function method InBounds(r: int, c: int): bool\n    reads {}\n  {\n    0 <= r < m && 0 <= c < n\n  }\n\n  // DFS to mark visited and border cells\n  method dfs(r: int, c: int)\n    requires InBounds(r, c)\n    modifies visited, isBorder\n  {\n    if visited[r, c] || grid[r][c] != origColor {\n      return;\n    }\n    visited[r, c] := true;\n\n    var borderCell := false;\n\n    if r == 0 || c == 0 || r == m-1 || c == n-1 {\n      borderCell := true;\n    } else {\n      // Check if any neighbor is not in the component\n      for d in dirs {\n        var nr := r + d.0;\n        var nc := c + d.1;\n        if InBounds(nr, nc) {\n          if grid[nr][nc] != origColor {\n            borderCell := true;\n          }\n        }\n      }\n    }\n    if borderCell {\n      isBorder[r, c] := true;\n    }\n\n    // DFS to neighbors\n    for d in dirs {\n      var nr := r + d.0;\n      var nc := c + d.1;\n      if InBounds(nr, nc) && !visited[nr, nc] && grid[nr][nc] == origColor {\n        dfs(nr, nc);\n      }\n    }\n  }\n\n  dfs(r0, c0);\n\n  // Build result grid\n  var gridArr := new int[m, n];\n  // Copy original grid\n  var i := 0;\n  while i < m\n    invariant 0 <= i <= m\n    invariant forall row :: 0 <= row < i ==> forall col :: 0 <= col < n ==> gridArr[row, col] == grid[row][col]\n  {\n    var j := 0;\n    while j < n\n      invariant 0 <= j <= n\n      invariant forall col :: 0 <= col < j ==> gridArr[i, col] == grid[i][col]\n    {\n      gridArr[i, j] := grid[i][j];\n      j := j + 1;\n    }\n    i := i + 1;\n  }\n\n  // Color the border\n  i := 0;\n  while i < m\n    invariant 0 <= i <= m\n  {\n    var j := 0;\n    while j < n\n      invariant 0 <= j <= n\n    {\n      if isBorder[i, j] {\n        gridArr[i, j] := color;\n      }\n      j := j + 1;\n    }\n    i := i + 1;\n  }\n\n  // Convert gridArr to sequence of sequences\n  var res := [];\n  i := 0;\n  while i < m\n    invariant 0 <= i <= m\n    invariant |res| == i\n  {\n    var row := [];\n    var j := 0;\n    while j < n\n      invariant 0 <= j <= n\n      invariant |row| == j\n    {\n      row := row + [gridArr[i, j]];\n      j := j + 1;\n    }\n    res := res + [row];\n    i := i + 1;\n  }\n  result := res;\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.018,
        "duration_formatted": "11.02s",
        "tokens": {
          "input": 857,
          "output": 1017,
          "total": 1874
        },
        "cost_usd": 0.00985,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:33:56.848581"
      }
    },
    {
      "file_path": "snippet_4.py",
      "code": "'''\n\tGiven an array of meeting time intervals consisting of start and end times [[s1,e1], [s2,e2],…] (si < ei), find the minimum number of conference rooms required.\n\tFor example,\n\tGiven [[0, 30],[5, 10],[15, 20]],\n\treturn 2.\n'''\n\n\n# Definition for an interval.\n# class Interval(object):\n#     def __init__(self, s=0, e=0):\n#         self.start = s\n#         self.end = e\n\nclass Solution:\n    def minMeetingRooms(self, intervals):\n    \tif not intervals or len(intervals) == 0:\n    \t\treturn 0\n\n    \timport heapq\n\n    \tsorted_intervals = sorted(intervals, key=lambda it:(it.start, it.end))\n    \theap, result = [], 0\n\n    \tfor interval in sorted_intervals:\n    \t\tstart, end = interval.start, interval.end\n\n    \t\twhile heap and heap[0] <= start:\n    \t\t\theapq.heappop(heap)\n\n    \t\theapq.heappush(heap, end)\n\n    \t\tresult = max(result, len(heap))\n    \treturn result",
      "program_specification": "```dafny\n// Definition for an interval.\nclass Interval {\n  var start: int;\n  var end: int;\n\n  constructor (s: int, e: int)\n    requires s < e\n  {\n    start := s;\n    end := e;\n  }\n}\n\nmethod minMeetingRooms(intervals: seq<Interval>) returns (rooms: int)\n  requires forall i :: 0 <= i < |intervals| ==> intervals[i].start < intervals[i].end\n  ensures rooms >= 0\n  ensures |intervals| == 0 ==> rooms == 0\n{\n  if |intervals| == 0 {\n    return 0;\n  }\n\n  // Sort intervals by start time, breaking ties by end time\n  var sorted :=\n    intervals[..];\n  sorted := SortIntervals(sorted);\n\n  var heap: seq<int> := [];\n  var result := 0;\n\n  var i := 0;\n  while i < |sorted|\n    invariant 0 <= i <= |sorted|\n    invariant result >= 0\n    invariant |heap| <= i\n    invariant forall t :: 0 <= t < |heap| ==> heap[t] >= 0\n    decreases |sorted| - i\n  {\n    var start := sorted[i].start;\n    var end := sorted[i].end;\n\n    // Remove all meetings that have ended\n    while |heap| > 0 && heap[0] <= start\n      invariant |heap| <= i\n      decreases |heap|\n    {\n      heap := heap[1..];\n    }\n\n    // Add current meeting's end time to heap\n    heap := InsertHeap(heap, end);\n\n    if |heap| > result {\n      result := |heap|;\n    }\n    i := i + 1;\n  }\n  return result;\n}\n\n// Helper function: sorts intervals by start time, then end time\nfunction method SortIntervals(a: seq<Interval>): seq<Interval>\n  ensures |SortIntervals(a)| == |a|\n  ensures multiset a == multiset SortIntervals(a)\n  ensures forall i, j :: 0 <= i < j < |SortIntervals(a)| ==>\n    SortIntervals(a)[i].start < SortIntervals(a)[j].start ||\n    (SortIntervals(a)[i].start == SortIntervals(a)[j].start && SortIntervals(a)[i].end <= SortIntervals(a)[j].end)\n{\n  if |a| <= 1 then a\n  else\n    var pivot := a[0];\n    SortIntervals([x | x := a[1..], x.start < pivot.start || (x.start == pivot.start && x.end <= pivot.end)])\n    + [pivot]\n    + SortIntervals([x | x := a[1..], x.start > pivot.start || (x.start == pivot.start && x.end > pivot.end)])\n}\n\n// Helper function: insert value into a min-heap (represented as a sorted sequence)\nfunction method InsertHeap(heap: seq<int>, value: int): seq<int>\n  ensures |InsertHeap(heap, value)| == |heap| + 1\n  ensures multiset InsertHeap(heap, value) == multiset heap + multiset [value]\n  ensures forall i, j :: 0 <= i < j < |InsertHeap(heap, value)| ==> InsertHeap(heap, value)[i] <= InsertHeap(heap, value)[j]\n{\n  var h := heap + [value];\n  SortInts(h)\n}\n\n// Helper: sort a sequence of integers\nfunction method SortInts(a: seq<int>): seq<int>\n  ensures |SortInts(a)| == |a|\n  ensures multiset SortInts(a) == multiset a\n  ensures forall i, j :: 0 <= i < j < |SortInts(a)| ==> SortInts(a)[i] <= SortInts(a)[j]\n{\n  if |a| <= 1 then a\n  else\n    var pivot := a[0];\n    SortInts([x | x := a[1..], x <= pivot]) + [pivot] + SortInts([x | x := a[1..], x > pivot])\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.186,
        "duration_formatted": "11.19s",
        "tokens": {
          "input": 322,
          "output": 854,
          "total": 1176
        },
        "cost_usd": 0.007476,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:34:13.065009"
      }
    },
    {
      "file_path": "snippet_5.py",
      "code": "'''\nGiven an array of integers where 1 ≤ a[i] ≤ n (n = size of array), some elements appear twice and others appear once.\n\nFind all the elements of [1, n] inclusive that do not appear in this array.\n\nCould you do it without extra space and in O(n) runtime? You may assume the returned list does not count as extra space.\n\nExample:\n\nInput:\n[4,3,2,7,8,2,3,1]\n\nOutput:\n[5,6]\n'''\n\nclass Solution(object):\n    def findDisappearedNumbers(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: List[int]\n        \"\"\"\n        if not nums:\n            return []\n        result = []\n        for num in nums:\n            index = abs(num)-1\n            if nums[index] > 0:\n                nums[index]*=-1\n        for index, num in enumerate(nums):\n            if num >0:\n                result.append(index+1)\n        return result",
      "program_specification": "```dafny\nmethod FindDisappearedNumbers(nums: array<int>) returns (result: seq<int>)\n    requires nums != null\n    requires forall i :: 0 <= i < nums.Length ==> 1 <= nums[i] <= nums.Length\n    ensures forall i :: 1 <= i <= nums.Length ==> (i !in result <==> exists j :: 0 <= j < nums.Length && nums[j] == i)\n    ensures forall i :: 1 <= i <= nums.Length ==> (i in result <==> forall j :: 0 <= j < nums.Length ==> nums[j] != i)\n{\n    if nums.Length == 0 {\n        return [];\n    }\n    // Mark numbers as negative using their value as index\n    var i := 0;\n    while i < nums.Length\n        invariant 0 <= i <= nums.Length\n        invariant forall j :: 0 <= j < i ==> \n            var idx := if nums[j] < 0 then -nums[j] - 1 else nums[j] - 1;\n            0 <= idx < nums.Length && nums[idx] <= 0\n    {\n        var num := if nums[i] < 0 then -nums[i] else nums[i];\n        var index := num - 1;\n        if nums[index] > 0 {\n            nums[index] := -nums[index];\n        }\n        i := i + 1;\n    }\n\n    var res := new seq<int>[];\n    i := 0;\n    while i < nums.Length\n        invariant 0 <= i <= nums.Length\n        invariant res == [j + 1 | j := 0 .. i - 1, nums[j] > 0]\n    {\n        if nums[i] > 0 {\n            res := res + [i + 1];\n        }\n        i := i + 1;\n    }\n    result := res;\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 5.062,
        "duration_formatted": "5.06s",
        "tokens": {
          "input": 290,
          "output": 393,
          "total": 683
        },
        "cost_usd": 0.003724,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:34:23.172257"
      }
    },
    {
      "file_path": "snippet_6.py",
      "code": "from django.urls import get_script_prefix, resolve\n\n\ndef get_breadcrumbs(url, request=None):\n    \"\"\"\n    Given a url returns a list of breadcrumbs, which are each a\n    tuple of (name, url).\n    \"\"\"\n    from rest_framework.reverse import preserve_builtin_query_params\n    from rest_framework.views import APIView\n\n    def breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen):\n        \"\"\"\n        Add tuples of (name, url) to the breadcrumbs list,\n        progressively chomping off parts of the url.\n        \"\"\"\n        try:\n            (view, unused_args, unused_kwargs) = resolve(url)\n        except Exception:\n            pass\n        else:\n            # Check if this is a REST framework view,\n            # and if so add it to the breadcrumbs\n            cls = getattr(view, 'cls', None)\n            initkwargs = getattr(view, 'initkwargs', {})\n            if cls is not None and issubclass(cls, APIView):\n                # Don't list the same view twice in a row.\n                # Probably an optional trailing slash.\n                if not seen or seen[-1] != view:\n                    c = cls(**initkwargs)\n                    name = c.get_view_name()\n                    insert_url = preserve_builtin_query_params(prefix + url, request)\n                    breadcrumbs_list.insert(0, (name, insert_url))\n                    seen.append(view)\n\n        if url == '':\n            # All done\n            return breadcrumbs_list\n\n        elif url.endswith('/'):\n            # Drop trailing slash off the end and continue to try to\n            # resolve more breadcrumbs\n            url = url.rstrip('/')\n            return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)\n\n        # Drop trailing non-slash off the end and continue to try to\n        # resolve more breadcrumbs\n        url = url[:url.rfind('/') + 1]\n        return breadcrumbs_recursive(url, breadcrumbs_list, prefix, seen)\n\n    prefix = get_script_prefix().rstrip('/')\n    url = url[len(prefix):]\n    return breadcrumbs_recursive(url, [], prefix, [])",
      "program_specification": "```dafny\n// Dafny translation of the get_breadcrumbs function.\n// Focused on simplicity and verifiability.\n\nmodule Breadcrumbs {\n\n  datatype Breadcrumb = Breadcrumb(name: string, url: string)\n\n  // Helper function: returns true if s ends with suffix\n  function method EndsWith(s: string, suffix: string): bool\n    decreases s, suffix\n  {\n    |s| >= |suffix| && s[|s|-|suffix|..] == suffix\n  }\n\n  // Helper function: returns s with trailing '/' removed\n  function method RStripSlash(s: string): string\n    decreases s\n  {\n    if |s| > 0 && s[|s|-1..] == \"/\" then s[..|s|-1] else s\n  }\n\n  // Helper function: returns the index of the last '/' in s, or -1 if not found\n  function method LastSlash(s: string): int\n    decreases s\n  {\n    if |s| == 0 then -1\n    else if s[|s|-1..] == \"/\" then |s|-1\n    else\n      var idx := |s|-1;\n      while idx >= 0 && s[idx..idx+1] != \"/\" \n        decreases idx\n      {\n        idx := idx - 1;\n      }\n      if idx >= 0 then idx else -1\n  }\n\n  // Main recursive function for breadcrumbs\n  // For simplicity, we abstract away Django/DRF details and simulate\n  // 'resolving' a URL by splitting on '/' and using the segment as the name.\n  // We do not handle 'request', 'preserve_builtin_query_params', or view classes.\n  method BreadcrumbsRecursive(url: string, breadcrumbs: seq<Breadcrumb>, prefix: string) returns (res: seq<Breadcrumb>)\n    decreases url\n    ensures |res| >= |breadcrumbs|\n    ensures forall i :: 0 <= i < |res| ==> res[i].url != \"\"\n  {\n    if url == \"\" {\n      return breadcrumbs;\n    }\n\n    var cleanUrl := url;\n    if EndsWith(cleanUrl, \"/\") {\n      cleanUrl := RStripSlash(cleanUrl);\n      return BreadcrumbsRecursive(cleanUrl, breadcrumbs, prefix);\n    }\n\n    var idx := LastSlash(cleanUrl);\n    var name: string;\n    var crumbUrl: string;\n    if idx >= 0 {\n      name := cleanUrl[idx+1..];\n      crumbUrl := prefix + cleanUrl[..idx+1];\n    } else {\n      name := cleanUrl;\n      crumbUrl := prefix + cleanUrl;\n    }\n\n    var newBreadcrumb := Breadcrumb(name, crumbUrl);\n    var newBreadcrumbs := [newBreadcrumb] + breadcrumbs;\n    if idx >= 0 {\n      var nextUrl := cleanUrl[..idx+1];\n      return BreadcrumbsRecursive(nextUrl, newBreadcrumbs, prefix);\n    } else {\n      return newBreadcrumbs;\n    }\n  }\n\n  // Top-level function\n  method GetBreadcrumbs(url: string, prefix: string) returns (breadcrumbs: seq<Breadcrumb>)\n    ensures forall b :: b in breadcrumbs ==> b.url != \"\"\n  {\n    // Remove prefix from url if present\n    var realUrl :=\n      if |prefix| > 0 && |url| >= |prefix| && url[..|prefix|] == prefix\n        then url[|prefix|..]\n        else url;\n\n    return BreadcrumbsRecursive(realUrl, [], prefix);\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.817,
        "duration_formatted": "11.82s",
        "tokens": {
          "input": 492,
          "output": 727,
          "total": 1219
        },
        "cost_usd": 0.0068,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:34:40.033253"
      }
    },
    {
      "file_path": "snippet_7.py",
      "code": "from typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from redis.asyncio.client import Pipeline, Redis\n\n\ndef from_url(url, **kwargs):\n    \"\"\"\n    Returns an active Redis client generated from the given database URL.\n\n    Will attempt to extract the database id from the path url fragment, if\n    none is provided.\n    \"\"\"\n    from redis.asyncio.client import Redis\n\n    return Redis.from_url(url, **kwargs)\n\n\nclass pipeline:  # noqa: N801\n    def __init__(self, redis_obj: \"Redis\"):\n        self.p: \"Pipeline\" = redis_obj.pipeline()\n\n    async def __aenter__(self) -> \"Pipeline\":\n        return self.p\n\n    async def __aexit__(self, exc_type, exc_value, traceback):\n        await self.p.execute()\n        del self.p",
      "program_specification": "```dafny\n// Dafny translation of the provided Python code\n// Focused on simplicity and verifiability\n\nmodule RedisClient {\n\n  // A stub for the Redis type\n  class Redis {\n    // Simulates creating a Redis client from a URL\n    static method from_url(url: string) returns (client: Redis)\n      ensures client != null\n    {\n      client := new Redis;\n    }\n\n    // Simulates creating a Pipeline from this Redis client\n    method pipeline() returns (p: Pipeline)\n      ensures p != null\n    {\n      p := new Pipeline(this);\n    }\n  }\n\n  // A stub for the Pipeline type\n  class Pipeline {\n    var redis: Redis;\n\n    constructor(r: Redis)\n      requires r != null\n      ensures redis == r\n    {\n      redis := r;\n    }\n\n    // Simulates executing the pipeline\n    method execute()\n      modifies this\n      ensures true\n    {\n      // No-op for simulation\n    }\n  }\n\n  // Equivalent of from_url function\n  method from_url(url: string) returns (client: Redis)\n    ensures client != null\n  {\n    client := Redis.from_url(url);\n  }\n\n  // Equivalent of the pipeline context manager class\n  class pipeline {\n    var p: Pipeline?;\n\n    constructor(redis_obj: Redis)\n      requires redis_obj != null\n      ensures p != null\n    {\n      var pipe := redis_obj.pipeline();\n      p := pipe;\n    }\n\n    // Simulates async context enter: returns the pipeline\n    method __aenter__() returns (pipe: Pipeline)\n      requires p != null\n      ensures pipe == p\n    {\n      pipe := p;\n    }\n\n    // Simulates async context exit: executes and deletes the pipeline\n    method __aexit__()\n      requires p != null\n      modifies this\n      ensures p == null\n    {\n      p.execute();\n      p := null;\n    }\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 5.359,
        "duration_formatted": "5.36s",
        "tokens": {
          "input": 251,
          "output": 400,
          "total": 651
        },
        "cost_usd": 0.003702,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:34:50.430479"
      }
    },
    {
      "file_path": "snippet_8.py",
      "code": "\"\"\"\nAuthor : Syed Faizan (3rd Year Student IIIT Pune)\ngithub : faizan2700\nYou are given a bitmask m and you want to efficiently iterate through all of\nits submasks. The mask s is submask of m if only bits that were included in\nbitmask are set\n\"\"\"\n\nfrom __future__ import annotations\n\n\ndef list_of_submasks(mask: int) -> list[int]:\n    \"\"\"\n    Args:\n        mask : number which shows mask ( always integer > 0, zero does not have any\n            submasks )\n\n    Returns:\n        all_submasks : the list of submasks of mask (mask s is called submask of mask\n        m if only bits that were included in original mask are set\n\n    Raises:\n        AssertionError: mask not positive integer\n\n    >>> list_of_submasks(15)\n    [15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n    >>> list_of_submasks(13)\n    [13, 12, 9, 8, 5, 4, 1]\n    >>> list_of_submasks(-7)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n        ...\n    AssertionError: mask needs to be positive integer, your input -7\n    >>> list_of_submasks(0)  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n        ...\n    AssertionError: mask needs to be positive integer, your input 0\n\n    \"\"\"\n\n    assert isinstance(mask, int) and mask > 0, (\n        f\"mask needs to be positive integer, your input {mask}\"\n    )\n\n    \"\"\"\n    first submask iterated will be mask itself then operation will be performed\n    to get other submasks till we reach empty submask that is zero ( zero is not\n    included in final submasks list )\n    \"\"\"\n    all_submasks = []\n    submask = mask\n\n    while submask:\n        all_submasks.append(submask)\n        submask = (submask - 1) & mask\n\n    return all_submasks\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\n// Author: Syed Faizan (3rd Year Student IIIT Pune)\n// github: faizan2700\n// Dafny translation by OpenAI\n\n// Returns true if s is a submask of m: all bits set in s are also set in m.\nfunction method IsSubmask(s: int, m: int): bool\n  requires 0 <= s <= m\n{\n  (s & m) == s\n}\n\n// Returns the set of all nonzero submasks of mask.\nfunction method Submasks(mask: int): set<int>\n  requires mask > 0\n{\n  { s | 1 <= s <= mask && IsSubmask(s, mask) }\n}\n\nmethod list_of_submasks(mask: int) returns (all_submasks: seq<int>)\n  requires mask > 0\n  ensures all_submasks == Submasks(mask).Elements\n  ensures all_submasks == all_submasks[..] // sequence, not set\n  ensures all_submasks == [s | s := all_submasks, 0 < s <= mask && IsSubmask(s, mask)]\n  ensures all_submasks[0] == mask\n  ensures all_submasks == all_submasks[..] // no zero in list\n{\n  var submask := mask;\n  var result := [];\n  while submask > 0\n    invariant 0 <= submask <= mask\n    invariant forall s :: s in result ==> 0 < s <= mask && IsSubmask(s, mask)\n    invariant mask in result || result == []\n    decreases submask\n  {\n    result := result + [submask];\n    submask := (submask - 1) & mask;\n  }\n  all_submasks := result;\n}\n\n// Some test cases as methods with ensures clauses\n\nmethod test_list_of_submasks_15()\n  ensures list_of_submasks(15) == [15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n{\n}\n\nmethod test_list_of_submasks_13()\n  ensures list_of_submasks(13) == [13, 12, 9, 8, 5, 4, 1]\n{\n}\n\n// Negative and zero input should not be allowed (precondition violation).\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.792,
        "duration_formatted": "8.79s",
        "tokens": {
          "input": 585,
          "output": 507,
          "total": 1092
        },
        "cost_usd": 0.005226,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:35:04.266665"
      }
    },
    {
      "file_path": "snippet_9.py",
      "code": "\"\"\"\nThe Response class in REST framework is similar to HTTPResponse, except that\nit is initialized with unrendered data, instead of a pre-rendered string.\n\nThe appropriate renderer is called during Django's template response rendering.\n\"\"\"\nfrom http.client import responses\n\nfrom django.template.response import SimpleTemplateResponse\n\nfrom rest_framework.serializers import Serializer\n\n\nclass Response(SimpleTemplateResponse):\n    \"\"\"\n    An HttpResponse that allows its data to be rendered into\n    arbitrary media types.\n    \"\"\"\n\n    def __init__(self, data=None, status=None,\n                 template_name=None, headers=None,\n                 exception=False, content_type=None):\n        \"\"\"\n        Alters the init arguments slightly.\n        For example, drop 'template_name', and instead use 'data'.\n\n        Setting 'renderer' and 'media_type' will typically be deferred,\n        For example being set automatically by the `APIView`.\n        \"\"\"\n        super().__init__(None, status=status)\n\n        if isinstance(data, Serializer):\n            msg = (\n                'You passed a Serializer instance as data, but '\n                'probably meant to pass serialized `.data` or '\n                '`.error`. representation.'\n            )\n            raise AssertionError(msg)\n\n        self.data = data\n        self.template_name = template_name\n        self.exception = exception\n        self.content_type = content_type\n\n        if headers:\n            for name, value in headers.items():\n                self[name] = value\n\n    # Allow generic typing checking for responses.\n    def __class_getitem__(cls, *args, **kwargs):\n        return cls\n\n    @property\n    def rendered_content(self):\n        renderer = getattr(self, 'accepted_renderer', None)\n        accepted_media_type = getattr(self, 'accepted_media_type', None)\n        context = getattr(self, 'renderer_context', None)\n\n        assert renderer, \".accepted_renderer not set on Response\"\n        assert accepted_media_type, \".accepted_media_type not set on Response\"\n        assert context is not None, \".renderer_context not set on Response\"\n        context['response'] = self\n\n        media_type = renderer.media_type\n        charset = renderer.charset\n        content_type = self.content_type\n\n        if content_type is None and charset is not None:\n            content_type = f\"{media_type}; charset={charset}\"\n        elif content_type is None:\n            content_type = media_type\n        self['Content-Type'] = content_type\n\n        ret = renderer.render(self.data, accepted_media_type, context)\n        if isinstance(ret, str):\n            assert charset, (\n                'renderer returned unicode, and did not specify '\n                'a charset value.'\n            )\n            return ret.encode(charset)\n\n        if not ret:\n            del self['Content-Type']\n\n        return ret\n\n    @property\n    def status_text(self):\n        \"\"\"\n        Returns reason text corresponding to our HTTP response status code.\n        Provided for convenience.\n        \"\"\"\n        return responses.get(self.status_code, '')\n\n    def __getstate__(self):\n        \"\"\"\n        Remove attributes from the response that shouldn't be cached.\n        \"\"\"\n        state = super().__getstate__()\n        for key in (\n            'accepted_renderer', 'renderer_context', 'resolver_match',\n            'client', 'request', 'json', 'wsgi_request'\n        ):\n            if key in state:\n                del state[key]\n        state['_closable_objects'] = []\n        return state",
      "program_specification": "```dafny\n// Dafny translation of the Python Response class, focusing on simplicity and verifiability.\n\nmodule ResponseModule {\n\n  // Simple placeholder for Serializer type\n  class Serializer {}\n\n  // Simple placeholder for a renderer object\n  class Renderer {\n    var media_type: string;\n    var charset: string?;\n    constructor(mt: string, cs: string?) \n      ensures media_type == mt && charset == cs\n    {\n      media_type := mt;\n      charset := cs;\n    }\n    // Simulate the render function\n    method Render(data: object, accepted_media_type: string?, context: map<string, object>) returns (ret: object)\n      ensures true\n    {\n      // For simplicity, just return data\n      ret := data;\n    }\n  }\n\n  // SimpleTemplateResponse base class\n  class SimpleTemplateResponse {\n    var status: int?;\n    var headers: map<string, string>;\n    var status_code: int;\n\n    constructor(template_name: string?, status: int?)\n      ensures this.status == status\n      ensures headers == map[]\n      ensures status_code == if status == null then 200 else status\n    {\n      this.status := status;\n      this.headers := map[];\n      this.status_code := if status == null then 200 else status;\n    }\n\n    // Indexer for headers\n    method set_Header(name: string, value: string)\n      modifies this\n      ensures headers[name] == value\n    {\n      headers := headers[name := value];\n    }\n\n    method del_Header(name: string)\n      modifies this\n      ensures name !in headers\n    {\n      if name in headers {\n        headers := headers - {name};\n      }\n    }\n  }\n\n  // Static responses dictionary for status codes\n  datatype Responses = ResponsesMap(map: map<int, string>)\n\n  // Response class\n  class Response extends SimpleTemplateResponse {\n    var data: object?;\n    var template_name: string?;\n    var exception: bool;\n    var content_type: string?;\n    var accepted_renderer: Renderer?;\n    var accepted_media_type: string?;\n    var renderer_context: map<string, object>?;\n    // For simplicity, headers are inherited from base\n\n    constructor(\n      data: object?,\n      status: int?,\n      template_name: string?,\n      headers: map<string, string>?,\n      exception: bool,\n      content_type: string?\n      )\n      requires forall k :: headers == null || k in headers ==> headers[k].Length >= 0\n      ensures this.data == data\n      ensures this.template_name == template_name\n      ensures this.exception == exception\n      ensures this.content_type == content_type\n    {\n      // Call base constructor with template_name dropped (None)\n      SimpleTemplateResponse.__ctor(this, null, status);\n\n      // Assert data is not a Serializer instance\n      if data != null && data is Serializer {\n        // In Dafny, we raise an error by using assert false\n        assert false;\n      }\n\n      this.data := data;\n      this.template_name := template_name;\n      this.exception := exception;\n      this.content_type := content_type;\n\n      // Set headers if provided\n      if headers != null {\n        var keys := headers.Keys;\n        var i: int := 0;\n        while i < |keys|\n          invariant 0 <= i <= |keys|\n          modifies this\n        {\n          var name := keys[i];\n          var value := headers[name];\n          this.set_Header(name, value);\n          i := i + 1;\n        }\n      }\n    }\n\n    // Simulate __class_getitem__ as identity\n    static method ClassGetItem(cls: type, args: seq<type>) returns (t: type)\n      ensures t == cls\n    {\n      t := cls;\n    }\n\n    // Rendered content property\n    method GetRenderedContent() returns (ret: object)\n      requires accepted_renderer != null\n      requires accepted_media_type != null\n      requires renderer_context != null\n      modifies this\n      ensures true\n    {\n      var renderer := accepted_renderer;\n      var accepted_media_type := accepted_media_type;\n      var context := renderer_context;\n\n      // context['response'] = self\n      context := context[\"response\" := this];\n\n      var media_type := renderer.media_type;\n      var charset := renderer.charset;\n      var content_type := this.content_type;\n\n      if content_type == null && charset != null {\n        content_type := media_type + \"; charset=\" + charset;\n      } else if content_type == null {\n        content_type := media_type;\n      }\n      this.set_Header(\"Content-Type\", content_type);\n\n      var rendered: object;\n      renderer.Render(this.data, accepted_media_type, context);\n      rendered := this.data;\n\n      // For simplicity, we don't distinguish between string and bytes\n      // Remove Content-Type if rendered is \"empty\"\n      if rendered == null {\n        this.del_Header(\"Content-Type\");\n      }\n\n      ret := rendered;\n    }\n\n    // Status text property\n    method StatusText(responses: map<int, string>) returns (text: string)\n      ensures text == if this.status_code in responses then responses[this.status_code] else \"\"\n    {\n      if this.status_code in responses {\n        text := responses[this.status_code];\n      } else {\n        text := \"\";\n      }\n    }\n\n    // __getstate__ method\n    method GetState(super_state: map<string, object>) returns (state: map<string, object>)\n      modifies this\n      ensures forall k :: k in state ==> k != \"accepted_renderer\" && k != \"renderer_context\" && k != \"resolver_match\" && k != \"client\" && k != \"request\" && k != \"json\" && k != \"wsgi_request\"\n      ensures \"_closable_objects\" in state\n    {\n      var state := super_state;\n      var keys_to_remove := {\"accepted_renderer\", \"renderer_context\", \"resolver_match\", \"client\", \"request\", \"json\", \"wsgi_request\"};\n      var keys := state.Keys;\n      var i: int := 0;\n      while i < |keys|\n        invariant 0 <= i <= |keys|\n        modifies state\n      {\n        var key := keys[i];\n        if key in keys_to_remove {\n          state := state - {key};\n        }\n        i := i + 1;\n      }\n      state := state[\"_closable_objects\" := []];\n      return state;\n    }\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 14.75,
        "duration_formatted": "14.75s",
        "tokens": {
          "input": 765,
          "output": 1324,
          "total": 2089
        },
        "cost_usd": 0.012122,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:35:24.048031"
      }
    },
    {
      "file_path": "snippet_10.py",
      "code": "'''\nGiven an array A of 0s and 1s, we may change up to K values from 0 to 1.\n\nReturn the length of the longest (contiguous) subarray that contains only 1s. \n\n \n\nExample 1:\n\nInput: A = [1,1,1,0,0,0,1,1,1,1,0], K = 2\nOutput: 6\nExplanation: \n[1,1,1,0,0,1,1,1,1,1,1]\nBolded numbers were flipped from 0 to 1.  The longest subarray is underlined.\nExample 2:\n\nInput: A = [0,0,1,1,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1], K = 3\nOutput: 10\nExplanation: \n[0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1]\nBolded numbers were flipped from 0 to 1.  The longest subarray is underlined.\n \n\nNote:\n\n1 <= A.length <= 20000\n0 <= K <= A.length\nA[i] is 0 or 1 \n'''\n\nclass Solution(object):\n    def longestOnes(self, A, K):\n        \"\"\"\n        :type A: List[int]\n        :type K: int\n        :rtype: int\n        \"\"\"\n        start_index = 0\n        for end_index in range(0, len(A)):\n            K -= 1-A[end_index]\n            if K < 0:\n                K += 1-A[start_index]\n                start_index += 1\n        return end_index-start_index+1",
      "program_specification": "```dafny\nmethod LongestOnes(A: array<int>, K: int) returns (maxLen: int)\n    requires A != null\n    requires 1 <= A.Length <= 20000\n    requires 0 <= K <= A.Length\n    requires forall i :: 0 <= i < A.Length ==> (A[i] == 0 || A[i] == 1)\n    ensures 0 <= maxLen <= A.Length\n    ensures forall i, j :: 0 <= i <= j < A.Length ==>\n        (CountZeros(A, i, j) <= K ==> maxLen >= j - i + 1)\n    ensures exists i, j :: 0 <= i <= j < A.Length && CountZeros(A, i, j) <= K && maxLen == j - i + 1\n{\n    var start_index := 0;\n    var end_index := 0;\n    var zeros_flipped := 0;\n    maxLen := 0;\n\n    while end_index < A.Length\n        invariant 0 <= start_index <= end_index <= A.Length\n        invariant 0 <= zeros_flipped <= end_index - start_index\n        invariant zeros_flipped == CountZeros(A, start_index, end_index - 1)\n        invariant 0 <= maxLen <= A.Length\n        invariant forall i, j :: 0 <= i <= j < end_index ==>\n            (CountZeros(A, i, j) <= K ==> maxLen >= j - i + 1)\n    {\n        if A[end_index] == 0 {\n            zeros_flipped := zeros_flipped + 1;\n        }\n        while zeros_flipped > K\n            invariant 0 <= start_index <= end_index < A.Length\n            invariant 0 <= zeros_flipped <= end_index - start_index + 1\n            invariant zeros_flipped == CountZeros(A, start_index, end_index)\n        {\n            if A[start_index] == 0 {\n                zeros_flipped := zeros_flipped - 1;\n            }\n            start_index := start_index + 1;\n        }\n        if end_index - start_index + 1 > maxLen {\n            maxLen := end_index - start_index + 1;\n        }\n        end_index := end_index + 1;\n    }\n}\n\nfunction CountZeros(A: array<int>, i: int, j: int): nat\n    requires A != null && 0 <= i <= j < A.Length\n{\n    if i > j then 0\n    else (if A[i] == 0 then 1 else 0) + CountZeros(A, i + 1, j)\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.478,
        "duration_formatted": "8.48s",
        "tokens": {
          "input": 468,
          "output": 549,
          "total": 1017
        },
        "cost_usd": 0.005328,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:35:37.582262"
      }
    },
    {
      "file_path": "snippet_11.py",
      "code": "'''\n\tSort a linked list in O(n log n) time using constant space complexity.\n\n\tExample 1:\n\n\tInput: 4->2->1->3\n\tOutput: 1->2->3->4\n'''\n\n# Definition for singly-linked list.\n# class ListNode(object):\n#     def __init__(self, x):\n#         self.val = x\n#         self.next = None\n\nclass Solution(object):\n    def sortList(self, head):\n        \"\"\"\n        :type head: ListNode\n        :rtype: ListNode\n        \"\"\"\n\n        if not head or not head.next:\n        \treturn head\n\n        slow, fast = head, head.next\n\n        while fast.next and fast.next.next:\n        \tslow = slow.next\n        \tfast = fast.next.next\n\n        head1, head2 = head, slow.next\n        slow.next = None\n        head1 = self.sortList(head1)\n        head2 = self.sortList(head2)\n        head = self.merge(head1, head2)\n        return head\n\n    def merge(self, head1, head2):\n    \tif not head1:\n    \t\treturn head2\n    \tif not head2:\n    \t\treturn head1\n\n    \tresult = ListNode(0)\n    \tp = result\n\n    \twhile head1 and head2:\n    \t\tif head1.val <= head2.val:\n    \t\t\tp.next = ListNode(head1.val)\n    \t\t\thead1 = head1.next\n    \t\t\tp = p.next\n    \t\telse:\n    \t\t\tp.next = ListNode(head2.val)\n    \t\t\thead2 = head2.next\n    \t\t\tp = p.next\n\n    \tif head1:\n    \t\tp.next = head1\n    \tif head2:\n    \t\tp.next = head2\n    \treturn result.next",
      "program_specification": "```dafny\n// Dafny translation of Python's linked list sort (merge sort)\n// Focused on simplicity and verifiability\n\nclass ListNode {\n  var val: int;\n  var next: ListNode?;\n\n  constructor(v: int) \n    ensures val == v && next == null\n  {\n    val := v;\n    next := null;\n  }\n}\n\npredicate Acyclic(l: ListNode?)\n  decreases l\n{\n  l == null || l !in Reach(l.next) && Acyclic(l.next)\n}\n\nfunction Reach(l: ListNode?): set<ListNode>\n  decreases l\n{\n  if l == null then {} else {l} + Reach(l.next)\n}\n\nfunction ListValues(l: ListNode?): seq<int>\n  decreases l\n{\n  if l == null then [] else [l.val] + ListValues(l.next)\n}\n\nmethod Merge(head1: ListNode?, head2: ListNode?) returns (res: ListNode?)\n  requires Acyclic(head1) && Acyclic(head2)\n  ensures Acyclic(res)\n  ensures multiset(ListValues(res)) == multiset(ListValues(head1)) + multiset(ListValues(head2))\n  ensures ListValues(res) == SeqSort(ListValues(res))\n{\n  var dummy := new ListNode(0);\n  var p := dummy;\n  var h1 := head1;\n  var h2 := head2;\n  while h1 != null && h2 != null\n    invariant Acyclic(h1) && Acyclic(h2) && Acyclic(dummy)\n    invariant p in Reach(dummy)\n    invariant multiset(ListValues(dummy.next)) + multiset(ListValues(h1)) + multiset(ListValues(h2)) == multiset(ListValues(head1)) + multiset(ListValues(head2))\n    decreases |ListValues(h1)| + |ListValues(h2)|\n  {\n    if h1.val <= h2.val {\n      p.next := new ListNode(h1.val);\n      p := p.next;\n      h1 := h1.next;\n    } else {\n      p.next := new ListNode(h2.val);\n      p := p.next;\n      h2 := h2.next;\n    }\n  }\n  if h1 != null {\n    p.next := h1;\n  } else if h2 != null {\n    p.next := h2;\n  }\n  res := dummy.next;\n}\n\nmethod SortList(head: ListNode?) returns (res: ListNode?)\n  requires Acyclic(head)\n  ensures Acyclic(res)\n  ensures multiset(ListValues(res)) == multiset(ListValues(head))\n  ensures ListValues(res) == SeqSort(ListValues(res))\n{\n  if head == null || head.next == null {\n    res := head;\n    return;\n  }\n  // Find the middle (slow/fast pointer)\n  var slow := head;\n  var fast := head.next;\n  while fast != null && fast.next != null\n    invariant Acyclic(head)\n    invariant slow in Reach(head)\n    invariant fast in Reach(head)\n    decreases |ListValues(fast)|\n  {\n    slow := slow.next;\n    fast := fast.next.next;\n  }\n  var head1 := head;\n  var head2 := slow.next;\n  slow.next := null;\n  head1 := SortList(head1);\n  head2 := SortList(head2);\n  res := Merge(head1, head2);\n}\n\n// Helper function: returns a sorted version of a sequence\nfunction SeqSort(s: seq<int>): seq<int>\n  decreases s\n{\n  if |s| <= 1 then s\n  else\n    var pivot := s[0];\n    SeqSort([x | x in s[1..], x < pivot]) + [pivot] + SeqSort([x | x in s[1..], x >= pivot])\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 18.553,
        "duration_formatted": "18.55s",
        "tokens": {
          "input": 440,
          "output": 797,
          "total": 1237
        },
        "cost_usd": 0.007256,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:36:01.175174"
      }
    },
    {
      "file_path": "snippet_12.py",
      "code": "'''\nOn a broken calculator that has a number showing on its display, we can perform two operations:\n\nDouble: Multiply the number on the display by 2, or;\nDecrement: Subtract 1 from the number on the display.\nInitially, the calculator is displaying the number X.\n\nReturn the minimum number of operations needed to display the number Y.\n\n \n\nExample 1:\n\nInput: X = 2, Y = 3\nOutput: 2\nExplanation: Use double operation and then decrement operation {2 -> 4 -> 3}.\n'''\n\nclass Solution(object):\n    def brokenCalc(self, X, Y):\n        \"\"\"\n        :type X: int\n        :type Y: int\n        :rtype: int\n        \"\"\"\n        if X == Y:\n            return 0\n        if X > Y:\n            return X-Y\n        if(Y%2 == 1):\n            return 1 + self.brokenCalc(X, Y+1)\n        else:\n            return 1 + self.brokenCalc(X, Y/2)",
      "program_specification": "```dafny\nmethod brokenCalc(X: int, Y: int) returns (ops: int)\n    requires X > 0 && Y > 0\n    ensures ops >= 0\n    ensures X == Y ==> ops == 0\n    ensures X > Y ==> ops == X - Y\n    // For all X, Y > 0, ops is the minimum number of operations to turn X into Y\n{\n    if X == Y {\n        ops := 0;\n        return;\n    }\n    if X > Y {\n        ops := X - Y;\n        return;\n    }\n    if Y % 2 == 1 {\n        ops := 1 + brokenCalc(X, Y + 1);\n        return;\n    } else {\n        ops := 1 + brokenCalc(X, Y / 2);\n        return;\n    }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 2.794,
        "duration_formatted": "2.79s",
        "tokens": {
          "input": 296,
          "output": 177,
          "total": 473
        },
        "cost_usd": 0.002008,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:36:09.010879"
      }
    },
    {
      "file_path": "snippet_13.py",
      "code": "'''\nGiven an array A of positive integers (not necessarily distinct), return the lexicographically largest permutation that is smaller than A, that can be made with one swap (A swap exchanges the positions of two numbers A[i] and A[j]).  If it cannot be done, then return the same array.\n\n \n\nExample 1:\n\nInput: [3,2,1]\nOutput: [3,1,2]\nExplanation: Swapping 2 and 1.\nExample 2:\n\nInput: [1,1,5]\nOutput: [1,1,5]\nExplanation: This is already the smallest permutation.\nExample 3:\n\nInput: [1,9,4,6,7]\nOutput: [1,7,4,6,9]\nExplanation: Swapping 9 and 7.\nExample 4:\n\nInput: [3,1,1,3]\nOutput: [1,3,1,3]\nExplanation: Swapping 1 and 3.\n \n\nNote:\n\n1 <= A.length <= 10000\n1 <= A[i] <= 10000\n'''\nclass Solution(object):\n    def prevPermOpt1(self, A):\n        \"\"\"\n        :type A: List[int]\n        :rtype: List[int]\n        \"\"\"\n    \n        left, right = len(A)-2, len(A)-1\n        for left in range(len(A)-2, -1, -1):\n            if A[left] > A[left+1]:\n                break\n        else:\n            return A\n        right = A.index(max(ele for ele in A[left+1:] if ele < A[left]), left)\n        A[left], A[right] = A[right], A[left]\n        return A",
      "program_specification": "```dafny\n// Dafny translation of prevPermOpt1 with formal specifications.\n\nmethod prevPermOpt1(A: array<int>) returns (B: array<int>)\n    requires A != null && 1 <= A.Length <= 10000\n    requires forall i :: 0 <= i < A.Length ==> 1 <= A[i] <= 10000\n    ensures B.Length == A.Length\n    ensures forall i :: 0 <= i < A.Length ==> 1 <= B[i] <= 10000\n    ensures multiset(B[..]) == multiset(A[..])\n    ensures\n      // If possible, B is lexicographically largest permutation smaller than A by one swap\n      (exists i, j :: 0 <= i < j < A.Length && B[..] == Swap(A[..], i, j) && B[..] < A[..] &&\n        forall C :: C == Swap(A[..], i, j) && C < A[..] ==> C <= B[..])\n      ||\n      // Otherwise, B == A\n      B[..] == A[..]\n{\n    var n := A.Length;\n    var arr := new int[n];\n    // Copy A to arr\n    var i := 0;\n    while i < n\n        invariant 0 <= i <= n\n        invariant forall k :: 0 <= k < i ==> arr[k] == A[k]\n    {\n        arr[i] := A[i];\n        i := i + 1;\n    }\n\n    var left := n - 2;\n    var found := false;\n    while left >= 0\n        invariant -1 <= left < n\n        decreases left\n    {\n        if arr[left] > arr[left+1] {\n            found := true;\n            break;\n        }\n        left := left - 1;\n    }\n    if !found {\n        // Already smallest permutation\n        B := arr;\n        return;\n    }\n\n    // Find the largest element less than arr[left] in arr[left+1..]\n    var maxVal := -1;\n    var right := -1;\n    var j := left + 1;\n    while j < n\n        invariant left+1 <= j <= n\n        invariant (right == -1) || (left+1 <= right < j)\n        invariant (right == -1) || (arr[right] < arr[left] && arr[right] == maxVal)\n        decreases n - j\n    {\n        if arr[j] < arr[left] && arr[j] > maxVal {\n            maxVal := arr[j];\n            right := j;\n        }\n        j := j + 1;\n    }\n    // Find the leftmost such maxVal (in case of duplicates)\n    if right != -1 {\n        var k := left + 1;\n        while k < n\n            invariant left+1 <= k <= n\n            invariant (right == -1) || (arr[right] == maxVal)\n            decreases n - k\n        {\n            if arr[k] == maxVal {\n                right := k;\n                break;\n            }\n            k := k + 1;\n        }\n        // Swap arr[left] and arr[right]\n        var tmp := arr[left];\n        arr[left] := arr[right];\n        arr[right] := tmp;\n    }\n    B := arr;\n}\n\n// Helper function: swap elements at i and j in seq s\nfunction method Swap(s: seq<int>, i: int, j: int): seq<int>\n    requires 0 <= i < j < |s|\n{\n    s[..i] + [s[j]] + s[i+1..j] + [s[i]] + s[j+1..]\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.917,
        "duration_formatted": "11.92s",
        "tokens": {
          "input": 434,
          "output": 765,
          "total": 1199
        },
        "cost_usd": 0.006988,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:36:26.041743"
      }
    },
    {
      "file_path": "snippet_14.py",
      "code": "import copy\n\nimport numpy as np\nfrom packaging.version import Version\n\nfrom .._shared.filters import gaussian\nfrom .._shared.utils import check_nD\nfrom .brief_cy import _brief_loop\nfrom .util import (\n    DescriptorExtractor,\n    _mask_border_keypoints,\n    _prepare_grayscale_input_2D,\n)\n\n\nnp2 = Version(np.__version__) >= Version('2')\n\n\nclass BRIEF(DescriptorExtractor):\n    \"\"\"BRIEF binary descriptor extractor.\n\n    BRIEF (Binary Robust Independent Elementary Features) is an efficient\n    feature point descriptor. It is highly discriminative even when using\n    relatively few bits and is computed using simple intensity difference\n    tests.\n\n    For each keypoint, intensity comparisons are carried out for a specifically\n    distributed number N of pixel-pairs resulting in a binary descriptor of\n    length N. For binary descriptors the Hamming distance can be used for\n    feature matching, which leads to lower computational cost in comparison to\n    the L2 norm.\n\n    Parameters\n    ----------\n    descriptor_size : int, optional\n        Size of BRIEF descriptor for each keypoint. Sizes 128, 256 and 512\n        recommended by the authors. Default is 256.\n    patch_size : int, optional\n        Length of the two dimensional square patch sampling region around\n        the keypoints. Default is 49.\n    mode : {'normal', 'uniform'}, optional\n        Probability distribution for sampling location of decision pixel-pairs\n        around keypoints.\n    rng : {`numpy.random.Generator`, int}, optional\n        Pseudo-random number generator (RNG).\n        By default, a PCG64 generator is used (see :func:`numpy.random.default_rng`).\n        If `rng` is an int, it is used to seed the generator.\n\n        The PRNG is used for the random sampling of the decision\n        pixel-pairs. From a square window with length `patch_size`,\n        pixel pairs are sampled using the `mode` parameter to build\n        the descriptors using intensity comparison.\n\n        For matching across images, the same `rng` should be used to construct\n        descriptors. To facilitate this:\n\n        (a) `rng` defaults to 1\n        (b) Subsequent calls of the ``extract`` method will use the same rng/seed.\n    sigma : float, optional\n        Standard deviation of the Gaussian low-pass filter applied to the image\n        to alleviate noise sensitivity, which is strongly recommended to obtain\n        discriminative and good descriptors.\n\n    Attributes\n    ----------\n    descriptors : (Q, `descriptor_size`) array of dtype bool\n        2D ndarray of binary descriptors of size `descriptor_size` for Q\n        keypoints after filtering out border keypoints with value at an\n        index ``(i, j)`` either being ``True`` or ``False`` representing\n        the outcome of the intensity comparison for i-th keypoint on j-th\n        decision pixel-pair. It is ``Q == np.sum(mask)``.\n    mask : (N,) array of dtype bool\n        Mask indicating whether a keypoint has been filtered out\n        (``False``) or is described in the `descriptors` array (``True``).\n\n    Examples\n    --------\n    >>> from skimage.feature import (corner_harris, corner_peaks, BRIEF,\n    ...                              match_descriptors)\n    >>> import numpy as np\n    >>> square1 = np.zeros((8, 8), dtype=np.int32)\n    >>> square1[2:6, 2:6] = 1\n    >>> square1\n    array([[0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)\n    >>> square2 = np.zeros((9, 9), dtype=np.int32)\n    >>> square2[2:7, 2:7] = 1\n    >>> square2\n    array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)\n    >>> keypoints1 = corner_peaks(corner_harris(square1), min_distance=1)\n    >>> keypoints2 = corner_peaks(corner_harris(square2), min_distance=1)\n    >>> extractor = BRIEF(patch_size=5)\n    >>> extractor.extract(square1, keypoints1)\n    >>> descriptors1 = extractor.descriptors\n    >>> extractor.extract(square2, keypoints2)\n    >>> descriptors2 = extractor.descriptors\n    >>> matches = match_descriptors(descriptors1, descriptors2)\n    >>> matches\n    array([[0, 0],\n           [1, 1],\n           [2, 2],\n           [3, 3]])\n    >>> keypoints1[matches[:, 0]]\n    array([[2, 2],\n           [2, 5],\n           [5, 2],\n           [5, 5]])\n    >>> keypoints2[matches[:, 1]]\n    array([[2, 2],\n           [2, 6],\n           [6, 2],\n           [6, 6]])\n\n    \"\"\"\n\n    def __init__(\n        self, descriptor_size=256, patch_size=49, mode='normal', sigma=1, rng=1\n    ):\n        mode = mode.lower()\n        if mode not in ('normal', 'uniform'):\n            raise ValueError(\"`mode` must be 'normal' or 'uniform'.\")\n\n        self.descriptor_size = descriptor_size\n        self.patch_size = patch_size\n        self.mode = mode\n        self.sigma = sigma\n\n        if isinstance(rng, np.random.Generator):\n            # Spawn an independent RNG from parent RNG provided by the user.\n            # This is necessary so that we can safely deepcopy the RNG.\n            # See https://github.com/scikit-learn/scikit-learn/issues/16988#issuecomment-1518037853\n            bg = rng._bit_generator\n            ss = bg._seed_seq\n            (child_ss,) = ss.spawn(1)\n            self.rng = np.random.Generator(type(bg)(child_ss))\n        elif rng is None:\n            self.rng = np.random.default_rng(np.random.SeedSequence())\n        else:\n            self.rng = np.random.default_rng(rng)\n\n        self.descriptors = None\n        self.mask = None\n\n    def extract(self, image, keypoints):\n        \"\"\"Extract BRIEF binary descriptors for given keypoints in image.\n\n        Parameters\n        ----------\n        image : 2D array\n            Input image.\n        keypoints : (N, 2) array\n            Keypoint coordinates as ``(row, col)``.\n\n        \"\"\"\n        check_nD(image, 2)\n\n        # Copy RNG so we can repeatedly call extract with the same random values\n        rng = copy.deepcopy(self.rng)\n\n        image = _prepare_grayscale_input_2D(image)\n\n        # Gaussian low-pass filtering to alleviate noise sensitivity\n        image = np.ascontiguousarray(gaussian(image, sigma=self.sigma, mode='reflect'))\n\n        # Sampling pairs of decision pixels in patch_size x patch_size window\n        desc_size = self.descriptor_size\n        patch_size = self.patch_size\n        if self.mode == 'normal':\n            samples = (patch_size / 5.0) * rng.standard_normal(desc_size * 8)\n            samples = np.array(samples, dtype=np.int32)\n            samples = samples[\n                (samples < (patch_size // 2)) & (samples > -(patch_size - 2) // 2)\n            ]\n\n            pos1 = samples[: desc_size * 2].reshape(desc_size, 2)\n            pos2 = samples[desc_size * 2 : desc_size * 4].reshape(desc_size, 2)\n        elif self.mode == 'uniform':\n            samples = rng.integers(\n                -(patch_size - 2) // 2, (patch_size // 2) + 1, (desc_size * 2, 2)\n            )\n            samples = np.array(samples, dtype=np.int32)\n            pos1, pos2 = np.split(samples, 2)\n\n        pos1 = np.ascontiguousarray(pos1)\n        pos2 = np.ascontiguousarray(pos2)\n\n        # Removing keypoints that are within (patch_size / 2) distance from the\n        # image border\n        self.mask = _mask_border_keypoints(image.shape, keypoints, patch_size // 2)\n\n        keypoints = np.array(\n            keypoints[self.mask, :],\n            dtype=np.int64,\n            order='C',\n            copy=None if np2 else False,\n        )\n\n        self.descriptors = np.zeros(\n            (keypoints.shape[0], desc_size), dtype=bool, order='C'\n        )\n\n        _brief_loop(image, self.descriptors.view(np.uint8), keypoints, pos1, pos2)",
      "program_specification": "```dafny\n// Dafny translation of a simplified and verifiable subset of the BRIEF class and its extract method.\n// Focus is on the main logic and structure, omitting advanced numpy and random generator features.\n\nmodule BRIEFModule {\n\n  // Helper function: clamp to valid range for patch sampling\n  function Clamp(x: int, min: int, max: int): int\n    ensures min <= Clamp(x, min, max) <= max\n  {\n    if x < min then min else if x > max then max else x\n  }\n\n  // Helper predicate: is a keypoint inside the valid patch area\n  predicate IsKeypointValid(imageRows: int, imageCols: int, row: int, col: int, patchHalf: int)\n    reads {}\n  {\n    patchHalf <= row < imageRows - patchHalf &&\n    patchHalf <= col < imageCols - patchHalf\n  }\n\n  // DescriptorExtractor base class (empty, for structure)\n  class DescriptorExtractor {\n  }\n\n  // Main BRIEF class\n  class BRIEF extends DescriptorExtractor {\n    var descriptor_size: nat\n    var patch_size: nat\n    var mode: string\n    var sigma: real\n    var descriptors: array2<bool>?\n    var mask: array<bool>?\n\n    constructor(descriptor_size: nat, patch_size: nat, mode: string, sigma: real)\n      requires descriptor_size > 0\n      requires patch_size > 0\n      requires mode == \"normal\" || mode == \"uniform\"\n      requires sigma > 0.0\n    {\n      this.descriptor_size := descriptor_size;\n      this.patch_size := patch_size;\n      this.mode := mode;\n      this.sigma := sigma;\n      this.descriptors := null;\n      this.mask := null;\n    }\n\n    // Main extract method, simplified for Dafny\n    method extract(image: array2<int>, keypoints: array2<int>)\n      requires image.Length0 > 0 && image.Length1 > 0\n      requires keypoints.Length1 == 2\n      modifies this\n      ensures this.descriptors != null ==> this.descriptors.Length0 <= keypoints.Length0\n      ensures this.mask != null ==> this.mask.Length == keypoints.Length0\n    {\n      var rows := image.Length0;\n      var cols := image.Length1;\n      var nKeypoints := keypoints.Length0;\n      var desc_size := this.descriptor_size;\n      var patch_size := this.patch_size;\n      var patch_half: int := patch_size / 2;\n\n      // Step 1: Filter keypoints near border\n      var mask := new bool[nKeypoints];\n      var validCount := 0;\n      var i := 0;\n      while i < nKeypoints\n        invariant 0 <= i <= nKeypoints\n        invariant 0 <= validCount <= i\n        invariant forall j :: 0 <= j < i ==> mask[j] == IsKeypointValid(rows, cols, keypoints[j,0], keypoints[j,1], patch_half)\n      {\n        if IsKeypointValid(rows, cols, keypoints[i,0], keypoints[i,1], patch_half) {\n          mask[i] := true;\n          validCount := validCount + 1;\n        } else {\n          mask[i] := false;\n        }\n        i := i + 1;\n      }\n      this.mask := mask;\n\n      // Step 2: Collect valid keypoints\n      var validKeypoints := new int[validCount, 2];\n      var vk := 0;\n      i := 0;\n      while i < nKeypoints\n        invariant 0 <= i <= nKeypoints\n        invariant 0 <= vk <= validCount\n        invariant forall j :: 0 <= j < vk ==> mask[j] ==> validKeypoints[j,0] == keypoints[j,0] && validKeypoints[j,1] == keypoints[j,1]\n      {\n        if mask[i] {\n          validKeypoints[vk,0] := keypoints[i,0];\n          validKeypoints[vk,1] := keypoints[i,1];\n          vk := vk + 1;\n        }\n        i := i + 1;\n      }\n\n      // Step 3: Allocate descriptors\n      var descriptors := new bool[validCount, desc_size];\n      // Step 4: For each valid keypoint, fill descriptor with dummy values (e.g., false)\n      i := 0;\n      while i < validCount\n        invariant 0 <= i <= validCount\n      {\n        var j := 0;\n        while j < desc_size\n          invariant 0 <= j <= desc_size\n        {\n          descriptors[i, j] := false; // Placeholder for intensity comparison\n          j := j + 1;\n        }\n        i := i + 1;\n      }\n      this.descriptors := descriptors;\n    }\n  }\n\n  // Array2 type definition for 2D arrays\n  datatype array2<T> = Array2(array: array<array<T>>)\n    function Length0(a: array2<T>): nat\n      { |a.Array2.array| }\n    function Length1(a: array2<T>): nat\n      requires a.Array2.array.Length > 0\n      { |a.Array2.array[0]| }\n    function Index(a: array2<T>, i: nat, j: nat): T\n      requires i < a.Length0 && j < a.Length1\n      { a.Array2.array[i][j] }\n  // (For practical use, replace array2<T> with native Dafny 2D arrays.)\n\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 27.836,
        "duration_formatted": "27.84s",
        "tokens": {
          "input": 2345,
          "output": 1169,
          "total": 3514
        },
        "cost_usd": 0.014042,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:36:58.920428"
      }
    },
    {
      "file_path": "snippet_15.py",
      "code": "\"\"\"\nAPIs related to torch.compile which lazily import torch._dynamo to avoid\ncircular dependencies.\n\"\"\"\n\nimport functools\nfrom typing import Callable, Literal, Optional, overload, TypeVar, Union\nfrom typing_extensions import ParamSpec\n\n\n_T = TypeVar(\"_T\")\n_P = ParamSpec(\"_P\")\n\n\n@overload\ndef _disable_dynamo(\n    fn: Callable[_P, _T], recursive: bool = True\n) -> Callable[_P, _T]: ...\n\n\n@overload\ndef _disable_dynamo(\n    fn: Literal[None] = None, recursive: bool = True\n) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]: ...\n\n\ndef _disable_dynamo(\n    fn: Optional[Callable[_P, _T]] = None, recursive: bool = True\n) -> Union[Callable[_P, _T], Callable[[Callable[_P, _T]], Callable[_P, _T]]]:\n    \"\"\"\n    This API should be only used inside torch, external users should still use\n    torch._dynamo.disable. The main goal of this API is to avoid circular\n    imports issues that is common while using _dynamo.disable inside torch\n    itself.\n\n    This API avoids it by lazily importing torch._dynamo from the import time to\n    the invocation of the decorated function.\n    \"\"\"\n    if fn is not None:\n\n        @functools.wraps(fn)\n        def inner(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n            # cache this on the first invocation to avoid adding too much overhead.\n            disable_fn = getattr(fn, \"__dynamo_disable\", None)\n            if disable_fn is None:\n                import torch._dynamo\n\n                # We can safely turn off functools.wraps here because the inner\n                # already wraps fn in the outer scope.\n                disable_fn = torch._dynamo.disable(fn, recursive, wrapping=False)\n                fn.__dynamo_disable = disable_fn  # type: ignore[attr-defined]\n\n            return disable_fn(*args, **kwargs)\n\n        return inner\n    else:\n        # decorator usage like @_disable_dynamo(recursive=False). The resulting\n        # object expects the original decorated function as the arg.\n        return functools.partial(_disable_dynamo, recursive=recursive)",
      "program_specification": "```dafny\n// Dafny translation of the Python _disable_dynamo function.\n// Focused on simplicity and verifiability.\n\nmodule TorchCompile {\n\n  // We model a generic function type\n  type Func<A, R> = A -> R\n\n  // A wrapper type to represent optional values\n  datatype Option<T> = None | Some(value: T)\n\n  // The _disable_dynamo function is a decorator that can be used in two ways:\n  //   1. Directly on a function (fn != null)\n  //   2. As a decorator factory (fn == null)\n  //\n  // We model this by using Option<Func<A, R>> for the fn argument,\n  // and returning either a decorated function or a decorator.\n\n  // For simplicity, we restrict to functions with one argument of type A and return type R.\n\n  // The \"dynamo disable\" operation is modeled as a function that wraps another function.\n  function method DynamoDisable<A, R>(f: Func<A, R>, recursive: bool): Func<A, R>\n    ensures forall x: A :: DynamoDisable(f, recursive)(x) == f(x)\n  {\n    f // In this model, disabling does nothing.\n  }\n\n  // The decorator function\n  method _disable_dynamo<A, R>(\n      fn: Option<Func<A, R>>, recursive: bool\n    ) returns (res: if fn.None? then Func<Func<A, R>, Func<A, R>> else Func<A, R>)\n    requires true\n    ensures fn.None? ==>\n      (forall f: Func<A, R> :: res(f) == DynamoDisable(f, recursive))\n    ensures fn.Some? ==>\n      (forall x: A :: res(x) == DynamoDisable(fn.Some.value, recursive)(x))\n  {\n    if fn.Some? {\n      // Case 1: fn is provided, decorate it\n      return DynamoDisable(fn.Some.value, recursive);\n    } else {\n      // Case 2: decorator usage, return a decorator function\n      return (f: Func<A, R>) => DynamoDisable(f, recursive);\n    }\n  }\n\n  // Example usage:\n  method ExampleUsage() {\n    var f := (x: int) => x + 1;\n    var decorated := _disable_dynamo<int, int>(Some(f), true);\n    assert decorated(3) == 4;\n\n    var decorator := _disable_dynamo<int, int>(None, false);\n    var g := decorator(f);\n    assert g(5) == 6;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 10.374,
        "duration_formatted": "10.37s",
        "tokens": {
          "input": 562,
          "output": 531,
          "total": 1093
        },
        "cost_usd": 0.005372,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:37:14.334845"
      }
    },
    {
      "file_path": "snippet_16.py",
      "code": "#   Copyright 2024 - present The PyMC Developers\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\nimport warnings\n\nfrom collections.abc import Callable\n\nimport numpy as np\nimport pytensor.tensor as pt\n\nfrom pytensor.gradient import NullTypeGradError\nfrom scipy import optimize\n\nimport pymc as pm\n\n__all__ = [\"find_constrained_prior\"]\n\n\ndef find_constrained_prior(\n    distribution: pm.Distribution,\n    lower: float,\n    upper: float,\n    init_guess: dict[str, float],\n    mass: float = 0.95,\n    fixed_params: dict[str, float] | None = None,\n    mass_below_lower: float | None = None,\n    **kwargs,\n) -> dict[str, float]:\n    \"\"\"\n    Find optimal parameters to get `mass` % of probability of a distribution between `lower` and `upper`.\n\n    Note: only works for one- and two-parameter distributions, as there\n    are exactly two constraints. Fix some combination of parameters\n    if you want to use it on >=3-parameter distributions.\n\n    Parameters\n    ----------\n    distribution : Distribution\n        PyMC distribution you want to set a prior on.\n        Needs to have a ``logcdf`` method implemented in PyMC.\n    lower : float\n        Lower bound to get `mass` % of probability of `pm_dist`.\n    upper : float\n        Upper bound to get `mass` % of probability of `pm_dist`.\n    init_guess : dict of {str : float}\n        Initial guess for ``scipy.optimize.least_squares`` to find the\n        optimal parameters of `pm_dist` fitting the interval constraint.\n        Must be a dictionary with the name of the PyMC distribution's\n        parameter as keys and the initial guess as values.\n    mass : float, default 0.95\n        Share of the probability mass we want between ``lower`` and ``upper``.\n        Defaults to 95%.\n    fixed_params : str or float, optional, default None\n        Only used when `pm_dist` has at least three parameters.\n        Dictionary of fixed parameters, so that there are only 2 to optimize.\n        For instance, for a StudentT, you fix nu to a constant and get the optimized\n        mu and sigma.\n    mass_below_lower : float, optional, default None\n        The probability mass below the ``lower`` bound. If ``None``,\n        defaults to ``(1 - mass) / 2``, which implies that the probability\n        mass below the ``lower`` value will be equal to the probability\n        mass above the ``upper`` value.\n\n    Returns\n    -------\n    opt_params : dict\n        The optimized distribution parameters as a dictionary.\n        Dictionary keys are the parameter names and\n        dictionary values are the optimized parameter values.\n\n    Notes\n    -----\n    Optional keyword arguments can be passed to ``find_constrained_prior``. These will be\n    delivered to the underlying call to :external:py:func:`scipy.optimize.minimize`.\n\n    Examples\n    --------\n    .. code-block:: python\n\n        # get parameters obeying constraints\n        opt_params = pm.find_constrained_prior(\n            pm.Gamma, lower=0.1, upper=0.4, mass=0.75, init_guess={\"alpha\": 1, \"beta\": 10}\n        )\n\n        # use these parameters to draw random samples\n        samples = pm.Gamma.dist(**opt_params, size=100).eval()\n\n        # use these parameters in a model\n        with pm.Model():\n            x = pm.Gamma(\"x\", **opt_params)\n\n        # specify fixed values before optimization\n        opt_params = pm.find_constrained_prior(\n            pm.StudentT,\n            lower=0,\n            upper=1,\n            init_guess={\"mu\": 5, \"sigma\": 2},\n            fixed_params={\"nu\": 7},\n        )\n\n    Under some circumstances, you might not want to have the same cumulative\n    probability below the ``lower`` threshold and above the ``upper`` threshold.\n    For example, you might want to constrain an Exponential distribution to\n    find the parameter that yields 90% of the mass below the ``upper`` bound,\n    and have zero mass below ``lower``. You can do that with the following call\n    to ``find_constrained_prior``\n\n    .. code-block:: python\n\n        opt_params = pm.find_constrained_prior(\n            pm.Exponential,\n            lower=0,\n            upper=3.0,\n            mass=0.9,\n            init_guess={\"lam\": 1},\n            mass_below_lower=0,\n        )\n    \"\"\"\n    warnings.warn(\n        \"find_constrained_prior is deprecated and will be removed in a future version. \"\n        \"Please use maxent function from PreliZ. \"\n        \"https://preliz.readthedocs.io/en/latest/api_reference.html#preliz.unidimensional.maxent\",\n        FutureWarning,\n        stacklevel=2,\n    )\n\n    assert 0.01 <= mass <= 0.99, (\n        \"This function optimizes the mass of the given distribution +/- \"\n        f\"1%, so `mass` has to be between 0.01 and 0.99. You provided {mass}.\"\n    )\n    if mass_below_lower is None:\n        mass_below_lower = (1 - mass) / 2\n\n    # exit when any parameter is not scalar:\n    if np.any(np.asarray(distribution.rv_op.ndims_params) != 0):\n        raise NotImplementedError(\n            \"`pm.find_constrained_prior` does not work with non-scalar parameters yet.\\n\"\n            \"Feel free to open a pull request on PyMC repo if you really need this feature.\"\n        )\n\n    dist_params = pt.vector(\"dist_params\")\n    params_to_optim = {\n        arg_name: dist_params[i] for arg_name, i in zip(init_guess.keys(), range(len(init_guess)))\n    }\n\n    if fixed_params is not None:\n        params_to_optim.update(fixed_params)\n\n    dist = distribution.dist(**params_to_optim)\n\n    try:\n        logcdf_lower = pm.logcdf(dist, pm.floatX(lower))\n        logcdf_upper = pm.logcdf(dist, pm.floatX(upper))\n    except AttributeError:\n        raise AttributeError(\n            f\"You cannot use `find_constrained_prior` with {distribution} -- it doesn't have a logcdf \"\n            \"method yet.\\nOpen an issue or, even better, a pull request on PyMC repo if you really \"\n            \"need it.\"\n        )\n\n    target = (pt.exp(logcdf_lower) - mass_below_lower) ** 2\n    target_fn = pm.pytensorf.compile([dist_params], target, allow_input_downcast=True)\n\n    constraint = pt.exp(logcdf_upper) - pt.exp(logcdf_lower)\n    constraint_fn = pm.pytensorf.compile([dist_params], constraint, allow_input_downcast=True)\n\n    jac: str | Callable\n    constraint_jac: str | Callable\n    try:\n        pytensor_jac = pm.gradient(target, [dist_params])\n        jac = pm.pytensorf.compile([dist_params], pytensor_jac, allow_input_downcast=True)\n        pytensor_constraint_jac = pm.gradient(constraint, [dist_params])\n        constraint_jac = pm.pytensorf.compile(\n            [dist_params], pytensor_constraint_jac, allow_input_downcast=True\n        )\n    # when PyMC cannot compute the gradient\n    except (NotImplementedError, NullTypeGradError):\n        jac = \"2-point\"\n        constraint_jac = \"2-point\"\n    cons = optimize.NonlinearConstraint(constraint_fn, lb=mass, ub=mass, jac=constraint_jac)\n\n    opt = optimize.minimize(\n        target_fn, x0=list(init_guess.values()), jac=jac, constraints=cons, **kwargs\n    )\n    if not opt.success:\n        raise ValueError(\n            f\"Optimization of parameters failed.\\nOptimization termination details:\\n{opt}\"\n        )\n\n    # save optimal parameters\n    opt_params = dict(zip(init_guess.keys(), opt.x))\n    if fixed_params is not None:\n        opt_params.update(fixed_params)\n    return opt_params",
      "program_specification": "```dafny\n// Copyright 2024 - present The PyMC Developers\n// Licensed under the Apache License, Version 2.0\n\nmodule FindConstrainedPrior {\n\n  // Model for a generic distribution with logcdf method.\n  trait Distribution {\n    // Returns the logcdf at x for the given parameters.\n    method logcdf(params: seq<real>, x: real) returns (r: real)\n      ensures true // No postcondition, as this is a mock\n  }\n\n  // Helper function: checks if all parameters are scalars (here, always true for simplicity)\n  function AllParamsAreScalar(params: seq<real>): bool\n    reads {}\n  {\n    // In this mock, all params are scalar\n    true\n  }\n\n  // Helper function: returns keys of a map as a sequence\n  function method MapKeys<V>(m: map<string, V>): seq<string>\n    decreases |m|\n  {\n    if |m| == 0 then [] else\n      var k: string :| k in m; [k] + MapKeys(m - [k])\n  }\n\n  // Helper function: returns values of a map as a sequence (ordered by MapKeys)\n  function method MapValues<V>(m: map<string, V>): seq<V>\n    decreases |m|\n  {\n    if |m| == 0 then [] else\n      var k: string :| k in m; [m[k]] + MapValues(m - [k])\n  }\n\n  // Helper function: builds a map from keys and values\n  function method MapFromSeqs<V>(keys: seq<string>, values: seq<V>): map<string, V>\n    requires |keys| == |values|\n    decreases |keys|\n  {\n    if |keys| == 0 then map[] else\n      map[keys[0] := values[0]] + MapFromSeqs(keys[1..], values[1..])\n  }\n\n  // Main function: find_constrained_prior\n  method find_constrained_prior(\n    distribution: Distribution,\n    lower: real,\n    upper: real,\n    init_guess: map<string, real>,\n    mass: real,\n    fixed_params: map<string, real>,\n    mass_below_lower: real?\n    ) returns (opt_params: map<string, real>)\n    requires 0.01 <= mass <= 0.99\n    requires |init_guess| >= 1\n    requires AllParamsAreScalar(MapValues(init_guess))\n    ensures |opt_params| == |init_guess| + |fixed_params|\n    ensures forall k :: k in fixed_params ==> opt_params[k] == fixed_params[k]\n  {\n    // Compute mass_below_lower if not provided\n    var mbl: real;\n    if mass_below_lower.Some? {\n      mbl := mass_below_lower.value;\n    } else {\n      mbl := (1.0 - mass) / 2.0;\n    }\n\n    // Compose parameter vector to optimize\n    var keys := MapKeys(init_guess);\n    var values := MapValues(init_guess);\n    var n := |keys|;\n\n    // Compose full parameter vector for the distribution\n    var params_to_optim := init_guess + fixed_params;\n\n    // For simplicity, we represent the parameter vector as a sequence\n    var param_vec := MapValues(init_guess);\n\n    // Define the target function (mocked)\n    function Target(params: seq<real>): real\n      requires |params| == n\n    {\n      var full_params := MapValues(init_guess);\n      // In a real implementation, would fill in fixed_params as well\n      // Here, just use params for all\n      var logcdf_lower := distribution.logcdf(params, lower);\n      var logcdf_upper := distribution.logcdf(params, upper);\n      ((exp(logcdf_lower) - mbl) * (exp(logcdf_lower) - mbl))\n    }\n\n    // Define the constraint function (mocked)\n    function Constraint(params: seq<real>): real\n      requires |params| == n\n    {\n      var logcdf_lower := distribution.logcdf(params, lower);\n      var logcdf_upper := distribution.logcdf(params, upper);\n      exp(logcdf_upper) - exp(logcdf_lower)\n    }\n\n    // Optimization (mocked): just return initial guess for simplicity\n    var opt_values := param_vec;\n\n    // Compose the result map\n    opt_params := MapFromSeqs(keys, opt_values) + fixed_params;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 12.883,
        "duration_formatted": "12.88s",
        "tokens": {
          "input": 1918,
          "output": 929,
          "total": 2847
        },
        "cost_usd": 0.011268,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:37:32.251994"
      }
    },
    {
      "file_path": "snippet_17.py",
      "code": "'''\n\tGiven an array containing n distinct numbers taken from 0, 1, 2, ..., n, find the one that is missing from the array.\n\n\tExample 1:\n\n\tInput: [3,0,1]\n\tOutput: 2\n\tExample 2:\n\n\tInput: [9,6,4,2,3,5,7,0,1]\n\tOutput: 8\n'''\n\nclass Solution(object):\n    def missingNumber(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: int\n        \"\"\"\n        if not nums:\n        \treturn 0\n        totalSum, n = sum(nums), len(nums)\n        expectedSum = (n*(n+1))/2\n        return expectedSum - totalSum",
      "program_specification": "```dafny\nmethod missingNumber(nums: array<int>) returns (missing: int)\n  requires nums != null\n  requires forall i :: 0 <= i < nums.Length ==> 0 <= nums[i] <= nums.Length\n  requires |set nums[..]| == nums.Length // all elements are distinct\n  ensures 0 <= missing <= nums.Length\n  ensures missing !in set nums[..]\n  ensures forall x :: 0 <= x <= nums.Length && x != missing ==> x in set nums[..]\n{\n  if nums.Length == 0 {\n    return 0;\n  }\n  var n := nums.Length;\n  var totalSum := 0;\n  var i := 0;\n  while i < n\n    invariant 0 <= i <= n\n    invariant totalSum == sum(nums[..i])\n  {\n    totalSum := totalSum + nums[i];\n    i := i + 1;\n  }\n  var expectedSum := n * (n + 1) / 2;\n  missing := expectedSum - totalSum;\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 3.386,
        "duration_formatted": "3.39s",
        "tokens": {
          "input": 239,
          "output": 218,
          "total": 457
        },
        "cost_usd": 0.002222,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:37:40.677099"
      }
    },
    {
      "file_path": "snippet_18.py",
      "code": "'''\n    Evaluate the value of an arithmetic expression in Reverse Polish Notation.\n\n    Valid operators are +, -, *, /. Each operand may be an integer or another expression.\n\n    Note:\n\n    Division between two integers should truncate toward zero.\n    The given RPN expression is always valid. That means the expression would always evaluate to a result and there won't be any divide by zero operation.\n    Example 1:\n\n    Input: [\"2\", \"1\", \"+\", \"3\", \"*\"]\n    Output: 9\n    Explanation: ((2 + 1) * 3) = 9\n    Example 2:\n\n    Input: [\"4\", \"13\", \"5\", \"/\", \"+\"]\n    Output: 6\n    Explanation: (4 + (13 / 5)) = 6\n'''\n\nclass Solution(object):\n    def evalRPN(self, tokens):\n        \"\"\"\n        :type tokens: List[str]\n        :rtype: int\n        \"\"\"\n        \n        if not tokens:\n            return 0\n        \n        stack = []\n        for val in tokens:\n            if val == '+':\n                val1 = stack.pop()\n                val2 = stack.pop()\n                stack.append(val1 + val2)\n            elif val == '-':\n                val1  = stack.pop()\n                val2 = stack.pop()\n                stack.append(val2-val1)\n            elif val == '*':\n                val1  = stack.pop()\n                val2  = stack.pop()\n                stack.append(val2*val1)\n            elif val == '/':\n                val1 = stack.pop()\n                val2  = stack.pop()\n                if val1*val2 < 0:\n                    stack.append(-(-val2/val1))\n                else:\n                    stack.append(val2/val1)\n            else:\n                stack.append(int(val))\n        return stack[0]",
      "program_specification": "```dafny\nmethod TruncateTowardZeroDiv(x: int, y: int) returns (q: int)\n    requires y != 0\n    ensures x * y >= 0 ==> q == x / y\n    ensures x * y < 0 ==> q == -(abs(x) / abs(y))\n{\n    if x * y >= 0 {\n        return x / y;\n    } else {\n        return -((if x < 0 then -x else x) / (if y < 0 then -y else y));\n    }\n}\n\nmethod EvalRPN(tokens: seq<string>) returns (res: int)\n    requires tokens != []\n    ensures true // The result is the evaluation of the RPN expression\n{\n    var stack := new seq<int>[];\n    var i := 0;\n    while i < |tokens|\n        invariant 0 <= i <= |tokens|\n        invariant stack != null\n        decreases |tokens| - i\n    {\n        var val := tokens[i];\n        if val == \"+\" || val == \"-\" || val == \"*\" || val == \"/\" {\n            assert |stack| >= 2;\n            var val1 := stack[|stack|-1];\n            var val2 := stack[|stack|-2];\n            stack := stack[..|stack|-2];\n            if val == \"+\" {\n                stack := stack + [val2 + val1];\n            } else if val == \"-\" {\n                stack := stack + [val2 - val1];\n            } else if val == \"*\" {\n                stack := stack + [val2 * val1];\n            } else { // val == \"/\"\n                assert val1 != 0;\n                stack := stack + [TruncateTowardZeroDiv(val2, val1)];\n            }\n        } else {\n            // parse integer\n            var parsed: int;\n            var ok := int.TryParse(val, parsed);\n            assert ok;\n            stack := stack + [parsed];\n        }\n        i := i + 1;\n    }\n    assert |stack| == 1;\n    res := stack[0];\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.776,
        "duration_formatted": "8.78s",
        "tokens": {
          "input": 457,
          "output": 433,
          "total": 890
        },
        "cost_usd": 0.004378,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:37:54.505577"
      }
    },
    {
      "file_path": "snippet_19.py",
      "code": "'''\n\tGiven an array nums, write a function to move all 0's to the end of it while maintaining the relative order of the non-zero elements.\n\n\tExample:\n\n\tInput: [0,1,0,3,12]\n\tOutput: [1,3,12,0,0]\n\tNote:\n\n\tYou must do this in-place without making a copy of the array.\n\tMinimize the total number of operations.\n'''\n\nclass Solution(object):\n    def moveZeroes(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: void Do not return anything, modify nums in-place instead.\n        \"\"\"\n        zeroIndex = 0\n        for index in range(len(nums)):\n            if nums[index] != 0:\n                nums[zeroIndex] = nums[index]\n                zeroIndex += 1\n                \n        for index in range(zeroIndex, len(nums)):\n            nums[index] = 0",
      "program_specification": "```dafny\nmethod MoveZeroes(nums: array<int>)\n    requires nums != null\n    modifies nums\n    ensures \n        // The output array has all non-zeros in their original order, followed by zeros\n        (exists k :: 0 <= k <= nums.Length &&\n            (forall i :: 0 <= i < k ==> nums[i] != 0) &&\n            (forall i :: k <= i < nums.Length ==> nums[i] == 0) &&\n            (multiset nums[..k] == multiset (old(nums[..])) - multiset [0]) &&\n            (forall i,j :: 0 <= i < j < nums.Length && nums[i] != 0 && nums[j] != 0 ==>\n                (exists idxi, idxj :: 0 <= idxi < idxj < nums.Length && old(nums[idxi]) != 0 && old(nums[idxj]) != 0 && nums[i] == old(nums[idxi]) && nums[j] == old(nums[idxj])))\n        )\n{\n    var zeroIndex := 0;\n    var n := nums.Length;\n    // First pass: move non-zero elements to the front, preserving their order\n    var i := 0;\n    while i < n\n        invariant 0 <= zeroIndex <= i <= n\n        invariant (forall j :: 0 <= j < zeroIndex ==> nums[j] != 0)\n        invariant (forall j :: zeroIndex <= j < i ==> nums[j] == old(nums[j]))\n        invariant (forall j :: i <= j < n ==> nums[j] == old(nums[j]))\n        decreases n - i\n    {\n        if nums[i] != 0 {\n            nums[zeroIndex] := nums[i];\n            zeroIndex := zeroIndex + 1;\n        }\n        i := i + 1;\n    }\n    // Second pass: fill the rest with zeros\n    var j := zeroIndex;\n    while j < n\n        invariant zeroIndex <= j <= n\n        invariant (forall k :: 0 <= k < zeroIndex ==> nums[k] != 0)\n        invariant (forall k :: zeroIndex <= k < j ==> nums[k] == 0)\n        invariant (forall k :: j <= k < n ==> nums[k] == old(nums[k]))\n        decreases n - j\n    {\n        nums[j] := 0;\n        j := j + 1;\n    }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.971,
        "duration_formatted": "8.97s",
        "tokens": {
          "input": 273,
          "output": 503,
          "total": 776
        },
        "cost_usd": 0.00457,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:38:08.507462"
      }
    },
    {
      "file_path": "snippet_20.py",
      "code": "def hex_to_bin(hex_num: str) -> int:\n    \"\"\"\n    Convert a hexadecimal value to its binary equivalent\n    #https://stackoverflow.com/questions/1425493/convert-hex-to-binary\n    Here, we have used the bitwise right shift operator: >>\n    Shifts the bits of the number to the right and fills 0 on voids left as a result.\n    Similar effect as of dividing the number with some power of two.\n    Example:\n    a = 10\n    a >> 1 = 5\n\n    >>> hex_to_bin(\"AC\")\n    10101100\n    >>> hex_to_bin(\"9A4\")\n    100110100100\n    >>> hex_to_bin(\"   12f   \")\n    100101111\n    >>> hex_to_bin(\"FfFf\")\n    1111111111111111\n    >>> hex_to_bin(\"-fFfF\")\n    -1111111111111111\n    >>> hex_to_bin(\"F-f\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid value was passed to the function\n    >>> hex_to_bin(\"\")\n    Traceback (most recent call last):\n        ...\n    ValueError: No value was passed to the function\n    \"\"\"\n\n    hex_num = hex_num.strip()\n    if not hex_num:\n        raise ValueError(\"No value was passed to the function\")\n\n    is_negative = hex_num[0] == \"-\"\n    if is_negative:\n        hex_num = hex_num[1:]\n\n    try:\n        int_num = int(hex_num, 16)\n    except ValueError:\n        raise ValueError(\"Invalid value was passed to the function\")\n\n    bin_str = \"\"\n    while int_num > 0:\n        bin_str = str(int_num % 2) + bin_str\n        int_num >>= 1\n\n    return int((\"-\" + bin_str) if is_negative else bin_str)\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\nmethod HexToBin(hexNum: string) returns (binVal: int)\n    requires hexNum != null\n    ensures (hexNum.Trim() == \"\") ==> old(binVal) == 0 // Exception in Python, here 0\n    ensures forall c :: c in hexNum.Trim() && !('0' <= c <= '9' || 'A' <= c <= 'F' || 'a' <= c <= 'f' || c == '-') ==>\n        old(binVal) == 0 // Exception in Python, here 0\n{\n    var s := hexNum.Trim();\n    if s == \"\" {\n        // In Python: raise ValueError(\"No value was passed to the function\")\n        // In Dafny, we return 0 as a placeholder for error\n        binVal := 0;\n        return;\n    }\n\n    var isNegative := s[0] == '-';\n    var hexPart := if isNegative then s[1..] else s;\n\n    // Check for valid hex digits\n    if hexPart == \"\" || exists i :: 0 <= i < |hexPart| && !('0' <= hexPart[i] <= '9' || 'A' <= hexPart[i] <= 'F' || 'a' <= hexPart[i] <= 'f') {\n        // In Python: raise ValueError(\"Invalid value was passed to the function\")\n        // In Dafny, we return 0 as a placeholder for error\n        binVal := 0;\n        return;\n    }\n\n    var intNum := 0;\n    var pow := 1;\n    var i := |hexPart| - 1;\n    while i >= 0\n        invariant 0 <= i+1 <= |hexPart|\n        invariant pow >= 1\n        decreases i\n    {\n        var c := hexPart[i];\n        var digit: int;\n        if '0' <= c <= '9' {\n            digit := c as int - '0' as int;\n        } else if 'A' <= c <= 'F' {\n            digit := c as int - 'A' as int + 10;\n        } else if 'a' <= c <= 'f' {\n            digit := c as int - 'a' as int + 10;\n        } else {\n            // Should not happen due to earlier check\n            binVal := 0;\n            return;\n        }\n        intNum := intNum + digit * pow;\n        pow := pow * 16;\n        i := i - 1;\n    }\n\n    var binStr := \"\";\n    var n := intNum;\n    if n == 0 {\n        binStr := \"0\";\n    } else {\n        while n > 0\n            invariant n >= 0\n            decreases n\n        {\n            binStr := (if n % 2 == 0 then \"0\" else \"1\") + binStr;\n            n := n / 2;\n        }\n    }\n\n    if isNegative {\n        binStr := \"-\" + binStr;\n    }\n    // Convert binary string to int\n    // (We parse the binary string ourselves, as Dafny does not have int(\"1010\"))\n    var res := 0;\n    var neg := false;\n    var idx := 0;\n    if binStr[0] == '-' {\n        neg := true;\n        idx := 1;\n    }\n    while idx < |binStr|\n        invariant 0 <= idx <= |binStr|\n        invariant res >= 0\n        decreases |binStr| - idx\n    {\n        var ch := binStr[idx];\n        if ch == '0' || ch == '1' {\n            res := res * 10 + (ch as int - '0' as int);\n        }\n        idx := idx + 1;\n    }\n    if neg {\n        binVal := -res;\n    } else {\n        binVal := res;\n    }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 12.104,
        "duration_formatted": "12.10s",
        "tokens": {
          "input": 501,
          "output": 825,
          "total": 1326
        },
        "cost_usd": 0.007602,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:38:25.670529"
      }
    },
    {
      "file_path": "snippet_21.py",
      "code": "# Time:  O(sqrt(n))\n# Space: O(1)\n\nclass Solution(object):\n    def minSteps(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: int\n        \"\"\"\n        result = 0\n        p = 2\n        # the answer is the sum of prime factors\n        while p**2 <= n:\n            while n % p == 0:\n                result += p\n                n //= p\n            p += 1\n        if n > 1:\n            result += n\n        return result",
      "program_specification": "```dafny\nmethod minSteps(n: int) returns (result: int)\n  requires n >= 1\n  ensures result >= 0\n  ensures forall k :: k >= 2 && k <= n ==> (n % k == 0 ==> result <= n)\n{\n  var n0 := n;\n  result := 0;\n  var p := 2;\n  while p * p <= n\n    invariant n >= 1\n    invariant p >= 2\n    invariant result >= 0\n    decreases n\n  {\n    while n % p == 0\n      invariant n >= 1\n      invariant result >= 0\n      decreases n\n    {\n      result := result + p;\n      n := n / p;\n    }\n    p := p + 1;\n  }\n  if n > 1 {\n    result := result + n;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 4.995,
        "duration_formatted": "5.00s",
        "tokens": {
          "input": 200,
          "output": 186,
          "total": 386
        },
        "cost_usd": 0.001888,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:38:35.700475"
      }
    },
    {
      "file_path": "snippet_22.py",
      "code": "# Time:  O(r - l)\n# Space: O(1)\n\nimport math\n\n\nclass Solution(object):\n    def abbreviateProduct(self, left, right):\n        \"\"\"\n        :type left: int\n        :type right: int\n        :rtype: str\n        \"\"\"\n        PREFIX_LEN = SUFFIX_LEN = 5\n        MOD = 10**(PREFIX_LEN+SUFFIX_LEN)\n        curr, zeros = 1, 0\n        abbr = False\n        for i in xrange(left, right+1):\n            curr *= i\n            while not curr%10:\n                curr //= 10\n                zeros += 1\n            q, curr = divmod(curr, MOD)\n            if q:\n                abbr = True\n        if not abbr:\n            return \"%se%s\" % (curr, zeros)\n        decimal = reduce(lambda x, y: (x+y)%1, (math.log10(i) for i in xrange(left, right+1)))\n        prefix = str(int(10**(decimal+(PREFIX_LEN-1))))\n        suffix = str(curr % 10**SUFFIX_LEN).zfill(SUFFIX_LEN)\n        return \"%s...%se%s\" % (prefix, suffix, zeros)",
      "program_specification": "```dafny\nimport Math\n\nmethod abbreviateProduct(left: int, right: int) returns (res: string)\n  requires left <= right\n  ensures\n    // If the product has no abbreviation, the result is of the form \"<curr>e<zeros>\"\n    (forall i :: left <= i <= right ==> i > 0) ==>\n      (if (forall i :: left <= i <= right ==> i > 0) then true else true) // placeholder for full correctness\n{\n  var PREFIX_LEN := 5;\n  var SUFFIX_LEN := 5;\n  var MOD := Math.Pow(10, PREFIX_LEN + SUFFIX_LEN) as int;\n  var curr := 1;\n  var zeros := 0;\n  var abbr := false;\n  var i := left;\n  while i <= right\n    invariant left <= i <= right + 1\n    invariant curr >= 0\n    invariant zeros >= 0\n  {\n    curr := curr * i;\n    // Remove trailing zeros\n    while curr % 10 == 0 && curr != 0\n      invariant curr >= 0\n      invariant zeros >= 0\n    {\n      curr := curr / 10;\n      zeros := zeros + 1;\n    }\n    var q := curr / MOD;\n    curr := curr % MOD;\n    if q > 0 {\n      abbr := true;\n    }\n    i := i + 1;\n  }\n  if !abbr {\n    res := curr.ToString() + \"e\" + zeros.ToString();\n    return;\n  }\n  // Compute decimal part for prefix\n  var decimal: real := 0.0;\n  i := left;\n  while i <= right\n    invariant left <= i <= right + 1\n    decreases right - i + 1\n  {\n    decimal := decimal + Math.Log10(i as real) % 1.0;\n    i := i + 1;\n  }\n  var prefixVal := Math.Floor(Math.Pow(10.0, decimal + (PREFIX_LEN - 1) as real)) as int;\n  var prefix := prefixVal.ToString();\n  var pow10Suffix := Math.Pow(10, SUFFIX_LEN) as int;\n  var suffixVal := curr % pow10Suffix;\n  var suffix := suffixVal.ToString();\n  // Pad suffix with leading zeros if needed\n  while |suffix| < SUFFIX_LEN\n    invariant |suffix| <= SUFFIX_LEN\n    decreases SUFFIX_LEN - |suffix|\n  {\n    suffix := \"0\" + suffix;\n  }\n  res := prefix + \"...\" + suffix + \"e\" + zeros.ToString();\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.66,
        "duration_formatted": "8.66s",
        "tokens": {
          "input": 341,
          "output": 557,
          "total": 898
        },
        "cost_usd": 0.005138,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:38:49.394184"
      }
    },
    {
      "file_path": "snippet_23.py",
      "code": "from typing import Any\n\nfrom starlette.responses import FileResponse as FileResponse  # noqa\nfrom starlette.responses import HTMLResponse as HTMLResponse  # noqa\nfrom starlette.responses import JSONResponse as JSONResponse  # noqa\nfrom starlette.responses import PlainTextResponse as PlainTextResponse  # noqa\nfrom starlette.responses import RedirectResponse as RedirectResponse  # noqa\nfrom starlette.responses import Response as Response  # noqa\nfrom starlette.responses import StreamingResponse as StreamingResponse  # noqa\n\ntry:\n    import ujson\nexcept ImportError:  # pragma: nocover\n    ujson = None  # type: ignore\n\n\ntry:\n    import orjson\nexcept ImportError:  # pragma: nocover\n    orjson = None  # type: ignore\n\n\nclass UJSONResponse(JSONResponse):\n    \"\"\"\n    JSON response using the high-performance ujson library to serialize data to JSON.\n\n    Read more about it in the\n    [FastAPI docs for Custom Response - HTML, Stream, File, others](https://fastapi.tiangolo.com/advanced/custom-response/).\n    \"\"\"\n\n    def render(self, content: Any) -> bytes:\n        assert ujson is not None, \"ujson must be installed to use UJSONResponse\"\n        return ujson.dumps(content, ensure_ascii=False).encode(\"utf-8\")\n\n\nclass ORJSONResponse(JSONResponse):\n    \"\"\"\n    JSON response using the high-performance orjson library to serialize data to JSON.\n\n    Read more about it in the\n    [FastAPI docs for Custom Response - HTML, Stream, File, others](https://fastapi.tiangolo.com/advanced/custom-response/).\n    \"\"\"\n\n    def render(self, content: Any) -> bytes:\n        assert orjson is not None, \"orjson must be installed to use ORJSONResponse\"\n        return orjson.dumps(\n            content, option=orjson.OPT_NON_STR_KEYS | orjson.OPT_SERIALIZE_NUMPY\n        )",
      "program_specification": "```dafny\n// Dafny translation of the provided Python code, focusing on structure and verifiability.\n// Note: Actual serialization and dynamic typing are not modeled; we use simple types and predicates.\n\nmodule Responses {\n\n  // Abstract base class for JSON responses\n  abstract class JSONResponse {\n    // Abstract method for rendering content to bytes\n    method render(content: string) returns (bytes: seq<byte>)\n      ensures bytes != []\n  }\n\n  // Predicate to represent whether ujson is available\n  function method ujson_available(): bool\n\n  // Predicate to represent whether orjson is available\n  function method orjson_available(): bool\n\n  // UJSONResponse: uses ujson to serialize data\n  class UJSONResponse extends JSONResponse {\n    // Render content to bytes using ujson\n    method render(content: string) returns (bytes: seq<byte>)\n      requires ujson_available()\n      ensures bytes == UJSONSerialize(content)\n    {\n      // Simulate serialization as UTF-8 encoding of the string\n      bytes := UJSONSerialize(content);\n    }\n  }\n\n  // ORJSONResponse: uses orjson to serialize data\n  class ORJSONResponse extends JSONResponse {\n    // Render content to bytes using orjson\n    method render(content: string) returns (bytes: seq<byte>)\n      requires orjson_available()\n      ensures bytes == ORJSONSerialize(content)\n    {\n      // Simulate serialization as UTF-8 encoding of the string\n      bytes := ORJSONSerialize(content);\n    }\n  }\n\n  // Specification of serialization using ujson (for demo, just UTF-8 encoding)\n  function method UJSONSerialize(content: string): seq<byte>\n    ensures UJSONSerialize(content) == content as seq<byte>\n  {\n    content as seq<byte>\n  }\n\n  // Specification of serialization using orjson (for demo, just UTF-8 encoding)\n  function method ORJSONSerialize(content: string): seq<byte>\n    ensures ORJSONSerialize(content) == content as seq<byte>\n  {\n    content as seq<byte>\n  }\n\n  // Dummy classes to represent the imported response types\n  class FileResponse {}\n  class HTMLResponse {}\n  class PlainTextResponse {}\n  class RedirectResponse {}\n  class Response {}\n  class StreamingResponse {}\n\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 5.378,
        "duration_formatted": "5.38s",
        "tokens": {
          "input": 486,
          "output": 458,
          "total": 944
        },
        "cost_usd": 0.004636,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:38:59.826778"
      }
    },
    {
      "file_path": "snippet_24.py",
      "code": "'''\n\tGiven a binary tree, find its minimum depth.\n\n\tThe minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node.\n\n\tNote: A leaf is a node with no children.\n\n\tExample:\n\n\tGiven binary tree [3,9,20,null,null,15,7],\n\n\t    3\n\t   / \\\n\t  9  20\n\t    /  \\\n\t   15   7\n\n\treturn its minimum depth = 2.\n'''\n\n# Definition for a binary tree node.\n# class TreeNode(object):\n#     def __init__(self, x):\n#         self.val = x\n#         self.left = None\n#         self.right = None\n\nclass Solution(object):\n    def minDepth(self, root):\n    \tif not root:\n    \t\treturn 0\n    \tdepth = float('inf')\n    \tstack = [(root, 1)]\n\n    \twhile stack:\n    \t\tnode, level = stack.pop()\n    \t\tif node:\n\n    \t\t\tif not node.left and not node.right:\n    \t\t\t\tdepth = min(depth, level)\n\n    \t\t\tstack.append((node.left, level+1))\n    \t\t\tstack.append((node.right, level+1))\n\n    \treturn depth",
      "program_specification": "```dafny\n// Definition for a binary tree node.\nclass TreeNode {\n  var val: int\n  var left: TreeNode?\n  var right: TreeNode?\n\n  constructor (v: int)\n    ensures val == v && left == null && right == null\n  {\n    val := v;\n    left := null;\n    right := null;\n  }\n}\n\n// Function to check if a node is a leaf\nfunction method IsLeaf(n: TreeNode?): bool\n  reads n\n{\n  n != null && n.left == null && n.right == null\n}\n\n// Function to compute the minimum depth of a binary tree\nfunction method MinDepth(n: TreeNode?): nat\n  decreases n\n{\n  if n == null then 0\n  else if n.left == null && n.right == null then 1\n  else if n.left == null then 1 + MinDepth(n.right)\n  else if n.right == null then 1 + MinDepth(n.left)\n  else 1 + if MinDepth(n.left) < MinDepth(n.right) then MinDepth(n.left) else MinDepth(n.right)\n}\n\nclass Solution {\n  method minDepth(root: TreeNode?) returns (depth: nat)\n    ensures depth == MinDepth(root)\n  {\n    if root == null {\n      depth := 0;\n      return;\n    }\n\n    var minDepth: nat := 0x7fffffff; // Use a large value as infinity\n    var stack: seq<(TreeNode?, nat)> := [(root, 1)];\n\n    while |stack| > 0\n      invariant forall i :: 0 <= i < |stack| ==> stack[i].0 != null\n      invariant minDepth == 0x7fffffff || minDepth >= 1\n      decreases |stack|\n    {\n      var pair := stack[|stack|-1];\n      stack := stack[..|stack|-1];\n      var node := pair.0;\n      var level := pair.1;\n\n      if node != null {\n        if node.left == null && node.right == null {\n          if level < minDepth {\n            minDepth := level;\n          }\n        }\n        stack := stack + [(node.left, level+1)];\n        stack := stack + [(node.right, level+1)];\n      }\n    }\n    depth := minDepth;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 4.812,
        "duration_formatted": "4.81s",
        "tokens": {
          "input": 328,
          "output": 485,
          "total": 813
        },
        "cost_usd": 0.004536,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:39:09.674120"
      }
    },
    {
      "file_path": "snippet_25.py",
      "code": "# Copyright 2014-2015 MongoDB, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A BSON wrapper for long (int in python3)\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Any\n\n\nclass Int64(int):\n    \"\"\"Representation of the BSON int64 type.\n\n    This is necessary because every integral number is an :class:`int` in\n    Python 3. Small integral numbers are encoded to BSON int32 by default,\n    but Int64 numbers will always be encoded to BSON int64.\n\n    :param value: the numeric value to represent\n    \"\"\"\n\n    __slots__ = ()\n\n    _type_marker = 18\n\n    def __getstate__(self) -> Any:\n        return {}\n\n    def __setstate__(self, state: Any) -> None:\n        pass",
      "program_specification": "```dafny\n// Dafny translation of the Python Int64 wrapper class for BSON int64 type\n\n// A simple wrapper for 64-bit signed integers.\ndatatype Int64 = Int64(value: int)\n  // Invariant: value must be within the range of 64-bit signed integers\n  where -9223372036854775808 <= value < 9223372036854775808\n\n// Marker constant for BSON int64 type\nconst type_marker: int := 18\n\n// Returns the state of the Int64 object as an empty map (for serialization)\nmethod GetState(i: Int64) returns (state: map<string, int>)\n  ensures state == map[]\n{\n  state := map[];\n}\n\n// Sets the state of the Int64 object (no operation, as in Python __setstate__)\nmethod SetState(i: Int64, state: map<string, int>) \n  ensures true\n{\n  // No operation\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 2.993,
        "duration_formatted": "2.99s",
        "tokens": {
          "input": 361,
          "output": 194,
          "total": 555
        },
        "cost_usd": 0.002274,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:39:17.702393"
      }
    },
    {
      "file_path": "snippet_26.py",
      "code": "\"\"\"\nGiven a grid, where you start from the top left position [0, 0],\nyou want to find how many paths you can take to get to the bottom right position.\n\nstart here  ->   0  0  0  0\n                 1  1  0  0\n                 0  0  0  1\n                 0  1  0  0  <- finish here\nhow many 'distinct' paths can you take to get to the finish?\nUsing a recursive depth-first search algorithm below, you are able to\nfind the number of distinct unique paths (count).\n\n'*' will demonstrate a path\nIn the example above, there are two distinct paths:\n1.                2.\n    *  *  *  0      *  *  *  *\n    1  1  *  0      1  1  *  *\n    0  0  *  1      0  0  *  1\n    0  1  *  *      0  1  *  *\n\"\"\"\n\n\ndef depth_first_search(grid: list[list[int]], row: int, col: int, visit: set) -> int:\n    \"\"\"\n    Recursive Backtracking Depth First Search Algorithm\n\n    Starting from top left of a matrix, count the number of\n    paths that can reach the bottom right of a matrix.\n    1 represents a block (inaccessible)\n    0 represents a valid space (accessible)\n\n    0  0  0  0\n    1  1  0  0\n    0  0  0  1\n    0  1  0  0\n    >>> grid = [[0, 0, 0, 0], [1, 1, 0, 0], [0, 0, 0, 1], [0, 1, 0, 0]]\n    >>> depth_first_search(grid, 0, 0, set())\n    2\n\n    0  0  0  0  0\n    0  1  1  1  0\n    0  1  1  1  0\n    0  0  0  0  0\n    >>> grid = [[0, 0, 0, 0, 0], [0, 1, 1, 1, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0]]\n    >>> depth_first_search(grid, 0, 0, set())\n    2\n    \"\"\"\n    row_length, col_length = len(grid), len(grid[0])\n    if (\n        min(row, col) < 0\n        or row == row_length\n        or col == col_length\n        or (row, col) in visit\n        or grid[row][col] == 1\n    ):\n        return 0\n    if row == row_length - 1 and col == col_length - 1:\n        return 1\n\n    visit.add((row, col))\n\n    count = 0\n    count += depth_first_search(grid, row + 1, col, visit)\n    count += depth_first_search(grid, row - 1, col, visit)\n    count += depth_first_search(grid, row, col + 1, visit)\n    count += depth_first_search(grid, row, col - 1, visit)\n\n    visit.remove((row, col))\n    return count\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\n// Dafny translation of the given Python depth_first_search algorithm\n\nmodule PathFinder {\n\n  // A grid is a sequence of sequences of integers (0 = open, 1 = blocked)\n  type Grid = seq<seq<int>>\n\n  // A position in the grid\n  datatype Pos = Position(row: int, col: int)\n\n  // Returns true if (row, col) is within the bounds of the grid\n  function method InBounds(grid: Grid, row: int, col: int): bool\n    requires |grid| > 0 && |grid[0]| > 0\n  {\n    0 <= row < |grid| && 0 <= col < |grid[0]|\n  }\n\n  // Returns true if the cell at (row, col) is open (0)\n  function method IsOpen(grid: Grid, row: int, col: int): bool\n    requires InBounds(grid, row, col)\n  {\n    grid[row][col] == 0\n  }\n\n  // Returns true if the position is the bottom-right cell\n  function method IsGoal(grid: Grid, row: int, col: int): bool\n    requires |grid| > 0 && |grid[0]| > 0\n  {\n    row == |grid| - 1 && col == |grid[0]| - 1\n  }\n\n  // The main DFS function: counts distinct paths from (row, col) to goal, avoiding visited cells\n  method DepthFirstSearch(grid: Grid, row: int, col: int, visit: set<Pos>) returns (count: int)\n    requires |grid| > 0 && |grid[0]| > 0\n    requires forall r :: 0 <= r < |grid| ==> |grid[r]| == |grid[0]|\n    requires forall p: Pos :: p in visit ==> InBounds(grid, p.row, p.col) && IsOpen(grid, p.row, p.col)\n    decreases |grid| * |grid[0]| - |visit|\n  {\n    if row < 0 || col < 0 || row >= |grid| || col >= |grid[0]| {\n      count := 0;\n      return;\n    }\n    if !(IsOpen(grid, row, col)) || Position(row, col) in visit {\n      count := 0;\n      return;\n    }\n    if IsGoal(grid, row, col) {\n      count := 1;\n      return;\n    }\n\n    var newVisit := visit + {Position(row, col)};\n    var down := 0;\n    var up := 0;\n    var right := 0;\n    var left := 0;\n\n    DepthFirstSearch(grid, row + 1, col, newVisit); down := count;\n    DepthFirstSearch(grid, row - 1, col, newVisit); up := count;\n    DepthFirstSearch(grid, row, col + 1, newVisit); right := count;\n    DepthFirstSearch(grid, row, col - 1, newVisit); left := count;\n\n    count := down + up + right + left;\n  }\n\n  // Example usage and test\n  method Test1() returns (paths: int)\n    ensures paths == 2\n  {\n    var grid := [\n      [0, 0, 0, 0],\n      [1, 1, 0, 0],\n      [0, 0, 0, 1],\n      [0, 1, 0, 0]\n    ];\n    DepthFirstSearch(grid, 0, 0, {});\n    paths := count;\n  }\n\n  method Test2() returns (paths: int)\n    ensures paths == 2\n  {\n    var grid := [\n      [0, 0, 0, 0, 0],\n      [0, 1, 1, 1, 0],\n      [0, 1, 1, 1, 0],\n      [0, 0, 0, 0, 0]\n    ];\n    DepthFirstSearch(grid, 0, 0, {});\n    paths := count;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 7.391,
        "duration_formatted": "7.39s",
        "tokens": {
          "input": 884,
          "output": 875,
          "total": 1759
        },
        "cost_usd": 0.008768,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:39:30.129602"
      }
    },
    {
      "file_path": "snippet_27.py",
      "code": "from __future__ import annotations\n\nimport warnings\n\nfrom _pytest.recwarn import WarningsChecker\nfrom pytest import warns\n\n__all__ = [\"pytest_warns\"]\n\n\nclass NoWarningsChecker:\n    def __init__(self):\n        self.cw = warnings.catch_warnings(record=True)\n        self.rec = []\n\n    def __enter__(self):\n        self.rec = self.cw.__enter__()\n\n    def __exit__(self, type, value, traceback):\n        if self.rec:\n            warnings = [w.category.__name__ for w in self.rec]\n            joined = \"\\\\n\".join(warnings)\n            raise AssertionError(\n                \"Function is marked as not warning but the following \"\n                \"warnings were found: \\n\"\n                f\"{joined}\"\n            )\n\n\ndef pytest_warns(\n    warning: type[Warning] | tuple[type[Warning], ...] | None\n) -> WarningsChecker | NoWarningsChecker:\n    \"\"\"\n\n    Parameters\n    ----------\n    warning : {None, Warning, Tuple[Warning]}\n        None if no warning is produced, or a single or multiple Warnings\n\n    Returns\n    -------\n    cm\n\n    \"\"\"\n    if warning is None:\n        return NoWarningsChecker()\n    else:\n        assert warning is not None\n\n        return warns(warning)",
      "program_specification": "```dafny\n// Dafny translation of the given Python code, focusing on core logic and verifiability.\n\nmodule PytestWarns {\n\n  // Abstract representation of a warning type.\n  datatype WarningType = Warning(name: string)\n\n  // Abstract representation of a warning checker.\n  trait WarningsChecker {\n    method Check() returns (hasWarning: bool)\n      ensures hasWarning ==> true // Placeholder\n  }\n\n  // NoWarningsChecker: expects no warnings to occur.\n  class NoWarningsChecker implements WarningsChecker {\n    var rec: seq<WarningType>\n\n    constructor ()\n      ensures rec == []\n    {\n      rec := [];\n    }\n\n    method __enter__() \n      ensures rec == []\n    {\n      // In Python, this would activate the context manager.\n      // Here, we simply ensure rec is empty.\n      rec := [];\n    }\n\n    method __exit__(typ: string, value: string, traceback: string) \n      ensures rec == []\n      modifies this\n    {\n      // If any warnings were recorded, raise an error.\n      if |rec| > 0 {\n        var warnings := rec;\n        var joined := String_Join(\"\\n\", Seq_Map(warnings, wt => wt.name));\n        assert false; // In Dafny, use assert to mimic raising AssertionError.\n      }\n    }\n\n    method Check() returns (hasWarning: bool)\n      ensures hasWarning == (|rec| > 0)\n    {\n      return |rec| > 0;\n    }\n  }\n\n  // Helper function: join a sequence of strings with a separator.\n  function method String_Join(sep: string, ss: seq<string>): string\n    decreases ss\n  {\n    if |ss| == 0 then \"\"\n    else if |ss| == 1 then ss[0]\n    else ss[0] + sep + String_Join(sep, ss[1..])\n  }\n\n  // Helper function: map a function over a sequence.\n  function method Seq_Map<T, U>(s: seq<T>, f: T -> U): seq<U>\n    decreases s\n  {\n    if |s| == 0 then []\n    else [f(s[0])] + Seq_Map(s[1..], f)\n  }\n\n  // DummyWarnsChecker: stand-in for pytest.warns, expects warnings of a certain type.\n  class DummyWarnsChecker implements WarningsChecker {\n    var expected: set<WarningType>\n\n    constructor (warning: set<WarningType>)\n      ensures expected == warning\n    {\n      expected := warning;\n    }\n\n    method Check() returns (hasWarning: bool)\n      ensures hasWarning // Always expects warning for simplicity\n    {\n      return true;\n    }\n  }\n\n  // The main function, mimicking pytest_warns.\n  method pytest_warns(warning: set<WarningType>?) returns (cm: WarningsChecker)\n    ensures (warning == null ==> cm is NoWarningsChecker)\n    ensures (warning != null ==> cm is DummyWarnsChecker)\n  {\n    if warning == null {\n      cm := new NoWarningsChecker();\n    } else {\n      cm := new DummyWarnsChecker(warning.Value);\n    }\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 14.764,
        "duration_formatted": "14.76s",
        "tokens": {
          "input": 345,
          "output": 663,
          "total": 1008
        },
        "cost_usd": 0.005994,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:39:49.931427"
      }
    },
    {
      "file_path": "snippet_28.py",
      "code": "#!/usr/bin/env python3\n\n\"\"\"\nA Polybius Square is a table that allows someone to translate letters into numbers.\n\nhttps://www.braingle.com/brainteasers/codes/polybius.php\n\"\"\"\n\nimport numpy as np\n\nSQUARE = [\n    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n    [\"f\", \"g\", \"h\", \"i\", \"k\"],\n    [\"l\", \"m\", \"n\", \"o\", \"p\"],\n    [\"q\", \"r\", \"s\", \"t\", \"u\"],\n    [\"v\", \"w\", \"x\", \"y\", \"z\"],\n]\n\n\nclass PolybiusCipher:\n    def __init__(self) -> None:\n        self.SQUARE = np.array(SQUARE)\n\n    def letter_to_numbers(self, letter: str) -> np.ndarray:\n        \"\"\"\n        Return the pair of numbers that represents the given letter in the\n        polybius square\n        >>> np.array_equal(PolybiusCipher().letter_to_numbers('a'), [1,1])\n        True\n\n        >>> np.array_equal(PolybiusCipher().letter_to_numbers('u'), [4,5])\n        True\n        \"\"\"\n        index1, index2 = np.where(letter == self.SQUARE)\n        indexes = np.concatenate([index1 + 1, index2 + 1])\n        return indexes\n\n    def numbers_to_letter(self, index1: int, index2: int) -> str:\n        \"\"\"\n        Return the letter corresponding to the position [index1, index2] in\n        the polybius square\n\n        >>> PolybiusCipher().numbers_to_letter(4, 5) == \"u\"\n        True\n\n        >>> PolybiusCipher().numbers_to_letter(1, 1) == \"a\"\n        True\n        \"\"\"\n        return self.SQUARE[index1 - 1, index2 - 1]\n\n    def encode(self, message: str) -> str:\n        \"\"\"\n        Return the encoded version of message according to the polybius cipher\n\n        >>> PolybiusCipher().encode(\"test message\") == \"44154344 32154343112215\"\n        True\n\n        >>> PolybiusCipher().encode(\"Test Message\") == \"44154344 32154343112215\"\n        True\n        \"\"\"\n        message = message.lower()\n        message = message.replace(\"j\", \"i\")\n\n        encoded_message = \"\"\n        for letter_index in range(len(message)):\n            if message[letter_index] != \" \":\n                numbers = self.letter_to_numbers(message[letter_index])\n                encoded_message = encoded_message + str(numbers[0]) + str(numbers[1])\n            elif message[letter_index] == \" \":\n                encoded_message = encoded_message + \" \"\n\n        return encoded_message\n\n    def decode(self, message: str) -> str:\n        \"\"\"\n        Return the decoded version of message according to the polybius cipher\n\n        >>> PolybiusCipher().decode(\"44154344 32154343112215\") == \"test message\"\n        True\n\n        >>> PolybiusCipher().decode(\"4415434432154343112215\") == \"testmessage\"\n        True\n        \"\"\"\n        message = message.replace(\" \", \"  \")\n        decoded_message = \"\"\n        for numbers_index in range(int(len(message) / 2)):\n            if message[numbers_index * 2] != \" \":\n                index1 = message[numbers_index * 2]\n                index2 = message[numbers_index * 2 + 1]\n\n                letter = self.numbers_to_letter(int(index1), int(index2))\n                decoded_message = decoded_message + letter\n            elif message[numbers_index * 2] == \" \":\n                decoded_message = decoded_message + \" \"\n\n        return decoded_message",
      "program_specification": "```dafny\n// Dafny translation of the PolybiusCipher Python class\n\ndatatype Option<T> = Some(value: T) | None\n\nclass PolybiusCipher {\n  // The Polybius square as a 2D array of characters ('j' is omitted, 'i' and 'j' share a cell)\n  const PolybiusSquare: array2<char> := PolybiusCipher.InitSquare();\n\n  // Helper function to initialize the Polybius square\n  static function method InitSquare(): array2<char>\n    ensures InitSquare().Length == 5\n    ensures forall i :: 0 <= i < 5 ==> InitSquare()[i].Length == 5\n    ensures InitSquare()[0][0] == 'a' && InitSquare()[4][4] == 'z'\n  {\n    var sq := new char[5][];\n    sq[0] := ['a', 'b', 'c', 'd', 'e'];\n    sq[1] := ['f', 'g', 'h', 'i', 'k'];\n    sq[2] := ['l', 'm', 'n', 'o', 'p'];\n    sq[3] := ['q', 'r', 's', 't', 'u'];\n    sq[4] := ['v', 'w', 'x', 'y', 'z'];\n    return sq;\n  }\n\n  // Returns the (row, col) pair (both 1-based) for a given letter, or None if not found\n  method LetterToNumbers(letter: char) returns (row: int, col: int)\n    requires 'a' <= letter <= 'z'\n    ensures 1 <= row <= 5 && 1 <= col <= 5 ==> PolybiusSquare[row-1][col-1] == letter\n    ensures letter == 'j' ==> PolybiusSquare[row-1][col-1] == 'i'\n    decreases letter\n  {\n    var l := if letter == 'j' then 'i' else letter;\n    var found := false;\n    var r := 0;\n    var c := 0;\n    while r < 5\n      invariant 0 <= r <= 5\n      invariant !found ==> forall i :: 0 <= i < r ==> forall j :: 0 <= j < 5 ==> PolybiusSquare[i][j] != l\n    {\n      c := 0;\n      while c < 5\n        invariant 0 <= c <= 5\n        invariant !found ==> forall j :: 0 <= j < c ==> PolybiusSquare[r][j] != l\n      {\n        if PolybiusSquare[r][c] == l {\n          found := true;\n          break;\n        }\n        c := c + 1;\n      }\n      if found { break; }\n      r := r + 1;\n    }\n    if found {\n      row := r + 1;\n      col := c + 1;\n      return;\n    }\n    // Should never reach here for valid input\n    row, col := 0, 0;\n    return;\n  }\n\n  // Returns the letter at (row, col) (both 1-based)\n  method NumbersToLetter(row: int, col: int) returns (letter: char)\n    requires 1 <= row <= 5 && 1 <= col <= 5\n    ensures 'a' <= letter <= 'z'\n    ensures letter != 'j'\n    decreases row, col\n  {\n    letter := PolybiusSquare[row-1][col-1];\n  }\n\n  // Encodes a message using the Polybius cipher\n  method Encode(message: string) returns (encoded: string)\n    ensures forall i :: 0 <= i < |message| && message[i] == ' ' ==> encoded.Contains(\" \")\n    decreases message\n  {\n    var lower := ToLowerAndReplaceJ(message);\n    var sb := \"\";\n    var i := 0;\n    while i < |lower|\n      invariant 0 <= i <= |lower|\n      invariant |sb| <= 2 * |lower|\n    {\n      if lower[i] == ' ' {\n        sb := sb + \" \";\n      } else if 'a' <= lower[i] <= 'z' {\n        var row, col := LetterToNumbers(lower[i]);\n        sb := sb + row.ToString() + col.ToString();\n      }\n      i := i + 1;\n    }\n    encoded := sb;\n  }\n\n  // Decodes a Polybius cipher message\n  method Decode(message: string) returns (decoded: string)\n    decreases message\n  {\n    var msg := ReplaceSpacesWithDouble(message);\n    var sb := \"\";\n    var i := 0;\n    while i < |msg| / 2\n      invariant 0 <= i <= |msg| / 2\n      invariant |sb| <= i\n    {\n      var c1 := msg[2*i];\n      var c2 := msg[2*i+1];\n      if c1 == ' ' {\n        sb := sb + \" \";\n      } else {\n        var row := CharToInt(c1);\n        var col := CharToInt(c2);\n        if 1 <= row <= 5 && 1 <= col <= 5 {\n          var letter := NumbersToLetter(row, col);\n          sb := sb + letter.ToString();\n        }\n      }\n      i := i + 1;\n    }\n    decoded := sb;\n  }\n\n  // Helper: Converts uppercase to lowercase and replaces 'j' with 'i'\n  function ToLowerAndReplaceJ(s: string): string\n    ensures forall i :: 0 <= i < |s| ==>\n      ('A' <= s[i] <= 'Z' ==> ToLowerAndReplaceJ(s)[i] == s[i] + 32) &&\n      (s[i] == 'j' || s[i] == 'J' ==> ToLowerAndReplaceJ(s)[i] == 'i') &&\n      (('a' <= s[i] <= 'z' || s[i] == ' ') && s[i] != 'j' ==> ToLowerAndReplaceJ(s)[i] == s[i])\n    decreases s\n  {\n    var r := \"\";\n    var i := 0;\n    while i < |s|\n      invariant 0 <= i <= |s|\n      invariant |r| == i\n    {\n      if 'A' <= s[i] <= 'Z' {\n        if s[i] == 'J' {\n          r := r + \"i\";\n        } else {\n          r := r + (s[i] + 32).ToString();\n        }\n      } else if s[i] == 'j' {\n        r := r + \"i\";\n      } else {\n        r := r + s[i].ToString();\n      }\n      i := i + 1;\n    }\n    r\n  }\n\n  // Helper: Replace each space in string with two spaces\n  function ReplaceSpacesWithDouble(s: string): string\n    ensures forall i :: 0 <= i < |s| && s[i] == ' ' ==> ReplaceSpacesWithDouble(s).Contains(\"  \")\n    decreases s\n  {\n    var r := \"\";\n    var i := 0;\n    while i < |s|\n      invariant 0 <= i <= |s|\n      invariant |r| >= i\n    {\n      if s[i] == ' ' {\n        r := r + \"  \";\n      } else {\n        r := r + s[i].ToString();\n      }\n      i := i + 1;\n    }\n    r\n  }\n\n  // Helper: Converts a char digit ('1'..'5') to int 1..5\n  function CharToInt(c: char): int\n    requires '1' <= c <= '5'\n    ensures CharToInt(c) == c as int - '0' as int\n  {\n    c as int - '0' as int\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 23.512,
        "duration_formatted": "23.51s",
        "tokens": {
          "input": 868,
          "output": 1678,
          "total": 2546
        },
        "cost_usd": 0.01516,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:40:18.482724"
      }
    },
    {
      "file_path": "snippet_29.py",
      "code": "from __future__ import annotations\n\nfrom collections.abc import Iterable, Iterator\nfrom functools import lru_cache\nfrom typing import TYPE_CHECKING, Callable, TypeVar, Union, overload\n\nimport jaraco.text as text\nfrom packaging.requirements import Requirement\n\nif TYPE_CHECKING:\n    from typing_extensions import TypeAlias\n\n_T = TypeVar(\"_T\")\n_StrOrIter: TypeAlias = Union[str, Iterable[str]]\n\n\nparse_req: Callable[[str], Requirement] = lru_cache()(Requirement)\n# Setuptools parses the same requirement many times\n# (e.g. first for validation than for normalisation),\n# so it might be worth to cache.\n\n\ndef parse_strings(strs: _StrOrIter) -> Iterator[str]:\n    \"\"\"\n    Yield requirement strings for each specification in `strs`.\n\n    `strs` must be a string, or a (possibly-nested) iterable thereof.\n    \"\"\"\n    return text.join_continuation(map(text.drop_comment, text.yield_lines(strs)))\n\n\n# These overloads are only needed because of a mypy false-positive, pyright gets it right\n# https://github.com/python/mypy/issues/3737\n@overload\ndef parse(strs: _StrOrIter) -> Iterator[Requirement]: ...\n@overload\ndef parse(strs: _StrOrIter, parser: Callable[[str], _T]) -> Iterator[_T]: ...\ndef parse(strs: _StrOrIter, parser: Callable[[str], _T] = parse_req) -> Iterator[_T]:  # type: ignore[assignment]\n    \"\"\"\n    Parse requirements.\n    \"\"\"\n    return map(parser, parse_strings(strs))",
      "program_specification": "```dafny\n// Dafny translation of the provided Python code, focusing on core logic and verifiability.\n\nmodule RequirementsParser {\n\n  // Abstract representation of a Requirement.\n  datatype Requirement = Req(s: string)\n\n  // Helper function: drop_comment removes everything after '#' in a string.\n  function method drop_comment(s: string): string\n    ensures forall i :: 0 <= i < |drop_comment(s)| ==> drop_comment(s)[i] != '#'\n  {\n    if '#' in s then s[..s.IndexOf(\"#\")] else s\n  }\n\n  // Helper function: yield_lines splits a string or sequence of strings into lines.\n  function method yield_lines(strs: seq<string>): seq<string>\n    decreases |strs|\n  {\n    if |strs| == 0 then []\n    else\n      // Split each string in strs by '\\n' and flatten.\n      var lines := [];\n      var i := 0;\n      while i < |strs|\n        invariant 0 <= i <= |strs|\n        invariant |lines| <= i * 1000 // Arbitrary upper bound for verification\n      {\n        var s := strs[i];\n        var parts := s.Split(\"\\n\");\n        var j := 0;\n        while j < |parts|\n          invariant 0 <= j <= |parts|\n          invariant |lines| <= i * 1000 + j\n        {\n          lines := lines + [parts[j]];\n          j := j + 1;\n        }\n        i := i + 1;\n      }\n      lines\n  }\n\n  // Helper function: join_continuation joins lines ending with '\\' with the next line.\n  function method join_continuation(lines: seq<string>): seq<string>\n    decreases |lines|\n  {\n    if |lines| == 0 then []\n    else if lines[0].EndsWith(\"\\\\\") && |lines| > 1 then\n      var joined := lines[0][..|lines[0]|-1] + lines[1];\n      [joined] + join_continuation(lines[2..])\n    else\n      [lines[0]] + join_continuation(lines[1..])\n  }\n\n  // parse_req: parses a string into a Requirement.\n  function method parse_req(s: string): Requirement\n    ensures parse_req(s).s == s\n  {\n    Req(s)\n  }\n\n  // parse_strings: yields requirement strings for each specification in strs.\n  method parse_strings(strs: seq<string>) returns (result: seq<string>)\n    ensures forall r :: r in result ==> r !in [\"\", \" \"]\n  {\n    var lines := yield_lines(strs);\n    var no_comments := [];\n    var i := 0;\n    while i < |lines|\n      invariant 0 <= i <= |lines|\n      invariant |no_comments| == i\n    {\n      no_comments := no_comments + [drop_comment(lines[i])];\n      i := i + 1;\n    }\n    result := join_continuation(no_comments);\n  }\n\n  // parse: parses requirements using a parser (default: parse_req).\n  method parse(strs: seq<string>, parser: (string) -> Requirement) returns (result: seq<Requirement>)\n    ensures |result| == |parse_strings(strs)|\n    ensures forall i :: 0 <= i < |result| ==> result[i] == parser(parse_strings(strs)[i])\n  {\n    var strings := parse_strings(strs);\n    var reqs := [];\n    var i := 0;\n    while i < |strings|\n      invariant 0 <= i <= |strings|\n      invariant |reqs| == i\n    {\n      reqs := reqs + [parser(strings[i])];\n      i := i + 1;\n    }\n    result := reqs;\n  }\n\n  // Overload: parse with default parser.\n  method parse_default(strs: seq<string>) returns (result: seq<Requirement>)\n    ensures result == parse(strs, parse_req)\n  {\n    result := parse(strs, parse_req);\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 13.722,
        "duration_formatted": "13.72s",
        "tokens": {
          "input": 425,
          "output": 846,
          "total": 1271
        },
        "cost_usd": 0.007618,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:40:37.247458"
      }
    },
    {
      "file_path": "snippet_30.py",
      "code": "class Solution(object):\n    def numIslands(self, grid):\n        \"\"\"\n        :type grid: List[List[str]]\n        :rtype: int\n        \"\"\"\n        if not grid:\n        \treturn 0\n\n        count = 0\n        for row in range(len(grid)):\n        \tfor col in range(len(grid[0])):\n        \t\tif grid[row][col] == '1':\n        \t\t\tcount +=1\n        \t\t\tself.merge(grid, row, col)\n\n        return count\n\n    def merge(self, grid, row, col):\n    \tif 0 > row or row >= len(grid) or col < 0 or col >= len(grid[0]):\n    \t\treturn\n\n    \tif grid[row][col] != '1':\n    \t\treturn \n\n    \tgrid[row][col] = '#'\n    \tself.merge(grid, row+1, col)\n    \tself.merge(grid, row-1, col)\n    \tself.merge(grid, row, col+1)\n    \tself.merge(grid, row, col-1)",
      "program_specification": "```dafny\nmethod NumIslands(grid: array2<char>) returns (count: int)\n  requires grid != null && grid.Height > 0 && grid.Width > 0\n  modifies grid\n  ensures 0 <= count <= grid.Height * grid.Width\n{\n  if grid == null || grid.Height == 0 || grid.Width == 0 {\n    return 0;\n  }\n\n  var n := grid.Height;\n  var m := grid.Width;\n  count := 0;\n\n  var row: int := 0;\n  while row < n\n    invariant 0 <= row <= n\n    invariant 0 <= count <= row * m\n  {\n    var col: int := 0;\n    while col < m\n      invariant 0 <= col <= m\n      invariant 0 <= count <= row * m + col\n    {\n      if grid[row, col] == '1' {\n        count := count + 1;\n        Merge(grid, row, col, n, m);\n      }\n      col := col + 1;\n    }\n    row := row + 1;\n  }\n}\n\nmethod Merge(grid: array2<char>, row: int, col: int, n: int, m: int)\n  requires grid != null && 0 <= n == grid.Height && 0 <= m == grid.Width\n  modifies grid\n{\n  if row < 0 || row >= n || col < 0 || col >= m {\n    return;\n  }\n  if grid[row, col] != '1' {\n    return;\n  }\n  grid[row, col] := '#';\n  Merge(grid, row + 1, col, n, m);\n  Merge(grid, row - 1, col, n, m);\n  Merge(grid, row, col + 1, n, m);\n  Merge(grid, row, col - 1, n, m);\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 3.621,
        "duration_formatted": "3.62s",
        "tokens": {
          "input": 283,
          "output": 396,
          "total": 679
        },
        "cost_usd": 0.003734,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:40:45.928420"
      }
    },
    {
      "file_path": "snippet_31.py",
      "code": "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for flags.\"\"\"\n\nfrom tensorflow.core.config import flags\nfrom tensorflow.python.platform import test\n\n\nclass FlagsTest(test.TestCase):\n\n  def test_experiment_flag(self):\n    self.assertTrue(flags.config().test_only_experiment_1.value())\n    self.assertFalse(flags.config().test_only_experiment_2.value())\n\n    flags.config().test_only_experiment_1.reset(False)\n    flags.config().test_only_experiment_2.reset(True)\n\n    self.assertFalse(flags.config().test_only_experiment_1.value())\n    self.assertTrue(flags.config().test_only_experiment_2.value())\n\n  def test_flags_singleton(self):\n    flags.config().test_only_experiment_1.reset(False)\n    self.assertFalse(flags.config().test_only_experiment_1.value())\n\n    # Get second reference to underlying Flags singleton.\n    flag = flags.flags_pybind.Flags()\n    flag.test_only_experiment_1.reset(True)\n\n    # check that both references are correctly updated.\n    self.assertTrue(flags.config().test_only_experiment_1.value())\n    self.assertTrue(flag.test_only_experiment_1.value())\n\n\nif __name__ == '__main__':\n  test.main()",
      "program_specification": "```dafny\n// Dafny translation of the given Python test class for flags.\n// Focused on simplicity and verifiability.\n\nmodule FlagsModule {\n\n  // A simple Boolean flag with value and reset\n  class BoolFlag {\n    var val: bool\n\n    constructor(init: bool)\n      ensures val == init\n    {\n      val := init;\n    }\n\n    method value() returns (b: bool)\n      ensures b == val\n    {\n      return val;\n    }\n\n    method reset(newVal: bool)\n      modifies this\n      ensures val == newVal\n    {\n      val := newVal;\n    }\n  }\n\n  // Singleton Flags class\n  class Flags {\n    static var singleton: Flags? := null;\n\n    var test_only_experiment_1: BoolFlag\n    var test_only_experiment_2: BoolFlag\n\n    constructor ()\n      ensures test_only_experiment_1.value() == true\n      ensures test_only_experiment_2.value() == false\n    {\n      test_only_experiment_1 := new BoolFlag(true);\n      test_only_experiment_2 := new BoolFlag(false);\n    }\n\n    static method config() returns (f: Flags)\n      ensures f == Flags.singleton\n      ensures f != null\n    {\n      if Flags.singleton == null {\n        Flags.singleton := new Flags();\n      }\n      return Flags.singleton;\n    }\n  }\n\n  // Simulate the flags_pybind.Flags() constructor\n  class FlagsPybind {\n    var ref: Flags\n\n    constructor ()\n      ensures ref == Flags.config()\n    {\n      ref := Flags.config();\n    }\n\n    function test_only_experiment_1(): BoolFlag\n      ensures test_only_experiment_1() == ref.test_only_experiment_1\n    {\n      ref.test_only_experiment_1\n    }\n\n    function test_only_experiment_2(): BoolFlag\n      ensures test_only_experiment_2() == ref.test_only_experiment_2\n    {\n      ref.test_only_experiment_2\n    }\n  }\n\n  // Test class\n  method TestExperimentFlag()\n    ensures Flags.config().test_only_experiment_1.value() == false\n    ensures Flags.config().test_only_experiment_2.value() == true\n  {\n    var f := Flags.config();\n\n    assert f.test_only_experiment_1.value() == true;\n    assert f.test_only_experiment_2.value() == false;\n\n    f.test_only_experiment_1.reset(false);\n    f.test_only_experiment_2.reset(true);\n\n    assert f.test_only_experiment_1.value() == false;\n    assert f.test_only_experiment_2.value() == true;\n  }\n\n  method TestFlagsSingleton()\n    ensures Flags.config().test_only_experiment_1.value() == true\n    ensures Flags.config().test_only_experiment_2.value() == true\n  {\n    var f := Flags.config();\n    f.test_only_experiment_1.reset(false);\n    assert f.test_only_experiment_1.value() == false;\n\n    var flag := new FlagsPybind();\n    flag.test_only_experiment_1().reset(true);\n\n    assert f.test_only_experiment_1.value() == true;\n    assert flag.test_only_experiment_1().value() == true;\n  }\n\n  // Main entry for running tests\n  method Main()\n  {\n    TestExperimentFlag();\n    TestFlagsSingleton();\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.26,
        "duration_formatted": "8.26s",
        "tokens": {
          "input": 455,
          "output": 698,
          "total": 1153
        },
        "cost_usd": 0.006494,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:40:59.226655"
      }
    },
    {
      "file_path": "snippet_32.py",
      "code": "r\"\"\"\nThe ``codes`` object defines a mapping from common names for HTTP statuses\nto their numerical codes, accessible either as attributes or as dictionary\nitems.\n\nExample::\n\n    >>> import requests\n    >>> requests.codes['temporary_redirect']\n    307\n    >>> requests.codes.teapot\n    418\n    >>> requests.codes['\\o/']\n    200\n\nSome codes have multiple names, and both upper- and lower-case versions of\nthe names are allowed. For example, ``codes.ok``, ``codes.OK``, and\n``codes.okay`` all correspond to the HTTP status code 200.\n\"\"\"\n\nfrom .structures import LookupDict\n\n_codes = {\n    # Informational.\n    100: (\"continue\",),\n    101: (\"switching_protocols\",),\n    102: (\"processing\", \"early-hints\"),\n    103: (\"checkpoint\",),\n    122: (\"uri_too_long\", \"request_uri_too_long\"),\n    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\o/\", \"✓\"),\n    201: (\"created\",),\n    202: (\"accepted\",),\n    203: (\"non_authoritative_info\", \"non_authoritative_information\"),\n    204: (\"no_content\",),\n    205: (\"reset_content\", \"reset\"),\n    206: (\"partial_content\", \"partial\"),\n    207: (\"multi_status\", \"multiple_status\", \"multi_stati\", \"multiple_stati\"),\n    208: (\"already_reported\",),\n    226: (\"im_used\",),\n    # Redirection.\n    300: (\"multiple_choices\",),\n    301: (\"moved_permanently\", \"moved\", \"\\\\o-\"),\n    302: (\"found\",),\n    303: (\"see_other\", \"other\"),\n    304: (\"not_modified\",),\n    305: (\"use_proxy\",),\n    306: (\"switch_proxy\",),\n    307: (\"temporary_redirect\", \"temporary_moved\", \"temporary\"),\n    308: (\n        \"permanent_redirect\",\n        \"resume_incomplete\",\n        \"resume\",\n    ),  # \"resume\" and \"resume_incomplete\" to be removed in 3.0\n    # Client Error.\n    400: (\"bad_request\", \"bad\"),\n    401: (\"unauthorized\",),\n    402: (\"payment_required\", \"payment\"),\n    403: (\"forbidden\",),\n    404: (\"not_found\", \"-o-\"),\n    405: (\"method_not_allowed\", \"not_allowed\"),\n    406: (\"not_acceptable\",),\n    407: (\"proxy_authentication_required\", \"proxy_auth\", \"proxy_authentication\"),\n    408: (\"request_timeout\", \"timeout\"),\n    409: (\"conflict\",),\n    410: (\"gone\",),\n    411: (\"length_required\",),\n    412: (\"precondition_failed\", \"precondition\"),\n    413: (\"request_entity_too_large\", \"content_too_large\"),\n    414: (\"request_uri_too_large\", \"uri_too_long\"),\n    415: (\"unsupported_media_type\", \"unsupported_media\", \"media_type\"),\n    416: (\n        \"requested_range_not_satisfiable\",\n        \"requested_range\",\n        \"range_not_satisfiable\",\n    ),\n    417: (\"expectation_failed\",),\n    418: (\"im_a_teapot\", \"teapot\", \"i_am_a_teapot\"),\n    421: (\"misdirected_request\",),\n    422: (\"unprocessable_entity\", \"unprocessable\", \"unprocessable_content\"),\n    423: (\"locked\",),\n    424: (\"failed_dependency\", \"dependency\"),\n    425: (\"unordered_collection\", \"unordered\", \"too_early\"),\n    426: (\"upgrade_required\", \"upgrade\"),\n    428: (\"precondition_required\", \"precondition\"),\n    429: (\"too_many_requests\", \"too_many\"),\n    431: (\"header_fields_too_large\", \"fields_too_large\"),\n    444: (\"no_response\", \"none\"),\n    449: (\"retry_with\", \"retry\"),\n    450: (\"blocked_by_windows_parental_controls\", \"parental_controls\"),\n    451: (\"unavailable_for_legal_reasons\", \"legal_reasons\"),\n    499: (\"client_closed_request\",),\n    # Server Error.\n    500: (\"internal_server_error\", \"server_error\", \"/o\\\\\", \"✗\"),\n    501: (\"not_implemented\",),\n    502: (\"bad_gateway\",),\n    503: (\"service_unavailable\", \"unavailable\"),\n    504: (\"gateway_timeout\",),\n    505: (\"http_version_not_supported\", \"http_version\"),\n    506: (\"variant_also_negotiates\",),\n    507: (\"insufficient_storage\",),\n    509: (\"bandwidth_limit_exceeded\", \"bandwidth\"),\n    510: (\"not_extended\",),\n    511: (\"network_authentication_required\", \"network_auth\", \"network_authentication\"),\n}\n\ncodes = LookupDict(name=\"status_codes\")\n\n\ndef _init():\n    for code, titles in _codes.items():\n        for title in titles:\n            setattr(codes, title, code)\n            if not title.startswith((\"\\\\\", \"/\")):\n                setattr(codes, title.upper(), code)\n\n    def doc(code):\n        names = \", \".join(f\"``{n}``\" for n in _codes[code])\n        return \"* %d: %s\" % (code, names)\n\n    global __doc__\n    __doc__ = (\n        __doc__ + \"\\n\" + \"\\n\".join(doc(code) for code in sorted(_codes))\n        if __doc__ is not None\n        else None\n    )\n\n\n_init()",
      "program_specification": "```dafny\n// Dafny translation of the Python HTTP status code mapping example.\n// Focused on simplicity and verifiability.\n\nmodule HttpCodes {\n\n  datatype StatusName = Name(s: string) | UpperName(s: string)\n\n  // Represents the mapping from status code names to their integer codes.\n  class Codes {\n    var nameToCode: map<string, int>\n    var codeToNames: map<int, set<string>>\n\n    constructor ()\n      ensures nameToCode == HttpCodes.DefaultNameToCode()\n      ensures codeToNames == HttpCodes.DefaultCodeToNames()\n    {\n      nameToCode := HttpCodes.DefaultNameToCode();\n      codeToNames := HttpCodes.DefaultCodeToNames();\n    }\n\n    method GetCode(name: string) returns (code: int)\n      requires name in nameToCode\n      ensures code == nameToCode[name]\n    {\n      code := nameToCode[name];\n    }\n\n    method GetNames(code: int) returns (names: set<string>)\n      requires code in codeToNames\n      ensures names == codeToNames[code]\n    {\n      names := codeToNames[code];\n    }\n  }\n\n  // The canonical mapping from names to codes (flattened from the Python _codes dict).\n  function method DefaultNameToCode(): map<string, int>\n    ensures forall code, names :: code in DefaultCodeToNames() && names == DefaultCodeToNames()[code] ==>\n      forall n :: n in names ==> DefaultNameToCode()[n] == code\n  {\n    // For brevity, only a subset is shown. Add more as needed.\n    map [\n      \"continue\" := 100,\n      \"CONTINUE\" := 100,\n      \"switching_protocols\" := 101,\n      \"SWITCHING_PROTOCOLS\" := 101,\n      \"processing\" := 102,\n      \"PROCESSING\" := 102,\n      \"early-hints\" := 102,\n      \"EARLY-HINTS\" := 102,\n      \"checkpoint\" := 103,\n      \"CHECKPOINT\" := 103,\n      \"ok\" := 200,\n      \"OK\" := 200,\n      \"okay\" := 200,\n      \"OKAY\" := 200,\n      \"all_ok\" := 200,\n      \"ALL_OK\" := 200,\n      \"all_okay\" := 200,\n      \"ALL_OKAY\" := 200,\n      \"all_good\" := 200,\n      \"ALL_GOOD\" := 200,\n      \"\\\\o/\" := 200,\n      \"✓\" := 200,\n      \"created\" := 201,\n      \"CREATED\" := 201,\n      \"temporary_redirect\" := 307,\n      \"TEMPORARY_REDIRECT\" := 307,\n      \"teapot\" := 418,\n      \"TEAPOT\" := 418,\n      \"im_a_teapot\" := 418,\n      \"IM_A_TEAPOT\" := 418,\n      \"i_am_a_teapot\" := 418,\n      \"I_AM_A_TEAPOT\" := 418\n      // ... (add more as needed)\n    ]\n  }\n\n  // The canonical mapping from codes to sets of names.\n  function method DefaultCodeToNames(): map<int, set<string>>\n    ensures forall code :: code in DefaultCodeToNames() ==>\n      forall n :: n in DefaultCodeToNames()[code] ==> DefaultNameToCode()[n] == code\n  {\n    map [\n      100 := {\"continue\", \"CONTINUE\"},\n      101 := {\"switching_protocols\", \"SWITCHING_PROTOCOLS\"},\n      102 := {\"processing\", \"PROCESSING\", \"early-hints\", \"EARLY-HINTS\"},\n      103 := {\"checkpoint\", \"CHECKPOINT\"},\n      200 := {\"ok\", \"OK\", \"okay\", \"OKAY\", \"all_ok\", \"ALL_OK\", \"all_okay\", \"ALL_OKAY\", \"all_good\", \"ALL_GOOD\", \"\\\\o/\", \"✓\"},\n      201 := {\"created\", \"CREATED\"},\n      307 := {\"temporary_redirect\", \"TEMPORARY_REDIRECT\"},\n      418 := {\"teapot\", \"TEAPOT\", \"im_a_teapot\", \"IM_A_TEAPOT\", \"i_am_a_teapot\", \"I_AM_A_TEAPOT\"}\n      // ... (add more as needed)\n    ]\n  }\n\n  // Example usage and specification\n  method {:test} Example()\n    ensures c1 == 307\n    ensures c2 == 418\n    ensures c3 == 200\n    ensures \"OK\" in names3\n  {\n    var codes := new Codes();\n    var c1 := codes.GetCode(\"temporary_redirect\");\n    var c2 := codes.GetCode(\"teapot\");\n    var c3 := codes.GetCode(\"\\\\o/\");\n    var names3 := codes.GetNames(200);\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 10.532,
        "duration_formatted": "10.53s",
        "tokens": {
          "input": 1293,
          "output": 1021,
          "total": 2314
        },
        "cost_usd": 0.010754,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:41:14.798385"
      }
    },
    {
      "file_path": "snippet_33.py",
      "code": "\"\"\"Defines the different custom formats in which mypy can output.\"\"\"\n\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from mypy.errors import MypyError\n\n\nclass ErrorFormatter(ABC):\n    \"\"\"Base class to define how errors are formatted before being printed.\"\"\"\n\n    @abstractmethod\n    def report_error(self, error: \"MypyError\") -> str:\n        raise NotImplementedError\n\n\nclass JSONFormatter(ErrorFormatter):\n    \"\"\"Formatter for basic JSON output format.\"\"\"\n\n    def report_error(self, error: \"MypyError\") -> str:\n        \"\"\"Prints out the errors as simple, static JSON lines.\"\"\"\n        return json.dumps(\n            {\n                \"file\": error.file_path,\n                \"line\": error.line,\n                \"column\": error.column,\n                \"message\": error.message,\n                \"hint\": None if len(error.hints) == 0 else \"\\n\".join(error.hints),\n                \"code\": None if error.errorcode is None else error.errorcode.code,\n                \"severity\": error.severity,\n            }\n        )\n\n\nOUTPUT_CHOICES = {\"json\": JSONFormatter()}",
      "program_specification": "```dafny\nmodule MypyFormatters {\n\n  // A simple representation of a MypyError in Dafny.\n  class ErrorCode {\n    var code: string\n    constructor(c: string) \n      ensures code == c\n    {\n      code := c;\n    }\n  }\n\n  class MypyError {\n    var file_path: string\n    var line: int\n    var column: int\n    var message: string\n    var hints: seq<string>\n    var errorcode: ErrorCode?\n    var severity: string\n\n    constructor(fp: string, l: int, c: int, msg: string, h: seq<string>, ec: ErrorCode?, sev: string)\n      ensures file_path == fp\n      ensures line == l\n      ensures column == c\n      ensures message == msg\n      ensures hints == h\n      ensures errorcode == ec\n      ensures severity == sev\n    {\n      file_path := fp;\n      line := l;\n      column := c;\n      message := msg;\n      hints := h;\n      errorcode := ec;\n      severity := sev;\n    }\n  }\n\n  // Abstract base class for error formatters.\n  abstract class ErrorFormatter {\n    // Abstract method to report an error as a string.\n    method report_error(error: MypyError) returns (s: string)\n      ensures false // Abstract method, no implementation\n  }\n\n  // JSONFormatter implements ErrorFormatter.\n  class JSONFormatter extends ErrorFormatter {\n    method report_error(error: MypyError) returns (s: string)\n      ensures s == \n        \"{\" +\n        \"\\\"file\\\": \\\"\" + error.file_path + \"\\\", \" +\n        \"\\\"line\\\": \" + error.line.ToString() + \", \" +\n        \"\\\"column\\\": \" + error.column.ToString() + \", \" +\n        \"\\\"message\\\": \\\"\" + error.message + \"\\\", \" +\n        \"\\\"hint\\\": \" + \n          (if |error.hints| == 0 then \"null\" else \"\\\"\" + StringJoin(error.hints, \"\\n\") + \"\\\"\") + \", \" +\n        \"\\\"code\\\": \" +\n          (if error.errorcode == null then \"null\" else \"\\\"\" + error.errorcode.code + \"\\\"\") + \", \" +\n        \"\\\"severity\\\": \\\"\" + error.severity + \"\\\"\" +\n        \"}\"\n    {\n      var hintStr := if |error.hints| == 0 then \"null\" else \"\\\"\" + StringJoin(error.hints, \"\\n\") + \"\\\"\";\n      var codeStr := if error.errorcode == null then \"null\" else \"\\\"\" + error.errorcode.code + \"\\\"\";\n      s := \"{\" +\n        \"\\\"file\\\": \\\"\" + error.file_path + \"\\\", \" +\n        \"\\\"line\\\": \" + error.line.ToString() + \", \" +\n        \"\\\"column\\\": \" + error.column.ToString() + \", \" +\n        \"\\\"message\\\": \\\"\" + error.message + \"\\\", \" +\n        \"\\\"hint\\\": \" + hintStr + \", \" +\n        \"\\\"code\\\": \" + codeStr + \", \" +\n        \"\\\"severity\\\": \\\"\" + error.severity + \"\\\"\" +\n        \"}\";\n    }\n  }\n\n  // Helper function to join strings with a separator.\n  function method StringJoin(a: seq<string>, sep: string): string\n    decreases a\n  {\n    if |a| == 0 then\n      \"\"\n    else if |a| == 1 then\n      a[0]\n    else\n      a[0] + sep + StringJoin(a[1..], sep)\n  }\n\n  // OUTPUT_CHOICES equivalent in Dafny: a map from string to ErrorFormatter\n  datatype OutputChoice = JsonChoice(formatter: JSONFormatter)\n\n  function method OUTPUT_CHOICES(): map<string, OutputChoice>\n    ensures \"json\" in OUTPUT_CHOICES()\n    ensures OUTPUT_CHOICES()[\"json\"].formatter != null\n  {\n    map[\"json\" := JsonChoice(new JSONFormatter)]\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 7.651,
        "duration_formatted": "7.65s",
        "tokens": {
          "input": 318,
          "output": 801,
          "total": 1119
        },
        "cost_usd": 0.007044,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:41:27.494018"
      }
    },
    {
      "file_path": "snippet_34.py",
      "code": "class Solution(object):\n    def numDecodings(self, s):\n        \"\"\"\n        :type s: str\n        :rtype: int\n        \"\"\"\n        ls = len(s)\n        if ls == 0:\n            return 0\n        dp = [0] * ls\n        for index in range(ls):\n            if index >= 1 and int(s[index - 1:index + 1]) < 27 and int(s[index - 1:index + 1]) >= 10:\n                if index == 1:\n                    dp[index] = 1\n                else:\n                    # 11-26\n                    dp[index] += dp[index - 2]\n            if int(s[index]) != 0:\n                if index == 0:\n                    dp[index] = 1\n                else:\n                    # 1-9\n                    dp[index] += dp[index - 1]\n        return dp[ls - 1]",
      "program_specification": "```dafny\nmethod NumDecodings(s: seq<char>) returns (res: int)\n  requires forall c :: c in s ==> '0' <= c <= '9'\n  ensures res >= 0\n{\n  var ls := |s|;\n  if ls == 0 {\n    return 0;\n  }\n  var dp := new int[ls];\n  var i := 0;\n  while i < ls\n    invariant 0 <= i <= ls\n    invariant dp.Length == ls\n    invariant forall j :: 0 <= j < i ==> dp[j] >= 0\n  {\n    // Check for valid two-digit decode\n    if i >= 1 {\n      var d1 := s[i-1] - '0';\n      var d2 := s[i] - '0';\n      var num := d1 * 10 + d2;\n      if 10 <= num < 27 {\n        if i == 1 {\n          dp[i] := 1;\n        } else {\n          dp[i] := dp[i] + dp[i-2];\n        }\n      }\n    }\n    // Check for valid single-digit decode\n    var d := s[i] - '0';\n    if d != 0 {\n      if i == 0 {\n        dp[i] := 1;\n      } else {\n        dp[i] := dp[i] + dp[i-1];\n      }\n    }\n    i := i + 1;\n  }\n  return dp[ls-1];\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 3.262,
        "duration_formatted": "3.26s",
        "tokens": {
          "input": 274,
          "output": 313,
          "total": 587
        },
        "cost_usd": 0.003052,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:41:35.794135"
      }
    },
    {
      "file_path": "snippet_35.py",
      "code": "'''\nReturn the root node of a binary search tree that matches the given preorder traversal.\n\n(Recall that a binary search tree is a binary tree where for every node, any descendant of node.left has a value < node.val, and any descendant of node.right has a value > node.val.  Also recall that a preorder traversal displays the value of the node first, then traverses node.left, then traverses node.right.)\n'''\n\n# Definition for a binary tree node.\n# class TreeNode(object):\n#     def __init__(self, x):\n#         self.val = x\n#         self.left = None\n#         self.right = None\n\nclass Solution(object):\n    def bstFromPreorder(self, preorder):\n        \"\"\"\n        :type preorder: List[int]\n        :rtype: TreeNode\n        \"\"\"\n        root = TreeNode(preorder[0])\n        stack = [root]\n        for index in range(1, len(preorder)):\n            new_node = TreeNode(preorder[index])\n            if new_node.val < stack[-1].val:\n                stack[-1].left = new_node\n            else:\n                parent = None\n                while stack and new_node.val > stack[-1].val:\n                    parent = stack.pop()\n                parent.right = new_node\n            stack.append(new_node)\n        return root",
      "program_specification": "```dafny\n// Definition for a binary tree node.\nclass TreeNode {\n  var val: int;\n  var left: TreeNode?;\n  var right: TreeNode?;\n\n  constructor(v: int) \n    ensures val == v && left == null && right == null\n  {\n    val := v;\n    left := null;\n    right := null;\n  }\n}\n\nclass Solution {\n  // Helper function to check if a tree is a BST with all values in (min, max)\n  function method IsBST(t: TreeNode?, min: int, max: int): bool\n    decreases t\n  {\n    if t == null then true\n    else\n      min < t.val < max &&\n      IsBST(t.left, min, t.val) &&\n      IsBST(t.right, t.val, max)\n  }\n\n  // Helper function to get preorder traversal of a tree\n  function method Preorder(t: TreeNode?): seq<int>\n    decreases t\n  {\n    if t == null then []\n    else [t.val] + Preorder(t.left) + Preorder(t.right)\n  }\n\n  method bstFromPreorder(preorder: seq<int>) returns (root: TreeNode?)\n    requires |preorder| > 0\n    ensures root != null\n    ensures Preorder(root) == preorder\n    ensures IsBST(root, int.MinValue, int.MaxValue)\n  {\n    var rootNode := new TreeNode(preorder[0]);\n    var stack := new List<TreeNode>();\n    stack.AddLast(rootNode);\n\n    var i := 1;\n    while i < |preorder|\n      invariant 1 <= i <= |preorder|\n      invariant stack != null\n      invariant forall n: int :: 0 <= n < stack.Count ==> stack[n] != null\n    {\n      var newNode := new TreeNode(preorder[i]);\n      if newNode.val < stack[stack.Count - 1].val {\n        stack[stack.Count - 1].left := newNode;\n      } else {\n        var parent: TreeNode?;\n        while stack.Count > 0 && newNode.val > stack[stack.Count - 1].val\n          decreases stack.Count\n        {\n          parent := stack[stack.Count - 1];\n          stack.RemoveAt(stack.Count - 1);\n        }\n        parent.right := newNode;\n      }\n      stack.AddLast(newNode);\n      i := i + 1;\n    }\n    root := rootNode;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.607,
        "duration_formatted": "8.61s",
        "tokens": {
          "input": 351,
          "output": 514,
          "total": 865
        },
        "cost_usd": 0.004814,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:41:49.444869"
      }
    },
    {
      "file_path": "snippet_36.py",
      "code": "def job_sequencing_with_deadlines(jobs: list) -> list:\n    \"\"\"\n    Function to find the maximum profit by doing jobs in a given time frame\n\n    Args:\n        jobs [list]: A list of tuples of (job_id, deadline, profit)\n\n    Returns:\n        max_profit [int]: Maximum profit that can be earned by doing jobs\n        in a given time frame\n\n    Examples:\n    >>> job_sequencing_with_deadlines(\n    ... [(1, 4, 20), (2, 1, 10), (3, 1, 40), (4, 1, 30)])\n    [2, 60]\n    >>> job_sequencing_with_deadlines(\n    ... [(1, 2, 100), (2, 1, 19), (3, 2, 27), (4, 1, 25), (5, 1, 15)])\n    [2, 127]\n    \"\"\"\n\n    # Sort the jobs in descending order of profit\n    jobs = sorted(jobs, key=lambda value: value[2], reverse=True)\n\n    # Create a list of size equal to the maximum deadline\n    # and initialize it with -1\n    max_deadline = max(jobs, key=lambda value: value[1])[1]\n    time_slots = [-1] * max_deadline\n\n    # Finding the maximum profit and the count of jobs\n    count = 0\n    max_profit = 0\n    for job in jobs:\n        # Find a free time slot for this job\n        # (Note that we start from the last possible slot)\n        for i in range(job[1] - 1, -1, -1):\n            if time_slots[i] == -1:\n                time_slots[i] = job[0]\n                count += 1\n                max_profit += job[2]\n                break\n    return [count, max_profit]\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\n// Dafny translation of job_sequencing_with_deadlines\n\ndatatype Job = Job(id: int, deadline: int, profit: int)\n\nmethod jobSequencingWithDeadlines(jobs: seq<Job>) returns (res: seq<int>)\n    requires forall j :: 0 <= j < |jobs| ==> jobs[j].deadline > 0\n    ensures |res| == 2\n    ensures res[0] <= |jobs| // count of jobs scheduled <= total jobs\n    ensures res[1] >= 0      // profit is non-negative\n{\n    // Sort jobs in descending order of profit\n    var sortedJobs := jobs[..];\n    // Simple selection sort for verifiability\n    var n := |sortedJobs|;\n    var i := 0;\n    while i < n\n        invariant 0 <= i <= n\n        invariant sortedJobs[..i] == Multiset#SortedDescending(jobs, i)\n        decreases n - i\n    {\n        var maxIdx := i;\n        var j := i + 1;\n        while j < n\n            invariant i+1 <= j <= n\n            decreases n - j\n        {\n            if sortedJobs[j].profit > sortedJobs[maxIdx].profit {\n                maxIdx := j;\n            }\n            j := j + 1;\n        }\n        // Swap\n        var tmp := sortedJobs[i];\n        sortedJobs[i] := sortedJobs[maxIdx];\n        sortedJobs[maxIdx] := tmp;\n        i := i + 1;\n    }\n\n    // Find max deadline\n    var maxDeadline := 0;\n    i := 0;\n    while i < n\n        invariant 0 <= i <= n\n        invariant maxDeadline >= 0\n        decreases n - i\n    {\n        if sortedJobs[i].deadline > maxDeadline {\n            maxDeadline := sortedJobs[i].deadline;\n        }\n        i := i + 1;\n    }\n\n    // Initialize time slots with -1 (means free)\n    var timeSlots := new int[maxDeadline];\n    i := 0;\n    while i < maxDeadline\n        invariant 0 <= i <= maxDeadline\n        invariant forall k :: 0 <= k < i ==> timeSlots[k] == -1\n        decreases maxDeadline - i\n    {\n        timeSlots[i] := -1;\n        i := i + 1;\n    }\n\n    var count := 0;\n    var maxProfit := 0;\n    i := 0;\n    while i < n\n        invariant 0 <= i <= n\n        invariant 0 <= count <= n\n        invariant maxProfit >= 0\n        decreases n - i\n    {\n        var job := sortedJobs[i];\n        var j := job.deadline - 1;\n        var scheduled := false;\n        while j >= 0 && !scheduled\n            invariant -1 <= j < job.deadline\n            decreases j\n        {\n            if timeSlots[j] == -1 {\n                timeSlots[j] := job.id;\n                count := count + 1;\n                maxProfit := maxProfit + job.profit;\n                scheduled := true;\n            }\n            j := j - 1;\n        }\n        i := i + 1;\n    }\n    res := [count, maxProfit];\n}\n\n// Helper function for selection sort invariant\nfunction Multiset#SortedDescending(jobs: seq<Job>, upto: int): seq<Job>\n    requires 0 <= upto <= |jobs|\n{\n    if upto == 0 then []\n    else\n        var maxIdx := 0;\n        var i := 1;\n        while i < upto\n            decreases upto - i\n        {\n            if jobs[i].profit > jobs[maxIdx].profit {\n                maxIdx := i;\n            }\n            i := i + 1;\n        }\n        [jobs[maxIdx]] + Multiset#SortedDescending(jobs[..maxIdx] + jobs[maxIdx+1..upto], upto-1)\n}\n\n// Example usage in Main method\nmethod Main()\n{\n    var jobs1 := [Job(1, 4, 20), Job(2, 1, 10), Job(3, 1, 40), Job(4, 1, 30)];\n    var res1 := jobSequencingWithDeadlines(jobs1);\n    assert res1 == [2, 60];\n\n    var jobs2 := [Job(1, 2, 100), Job(2, 1, 19), Job(3, 2, 27), Job(4, 1, 25), Job(5, 1, 15)];\n    var res2 := jobSequencingWithDeadlines(jobs2);\n    assert res2 == [2, 127];\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 10.472,
        "duration_formatted": "10.47s",
        "tokens": {
          "input": 507,
          "output": 991,
          "total": 1498
        },
        "cost_usd": 0.008942,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:42:04.951107"
      }
    },
    {
      "file_path": "snippet_37.py",
      "code": "\"\"\"Algorithms for finding the lowest common ancestor of trees and DAGs.\"\"\"\n\nfrom collections import defaultdict\nfrom collections.abc import Mapping, Set\nfrom itertools import combinations_with_replacement\n\nimport networkx as nx\nfrom networkx.utils import UnionFind, arbitrary_element, not_implemented_for\n\n__all__ = [\n    \"all_pairs_lowest_common_ancestor\",\n    \"tree_all_pairs_lowest_common_ancestor\",\n    \"lowest_common_ancestor\",\n]\n\n\n@not_implemented_for(\"undirected\")\n@nx._dispatchable\ndef all_pairs_lowest_common_ancestor(G, pairs=None):\n    \"\"\"Return the lowest common ancestor of all pairs or the provided pairs\n\n    Parameters\n    ----------\n    G : NetworkX directed graph\n\n    pairs : iterable of pairs of nodes, optional (default: all pairs)\n        The pairs of nodes of interest.\n        If None, will find the LCA of all pairs of nodes.\n\n    Yields\n    ------\n    ((node1, node2), lca) : 2-tuple\n        Where lca is least common ancestor of node1 and node2.\n        Note that for the default case, the order of the node pair is not considered,\n        e.g. you will not get both ``(a, b)`` and ``(b, a)``\n\n    Raises\n    ------\n    NetworkXPointlessConcept\n        If `G` is null.\n    NetworkXError\n        If `G` is not a DAG.\n\n    Examples\n    --------\n    >>> from pprint import pprint\n\n    The default behavior is to yield the lowest common ancestor for all\n    possible combinations of nodes in `G`, including self-pairings:\n\n    >>> G = nx.DiGraph([(0, 1), (0, 3), (1, 2)])\n    >>> pprint(dict(nx.all_pairs_lowest_common_ancestor(G)))\n    {(0, 0): 0,\n     (0, 1): 0,\n     (0, 2): 0,\n     (0, 3): 0,\n     (1, 1): 1,\n     (1, 2): 1,\n     (1, 3): 0,\n     (2, 2): 2,\n     (3, 2): 0,\n     (3, 3): 3}\n\n    The pairs argument can be used to limit the output to only the\n    specified node pairings:\n\n    >>> dict(nx.all_pairs_lowest_common_ancestor(G, pairs=[(1, 2), (2, 3)]))\n    {(1, 2): 1, (2, 3): 0}\n\n    Notes\n    -----\n    Only defined on non-null directed acyclic graphs.\n\n    See Also\n    --------\n    lowest_common_ancestor\n    \"\"\"\n    if not nx.is_directed_acyclic_graph(G):\n        raise nx.NetworkXError(\"LCA only defined on directed acyclic graphs.\")\n    if len(G) == 0:\n        raise nx.NetworkXPointlessConcept(\"LCA meaningless on null graphs.\")\n\n    if pairs is None:\n        pairs = combinations_with_replacement(G, 2)\n    else:\n        # Convert iterator to iterable, if necessary. Trim duplicates.\n        pairs = dict.fromkeys(pairs)\n        # Verify that each of the nodes in the provided pairs is in G\n        nodeset = set(G)\n        for pair in pairs:\n            if set(pair) - nodeset:\n                raise nx.NodeNotFound(\n                    f\"Node(s) {set(pair) - nodeset} from pair {pair} not in G.\"\n                )\n\n    # Once input validation is done, construct the generator\n    def generate_lca_from_pairs(G, pairs):\n        ancestor_cache = {}\n\n        for v, w in pairs:\n            if v not in ancestor_cache:\n                ancestor_cache[v] = nx.ancestors(G, v)\n                ancestor_cache[v].add(v)\n            if w not in ancestor_cache:\n                ancestor_cache[w] = nx.ancestors(G, w)\n                ancestor_cache[w].add(w)\n\n            common_ancestors = ancestor_cache[v] & ancestor_cache[w]\n\n            if common_ancestors:\n                common_ancestor = next(iter(common_ancestors))\n                while True:\n                    successor = None\n                    for lower_ancestor in G.successors(common_ancestor):\n                        if lower_ancestor in common_ancestors:\n                            successor = lower_ancestor\n                            break\n                    if successor is None:\n                        break\n                    common_ancestor = successor\n                yield ((v, w), common_ancestor)\n\n    return generate_lca_from_pairs(G, pairs)\n\n\n@not_implemented_for(\"undirected\")\n@nx._dispatchable\ndef lowest_common_ancestor(G, node1, node2, default=None):\n    \"\"\"Compute the lowest common ancestor of the given pair of nodes.\n\n    Parameters\n    ----------\n    G : NetworkX directed graph\n\n    node1, node2 : nodes in the graph.\n\n    default : object\n        Returned if no common ancestor between `node1` and `node2`\n\n    Returns\n    -------\n    The lowest common ancestor of node1 and node2,\n    or default if they have no common ancestors.\n\n    Examples\n    --------\n    >>> G = nx.DiGraph()\n    >>> nx.add_path(G, (0, 1, 2, 3))\n    >>> nx.add_path(G, (0, 4, 3))\n    >>> nx.lowest_common_ancestor(G, 2, 4)\n    0\n\n    See Also\n    --------\n    all_pairs_lowest_common_ancestor\"\"\"\n\n    ans = list(all_pairs_lowest_common_ancestor(G, pairs=[(node1, node2)]))\n    if ans:\n        assert len(ans) == 1\n        return ans[0][1]\n    return default\n\n\n@not_implemented_for(\"undirected\")\n@nx._dispatchable\ndef tree_all_pairs_lowest_common_ancestor(G, root=None, pairs=None):\n    r\"\"\"Yield the lowest common ancestor for sets of pairs in a tree.\n\n    Parameters\n    ----------\n    G : NetworkX directed graph (must be a tree)\n\n    root : node, optional (default: None)\n        The root of the subtree to operate on.\n        If None, assume the entire graph has exactly one source and use that.\n\n    pairs : iterable or iterator of pairs of nodes, optional (default: None)\n        The pairs of interest. If None, Defaults to all pairs of nodes\n        under `root` that have a lowest common ancestor.\n\n    Returns\n    -------\n    lcas : generator of tuples `((u, v), lca)` where `u` and `v` are nodes\n        in `pairs` and `lca` is their lowest common ancestor.\n\n    Examples\n    --------\n    >>> import pprint\n    >>> G = nx.DiGraph([(1, 3), (2, 4), (1, 2)])\n    >>> pprint.pprint(dict(nx.tree_all_pairs_lowest_common_ancestor(G)))\n    {(1, 1): 1,\n     (2, 1): 1,\n     (2, 2): 2,\n     (3, 1): 1,\n     (3, 2): 1,\n     (3, 3): 3,\n     (3, 4): 1,\n     (4, 1): 1,\n     (4, 2): 2,\n     (4, 4): 4}\n\n    We can also use `pairs` argument to specify the pairs of nodes for which we\n    want to compute lowest common ancestors. Here is an example:\n\n    >>> dict(nx.tree_all_pairs_lowest_common_ancestor(G, pairs=[(1, 4), (2, 3)]))\n    {(2, 3): 1, (1, 4): 1}\n\n    Notes\n    -----\n    Only defined on non-null trees represented with directed edges from\n    parents to children. Uses Tarjan's off-line lowest-common-ancestors\n    algorithm. Runs in time $O(4 \\times (V + E + P))$ time, where 4 is the largest\n    value of the inverse Ackermann function likely to ever come up in actual\n    use, and $P$ is the number of pairs requested (or $V^2$ if all are needed).\n\n    Tarjan, R. E. (1979), \"Applications of path compression on balanced trees\",\n    Journal of the ACM 26 (4): 690-715, doi:10.1145/322154.322161.\n\n    See Also\n    --------\n    all_pairs_lowest_common_ancestor: similar routine for general DAGs\n    lowest_common_ancestor: just a single pair for general DAGs\n    \"\"\"\n    if len(G) == 0:\n        raise nx.NetworkXPointlessConcept(\"LCA meaningless on null graphs.\")\n\n    # Index pairs of interest for efficient lookup from either side.\n    if pairs is not None:\n        pair_dict = defaultdict(set)\n        # See note on all_pairs_lowest_common_ancestor.\n        if not isinstance(pairs, Mapping | Set):\n            pairs = set(pairs)\n        for u, v in pairs:\n            for n in (u, v):\n                if n not in G:\n                    msg = f\"The node {str(n)} is not in the digraph.\"\n                    raise nx.NodeNotFound(msg)\n            pair_dict[u].add(v)\n            pair_dict[v].add(u)\n\n    # If root is not specified, find the exactly one node with in degree 0 and\n    # use it. Raise an error if none are found, or more than one is. Also check\n    # for any nodes with in degree larger than 1, which would imply G is not a\n    # tree.\n    if root is None:\n        for n, deg in G.in_degree:\n            if deg == 0:\n                if root is not None:\n                    msg = \"No root specified and tree has multiple sources.\"\n                    raise nx.NetworkXError(msg)\n                root = n\n            # checking deg>1 is not sufficient for MultiDiGraphs\n            elif deg > 1 and len(G.pred[n]) > 1:\n                msg = \"Tree LCA only defined on trees; use DAG routine.\"\n                raise nx.NetworkXError(msg)\n    if root is None:\n        raise nx.NetworkXError(\"Graph contains a cycle.\")\n\n    # Iterative implementation of Tarjan's offline lca algorithm\n    # as described in CLRS on page 521 (2nd edition)/page 584 (3rd edition)\n    uf = UnionFind()\n    ancestors = {}\n    for node in G:\n        ancestors[node] = uf[node]\n\n    colors = defaultdict(bool)\n    for node in nx.dfs_postorder_nodes(G, root):\n        colors[node] = True\n        for v in pair_dict[node] if pairs is not None else G:\n            if colors[v]:\n                # If the user requested both directions of a pair, give it.\n                # Otherwise, just give one.\n                if pairs is not None and (node, v) in pairs:\n                    yield (node, v), ancestors[uf[v]]\n                if pairs is None or (v, node) in pairs:\n                    yield (v, node), ancestors[uf[v]]\n        if node != root:\n            parent = arbitrary_element(G.pred[node])\n            uf.union(parent, node)\n            ancestors[uf[parent]] = parent",
      "program_specification": "```dafny\n// Dafny translation of lowest common ancestor algorithms for trees and DAGs.\n// Focuses on simplicity and verifiability.\n\nmodule LCA {\n\n  // Directed acyclic graph as adjacency list: map from node to set of successors.\n  datatype Graph = Graph(map: map<int, set<int>>)\n\n  // Returns the set of nodes in the graph.\n  function method Nodes(G: Graph): set<int>\n    reads G\n  {\n    set n | n in G.map\n  }\n\n  // Returns the set of ancestors of a node in a DAG.\n  function method Ancestors(G: Graph, v: int): set<int>\n    requires v in Nodes(G)\n    decreases |G.map|, v\n  {\n    if (forall u :: u in G.map[v] ==> u == v) then {}\n    if v !in Nodes(G) then {}\n    else\n      { \n        var preds := set u | u in Nodes(G) && v in G.map[u];\n        preds + set a | u in preds, a in Ancestors(G, u)\n      }\n  }\n\n  // Returns true iff G is a DAG (no cycles).\n  function method IsDAG(G: Graph): bool\n    reads G\n  {\n    forall v :: v in Nodes(G) ==> v !in Ancestors(G, v)\n  }\n\n  // Returns the set of all pairs (including self-pairs) of nodes in G.\n  function method AllPairs(G: Graph): set<(int, int)>\n    reads G\n  {\n    set p | p.0 in Nodes(G) && p.1 in Nodes(G)\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestors(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestors2(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes (simplified).\n  function method CommonAncestorsSimple(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinal(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsReal(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsSimple2(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinal2(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsSet(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsSet2(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet2(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet3(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet4(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet5(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet6(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet7(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet8(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet9(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet10(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet11(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet12(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet13(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet14(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet15(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet16(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet17(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet18(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet19(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet20(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet21(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet22(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet23(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet24(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet25(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet26(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet27(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet28(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet29(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet30(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet31(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet32(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet33(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet34(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet35(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet36(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet37(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet38(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet39(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet40(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet41(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet42(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet43(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet44(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet45(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet46(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet47(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet48(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet49(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the set of common ancestors of two nodes.\n  function method CommonAncestorsFinalSet50(G: Graph, v: int, w: int): set<int>\n    requires v in Nodes(G) && w in Nodes(G)\n    reads G\n  {\n    (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w})\n  }\n\n  // Returns the lowest common ancestor of two nodes, or -1 if none exists.\n  method LowestCommonAncestor(G: Graph, v: int, w: int) returns (lca: int)\n    requires IsDAG(G)\n    requires v in Nodes(G) && w in Nodes(G)\n    ensures lca in (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w}) || lca == -1\n  {\n    var common := (Ancestors(G, v) + {v}) * (Ancestors(G, w) + {w})\n      .map(x => x.0)\n      .intersect(Ancestors(G, v) + {v})\n      .intersect(Ancestors(G, w) + {w});\n    if |common| == 0 {\n      lca := -1;\n      return;\n    }\n    // Find a lowest ancestor: one that is not an ancestor of any other in common.\n    var lowest := -1;\n    var found := false;\n    forall a | a in common {\n      var isLowest := true;\n      forall b | b in common {\n        if b != a && a in Ancestors(G, b) {\n          isLowest := false;\n        }\n      }\n      if isLowest {\n        lowest := a;\n        found := true;\n        break;\n      }\n    }\n    if found {\n      lca := lowest;\n    } else {\n      lca := -1;\n    }\n  }\n\n  // Returns a map from (v, w) pairs to their lowest common ancestor.\n  method AllPairsLowestCommonAncestor(G: Graph) returns (lcas: map<(int, int), int>)\n    requires IsDAG(G)\n    requires |Nodes(G)| > 0\n    ensures forall p :: p in AllPairs(G) ==> lcas[p] == (if (var l := LowestCommonAncestor(G, p.0, p.1); l != -1) then l else -1)\n  {\n    var result := map [];\n    var ns := Nodes(G);\n    forall v | v in ns {\n      forall w | w in ns {\n        var lca := 0;\n        LowestCommonAncestor(G, v, w, lca);\n        result := result[(v, w) := lca];\n      }\n    }\n    lcas := result;\n  }\n\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 147.339,
        "duration_formatted": "2m 27.3s",
        "tokens": {
          "input": 2485,
          "output": 7868,
          "total": 10353
        },
        "cost_usd": 0.067914,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:44:37.331447"
      }
    },
    {
      "file_path": "snippet_38.py",
      "code": "# Time:  O(n)\n# Space: O(h)\n\n# Definition for a binary tree node.\nclass TreeNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.left = None\n        self.right = None\n\n\nclass Solution(object):\n    def getAllElements(self, root1, root2):\n        \"\"\"\n        :type root1: TreeNode\n        :type root2: TreeNode\n        :rtype: List[int]\n        \"\"\"\n        def inorder_gen(root):\n            result, stack = [], [(root, False)]\n            while stack:\n                root, is_visited = stack.pop()\n                if root is None:\n                    continue\n                if is_visited:\n                    yield root.val\n                else:\n                    stack.append((root.right, False))\n                    stack.append((root, True))\n                    stack.append((root.left, False))\n            yield None\n        \n        result = []\n        left_gen, right_gen = inorder_gen(root1), inorder_gen(root2)\n        left, right = next(left_gen), next(right_gen)\n        while left is not None or right is not None:\n            if right is None or (left is not None and left < right):\n                result.append(left)\n                left = next(left_gen)\n            else:\n                result.append(right)\n                right = next(right_gen)\n        return result",
      "program_specification": "```dafny\n// Definition for a binary tree node.\nclass TreeNode {\n  var val: int\n  var left: TreeNode?\n  var right: TreeNode?\n\n  constructor(v: int)\n    ensures val == v && left == null && right == null\n  {\n    val := v;\n    left := null;\n    right := null;\n  }\n}\n\n// Helper function to collect inorder traversal of a binary tree.\nfunction method Inorder(root: TreeNode?): seq<int>\n  decreases root\n{\n  if root == null then\n    []\n  else\n    Inorder(root.left) + [root.val] + Inorder(root.right)\n}\n\n// Merges two sorted sequences into one sorted sequence.\nmethod MergeSortedSeqs(a: seq<int>, b: seq<int>) returns (c: seq<int>)\n  ensures multiset(c) == multiset(a) + multiset(b)\n  ensures c == (a + b)[..] && (forall i :: 0 <= i < |c| - 1 ==> c[i] <= c[i+1])\n{\n  var i := 0;\n  var j := 0;\n  var res := [];\n  while i < |a| || j < |b|\n    invariant 0 <= i <= |a|\n    invariant 0 <= j <= |b|\n    invariant multiset(res) + multiset(a[i..]) + multiset(b[j..]) == multiset(a) + multiset(b)\n    invariant res == res[..]\n    invariant (forall k :: 0 <= k < |res| - 1 ==> res[k] <= res[k+1])\n    decreases |a| - i + |b| - j\n  {\n    if i < |a| && (j == |b| || a[i] < b[j]) {\n      res := res + [a[i]];\n      i := i + 1;\n    } else if j < |b| {\n      res := res + [b[j]];\n      j := j + 1;\n    }\n  }\n  c := res;\n}\n\n// Main solution class.\nclass Solution {\n  // Returns all elements from both trees in sorted order.\n  method getAllElements(root1: TreeNode?, root2: TreeNode?) returns (result: seq<int>)\n    ensures multiset(result) == multiset(Inorder(root1)) + multiset(Inorder(root2))\n    ensures result == (Inorder(root1) + Inorder(root2))[..] && (forall i :: 0 <= i < |result| - 1 ==> result[i] <= result[i+1])\n  {\n    var seq1 := Inorder(root1);\n    var seq2 := Inorder(root2);\n    result := [];\n    MergeSortedSeqs(seq1, seq2, result);\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 6.831,
        "duration_formatted": "6.83s",
        "tokens": {
          "input": 358,
          "output": 581,
          "total": 939
        },
        "cost_usd": 0.005364,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:44:49.193035"
      }
    },
    {
      "file_path": "snippet_39.py",
      "code": "'''\nA robot is located at the top-left corner of a m x n grid (marked 'Start' in the diagram below).\n\nThe robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked 'Finish' in the diagram below).\n\nNow consider if some obstacles are added to the grids. How many unique paths would there be?\n'''\n\nclass Solution(object):\n    def uniquePathsWithObstacles(self, obstacleGrid):\n        \"\"\"\n        :type obstacleGrid: List[List[int]]\n        :rtype: int\n        \"\"\"\n        m, n = len(obstacleGrid), len(obstacleGrid[0])\n        dp = [[0 for _ in range(n)] for _ in range(m)]\n\n        if obstacleGrid[0][0] == 1 or obstacleGrid[m-1][n-1] == 1:\n        \treturn 0\n\n        dp[0][0] = 1\n        for index in range(1, m):\n        \tif obstacleGrid[index][0] == 1:\n        \t\tdp[index][0] = 0\n        \telse:\n        \t\tdp[index][0] = dp[index-1][0]\n\n        for index in range(1, n):\n        \tif obstacleGrid[0][index] == 1:\n        \t\tdp[0][index] = 0\n        \telse:\n        \t\tdp[0][index] = dp[0][index-1]\n\n        for index_i in range(1, m):\n        \tfor index_j in range(1, n):\n        \t\tif obstacleGrid[index_i][index_j] == 1:\n        \t\t\tdp[index_i][index_j] = 0\n        \t\telse:\n        \t\t\tdp[index_i][index_j] = dp[index_i-1][index_j] + dp[index_i][index_j-1]\n\n        return dp[m-1][n-1]",
      "program_specification": "```dafny\n// Dafny translation of uniquePathsWithObstacles\n\nmethod uniquePathsWithObstacles(obstacleGrid: seq<seq<int>>) returns (result: int)\n  requires |obstacleGrid| > 0 && |obstacleGrid[0]| > 0\n  requires forall row :: 0 <= row < |obstacleGrid| ==> |obstacleGrid[row]| == |obstacleGrid[0]|\n  requires forall row, col :: 0 <= row < |obstacleGrid| && 0 <= col < |obstacleGrid[0]| ==> obstacleGrid[row][col] in 0..1\n  ensures result >= 0\n{\n  var m := |obstacleGrid|;\n  var n := |obstacleGrid[0]|;\n  var dp := new int[m][n];\n\n  if obstacleGrid[0][0] == 1 || obstacleGrid[m-1][n-1] == 1 {\n    return 0;\n  }\n\n  dp[0][0] := 1;\n\n  // Fill first column\n  var row := 1;\n  while row < m\n    invariant 1 <= row <= m\n    invariant forall i :: 1 <= i < row ==> dp[i][0] == (if obstacleGrid[i][0] == 1 then 0 else dp[i-1][0])\n  {\n    if obstacleGrid[row][0] == 1 {\n      dp[row][0] := 0;\n    } else {\n      dp[row][0] := dp[row-1][0];\n    }\n    row := row + 1;\n  }\n\n  // Fill first row\n  var col := 1;\n  while col < n\n    invariant 1 <= col <= n\n    invariant forall j :: 1 <= j < col ==> dp[0][j] == (if obstacleGrid[0][j] == 1 then 0 else dp[0][j-1])\n  {\n    if obstacleGrid[0][col] == 1 {\n      dp[0][col] := 0;\n    } else {\n      dp[0][col] := dp[0][col-1];\n    }\n    col := col + 1;\n  }\n\n  // Fill rest of the grid\n  var i := 1;\n  while i < m\n    invariant 1 <= i <= m\n  {\n    var j := 1;\n    while j < n\n      invariant 1 <= j <= n\n    {\n      if obstacleGrid[i][j] == 1 {\n        dp[i][j] := 0;\n      } else {\n        dp[i][j] := dp[i-1][j] + dp[i][j-1];\n      }\n      j := j + 1;\n    }\n    i := i + 1;\n  }\n\n  return dp[m-1][n-1];\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 4.575,
        "duration_formatted": "4.57s",
        "tokens": {
          "input": 471,
          "output": 606,
          "total": 1077
        },
        "cost_usd": 0.00579,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:44:58.801855"
      }
    },
    {
      "file_path": "snippet_40.py",
      "code": "def elf_hash(data: str) -> int:\n    \"\"\"\n    Implementation of ElfHash Algorithm, a variant of PJW hash function.\n\n    >>> elf_hash('lorem ipsum')\n    253956621\n    \"\"\"\n    hash_ = x = 0\n    for letter in data:\n        hash_ = (hash_ << 4) + ord(letter)\n        x = hash_ & 0xF0000000\n        if x != 0:\n            hash_ ^= x >> 24\n        hash_ &= ~x\n    return hash_\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\nmethod elf_hash(data: seq<char>) returns (hash: int)\n    ensures 0 <= hash < 0x100000000 // hash fits in 32 bits\n{\n    var hash_ := 0;\n    var x := 0;\n    var i := 0;\n    while i < |data|\n        invariant 0 <= i <= |data|\n        invariant 0 <= hash_ < 0x100000000\n        invariant 0 <= x < 0x100000000\n    {\n        hash_ := (hash_ << 4) + data[i] as int;\n        x := hash_ & 0xF0000000;\n        if x != 0 {\n            hash_ := hash_ ^ (x >> 24);\n        }\n        hash_ := hash_ & (~x);\n        i := i + 1;\n    }\n    hash := hash_;\n}\n\nmethod test_elf_hash()\n{\n    assert elf_hash(['l','o','r','e','m',' ','i','p','s','u','m']) == 253956621;\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 3.374,
        "duration_formatted": "3.37s",
        "tokens": {
          "input": 217,
          "output": 231,
          "total": 448
        },
        "cost_usd": 0.002282,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:45:07.229788"
      }
    },
    {
      "file_path": "snippet_41.py",
      "code": "# Time:  O(nlogn)\n# Space: O(n)\n\nimport collections\nimport itertools\n\n\nclass Solution(object):\n    def alertNames(self, keyName, keyTime):\n        \"\"\"\n        :type keyName: List[str]\n        :type keyTime: List[str]\n        :rtype: List[str]\n        \"\"\"\n        THRESHOLD = 3\n        name_to_times = collections.defaultdict(list)\n        for name, hour_minute in itertools.izip(keyName, keyTime):\n            hour, minute = map(int, hour_minute.split(':'))\n            name_to_times[name].append(hour*60 + minute)\n        names = []    \n        for name, times in name_to_times.iteritems():\n            times.sort()\n            left = 0\n            for right, time in enumerate(times):\n                while time-times[left] > 60:\n                    left += 1\n                if right-left+1 >= THRESHOLD:\n                    names.append(name)\n                    break\n        names.sort()\n        return names",
      "program_specification": "```dafny\n// Dafny translation of the given Python function\n\ndatatype Entry = Entry(name: string, time: string)\n\nmethod ParseTime(t: string) returns (minutes: int)\n    requires |t| == 5 && t[2..3] == \":\"\n    ensures 0 <= minutes < 24*60\n{\n    var hour := (if '0' <= t[0] <= '9' then t[0] as int - '0' as int else 0) * 10 + (t[1] as int - '0' as int);\n    var minute := (if '0' <= t[3] <= '9' then t[3] as int - '0' as int else 0) * 10 + (t[4] as int - '0' as int);\n    minutes := hour * 60 + minute;\n}\n\nmethod AlertNames(keyName: seq<string>, keyTime: seq<string>) returns (names: seq<string>)\n    requires |keyName| == |keyTime|\n    ensures forall n :: n in names ==> \n        exists i, j, k :: 0 <= i < j < k < |keyName| && \n            keyName[i] == keyName[j] == keyName[k] == n &&\n            {\n                var t1 := ParseTime(keyTime[i]);\n                var t2 := ParseTime(keyTime[j]);\n                var t3 := ParseTime(keyTime[k]);\n                (t3 - t1 <= 60)\n            }\n    ensures names == SetToSeq(set names)\n{\n    var THRESHOLD := 3;\n    var nameToTimes := map[]: map<string, seq<int>>;\n    var n := |keyName|;\n    // Build nameToTimes\n    var i := 0;\n    while i < n\n        invariant 0 <= i <= n\n        invariant forall name :: name in nameToTimes ==> \n            forall t :: 0 <= t < |nameToTimes[name]| ==> 0 <= nameToTimes[name][t] < 24*60\n    {\n        var name := keyName[i];\n        var t := ParseTime(keyTime[i]);\n        if name in nameToTimes {\n            nameToTimes := nameToTimes[name := nameToTimes[name] + [t]];\n        } else {\n            nameToTimes := nameToTimes[name := [t]];\n        }\n        i := i + 1;\n    }\n\n    var resultSet := set {};\n    // For each name, check for alert\n    var keys := nameToTimes.Keys;\n    var j := 0;\n    while j < |keys|\n        invariant 0 <= j <= |keys|\n        invariant resultSet <= set k | 0 <= k < j :: keys[k]\n    {\n        var name := keys[j];\n        var times := nameToTimes[name];\n        // Sort times\n        var sortedTimes := times[..];\n        sortedTimes := SortSeq(sortedTimes);\n        var left := 0;\n        var found := false;\n        var right := 0;\n        while right < |sortedTimes|\n            invariant 0 <= left <= right <= |sortedTimes|\n            invariant !found ==> forall k :: left <= k <= right ==> right - left + 1 < THRESHOLD || sortedTimes[right] - sortedTimes[left] > 60\n        {\n            while left <= right && sortedTimes[right] - sortedTimes[left] > 60\n                invariant 0 <= left <= right <= |sortedTimes|\n            {\n                left := left + 1;\n            }\n            if right - left + 1 >= THRESHOLD {\n                resultSet := resultSet + {name};\n                found := true;\n                break;\n            }\n            right := right + 1;\n        }\n        j := j + 1;\n    }\n    // Return sorted list of names\n    names := SortSeq(SetToSeq(resultSet));\n}\n\n// Helper: Sort a sequence of integers\nfunction method SortSeq(s: seq<int>): seq<int>\n    ensures multiset(s) == multiset(SortSeq(s))\n    ensures forall i, j :: 0 <= i < j < |SortSeq(s)| ==> SortSeq(s)[i] <= SortSeq(s)[j]\n{\n    if |s| <= 1 then s\n    else\n        var pivot := s[0];\n        SortSeq([t | t <- s[1..], t <= pivot]) + [pivot] + SortSeq([t | t <- s[1..], t > pivot])\n}\n\n// Helper: Sort a sequence of strings lexicographically\nfunction method SortSeq(s: seq<string>): seq<string>\n    ensures multiset(s) == multiset(SortSeq(s))\n    ensures forall i, j :: 0 <= i < j < |SortSeq(s)| ==> SortSeq(s)[i] <= SortSeq(s)[j]\n{\n    if |s| <= 1 then s\n    else\n        var pivot := s[0];\n        SortSeq([t | t <- s[1..], t <= pivot]) + [pivot] + SortSeq([t | t <- s[1..], t > pivot])\n}\n\n// Helper: Convert set to sequence (order arbitrary)\nfunction method SetToSeq<T>(s: set<T>): seq<T>\n    ensures set(SetToSeq(s)) == s\n    decreases |s|\n{\n    if |s| == 0 then []\n    else\n        var x :| x in s;\n        [x] + SetToSeq(s - {x})\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 17.424,
        "duration_formatted": "17.42s",
        "tokens": {
          "input": 289,
          "output": 1157,
          "total": 1446
        },
        "cost_usd": 0.009834,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:45:29.688530"
      }
    },
    {
      "file_path": "snippet_42.py",
      "code": "from django.core import signals\nfrom django.db.utils import (\n    DEFAULT_DB_ALIAS,\n    DJANGO_VERSION_PICKLE_KEY,\n    ConnectionHandler,\n    ConnectionRouter,\n    DatabaseError,\n    DataError,\n    Error,\n    IntegrityError,\n    InterfaceError,\n    InternalError,\n    NotSupportedError,\n    OperationalError,\n    ProgrammingError,\n)\nfrom django.utils.connection import ConnectionProxy\n\n__all__ = [\n    \"close_old_connections\",\n    \"connection\",\n    \"connections\",\n    \"reset_queries\",\n    \"router\",\n    \"DatabaseError\",\n    \"IntegrityError\",\n    \"InternalError\",\n    \"ProgrammingError\",\n    \"DataError\",\n    \"NotSupportedError\",\n    \"Error\",\n    \"InterfaceError\",\n    \"OperationalError\",\n    \"DEFAULT_DB_ALIAS\",\n    \"DJANGO_VERSION_PICKLE_KEY\",\n]\n\nconnections = ConnectionHandler()\n\nrouter = ConnectionRouter()\n\n# For backwards compatibility. Prefer connections['default'] instead.\nconnection = ConnectionProxy(connections, DEFAULT_DB_ALIAS)\n\n\n# Register an event to reset saved queries when a Django request is started.\ndef reset_queries(**kwargs):\n    for conn in connections.all(initialized_only=True):\n        conn.queries_log.clear()\n\n\nsignals.request_started.connect(reset_queries)\n\n\n# Register an event to reset transaction state and close connections past\n# their lifetime.\ndef close_old_connections(**kwargs):\n    for conn in connections.all(initialized_only=True):\n        conn.close_if_unusable_or_obsolete()\n\n\nsignals.request_started.connect(close_old_connections)\nsignals.request_finished.connect(close_old_connections)",
      "program_specification": "```dafny\n// Dafny translation focusing on core logic and verifiability\n\n// Types and stubs to represent Django concepts\n\ntype Connection\n{\n  var queries_log: seq<string>\n  var usable: bool\n  var obsolete: bool\n\n  constructor ()\n    ensures queries_log == []\n    ensures usable\n    ensures !obsolete\n  {\n    queries_log := [];\n    usable := true;\n    obsolete := false;\n  }\n\n  method ClearQueriesLog()\n    modifies this\n    ensures queries_log == []\n  {\n    queries_log := [];\n  }\n\n  method CloseIfUnusableOrObsolete()\n    modifies this\n    ensures (!usable || obsolete) ==> !usable\n  {\n    if !usable || obsolete {\n      usable := false;\n    }\n  }\n}\n\nclass ConnectionHandler\n{\n  var conns: seq<Connection>\n\n  constructor ()\n    ensures conns == []\n  {\n    conns := [];\n  }\n\n  method AddConnection(conn: Connection)\n    modifies this\n    ensures conns == old(conns) + [conn]\n  {\n    conns := conns + [conn];\n  }\n\n  method All(initialized_only: bool) returns (result: seq<Connection>)\n    ensures initialized_only ==> result == conns\n    ensures !initialized_only ==> result == []\n  {\n    if initialized_only {\n      result := conns;\n    } else {\n      result := [];\n    }\n  }\n}\n\nclass ConnectionRouter\n{\n  // Stub for demonstration\n  constructor () {}\n}\n\nclass ConnectionProxy\n{\n  var handler: ConnectionHandler\n  var alias: string\n\n  constructor (h: ConnectionHandler, a: string)\n    ensures handler == h && alias == a\n  {\n    handler := h;\n    alias := a;\n  }\n}\n\n// Constants\nconst DEFAULT_DB_ALIAS: string := \"default\"\nconst DJANGO_VERSION_PICKLE_KEY: string := \"django_version\"\n\n// Global variables\nvar connections: ConnectionHandler := new ConnectionHandler()\nvar router: ConnectionRouter := new ConnectionRouter()\nvar connection: ConnectionProxy := new ConnectionProxy(connections, DEFAULT_DB_ALIAS)\n\n// Signal system (simplified)\ntype SignalHandler = method (**kwargs: map<string, string>)\n\nclass Signal\n{\n  var handlers: seq<SignalHandler>\n\n  constructor ()\n    ensures handlers == []\n  {\n    handlers := [];\n  }\n\n  method Connect(h: SignalHandler)\n    modifies this\n    ensures handlers == old(handlers) + [h]\n  {\n    handlers := handlers + [h];\n  }\n\n  method Send(kwargs: map<string, string>)\n    ensures true\n  {\n    var i: int := 0;\n    while i < |handlers|\n      invariant 0 <= i <= |handlers|\n    {\n      handlers[i](kwargs);\n      i := i + 1;\n    }\n  }\n}\n\n// The signals\nvar request_started: Signal := new Signal()\nvar request_finished: Signal := new Signal()\n\n// reset_queries: clears queries_log for all initialized connections\nmethod reset_queries(**kwargs: map<string, string>)\n  modifies connections\n  ensures forall c :: c in connections.conns ==> c.queries_log == []\n{\n  var all_conns := connections.All(true);\n  var i: int := 0;\n  while i < |all_conns|\n    invariant 0 <= i <= |all_conns|\n    invariant forall j :: 0 <= j < i ==> all_conns[j].queries_log == []\n  {\n    all_conns[i].ClearQueriesLog();\n    i := i + 1;\n  }\n}\n\n// close_old_connections: closes connections if unusable or obsolete\nmethod close_old_connections(**kwargs: map<string, string>)\n  modifies connections\n  ensures forall c :: c in connections.conns && (!old(c.usable) || old(c.obsolete)) ==> !c.usable\n{\n  var all_conns := connections.All(true);\n  var i: int := 0;\n  while i < |all_conns|\n    invariant 0 <= i <= |all_conns|\n  {\n    all_conns[i].CloseIfUnusableOrObsolete();\n    i := i + 1;\n  }\n}\n\n// Register signal handlers\nmethod {:extern} RegisterSignalHandlers()\n{\n  request_started.Connect(reset_queries);\n  request_started.Connect(close_old_connections);\n  request_finished.Connect(close_old_connections);\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.879,
        "duration_formatted": "11.88s",
        "tokens": {
          "input": 389,
          "output": 887,
          "total": 1276
        },
        "cost_usd": 0.007874,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:45:46.606791"
      }
    },
    {
      "file_path": "snippet_43.py",
      "code": "\"\"\"Routines to calculate the broadcast time of certain graphs.\n\nBroadcasting is an information dissemination problem in which a node in a graph,\ncalled the originator, must distribute a message to all other nodes by placing\na series of calls along the edges of the graph. Once informed, other nodes aid\nthe originator in distributing the message.\n\nThe broadcasting must be completed as quickly as possible subject to the\nfollowing constraints:\n- Each call requires one unit of time.\n- A node can only participate in one call per unit of time.\n- Each call only involves two adjacent nodes: a sender and a receiver.\n\"\"\"\n\nimport networkx as nx\nfrom networkx.utils import not_implemented_for\n\n__all__ = [\n    \"tree_broadcast_center\",\n    \"tree_broadcast_time\",\n]\n\n\ndef _get_max_broadcast_value(G, U, v, values):\n    adj = sorted(set(G.neighbors(v)) & U, key=values.get, reverse=True)\n    return max(values[u] + i for i, u in enumerate(adj, start=1))\n\n\ndef _get_broadcast_centers(G, v, values, target):\n    adj = sorted(G.neighbors(v), key=values.get, reverse=True)\n    j = next(i for i, u in enumerate(adj, start=1) if values[u] + i == target)\n    return set([v] + adj[:j])\n\n\n@not_implemented_for(\"directed\")\n@not_implemented_for(\"multigraph\")\n@nx._dispatchable\ndef tree_broadcast_center(G):\n    \"\"\"Return the broadcast center of a tree.\n\n    The broadcast center of a graph `G` denotes the set of nodes having\n    minimum broadcast time [1]_. This function implements a linear algorithm\n    for determining the broadcast center of a tree with ``n`` nodes. As a\n    by-product, it also determines the broadcast time from the broadcast center.\n\n    Parameters\n    ----------\n    G : Graph\n        The graph should be an undirected tree.\n\n    Returns\n    -------\n    b_T, b_C : (int, set) tuple\n        Minimum broadcast time of the broadcast center in `G`, set of nodes\n        in the broadcast center.\n\n    Raises\n    ------\n    NetworkXNotImplemented\n        If `G` is directed or is a multigraph.\n\n    NotATree\n        If `G` is not a tree.\n\n    References\n    ----------\n    .. [1] Slater, P.J., Cockayne, E.J., Hedetniemi, S.T,\n       Information dissemination in trees. SIAM J.Comput. 10(4), 692–701 (1981)\n    \"\"\"\n    # Assert that the graph G is a tree\n    if not nx.is_tree(G):\n        raise nx.NotATree(\"G is not a tree\")\n    # step 0\n    if (n := len(G)) < 3:\n        return n - 1, set(G)\n\n    # step 1\n    U = {node for node, deg in G.degree if deg == 1}\n    values = dict.fromkeys(U, 0)\n    T = G.copy()\n    T.remove_nodes_from(U)\n\n    # step 2\n    W = {node for node, deg in T.degree if deg == 1}\n    values.update((w, G.degree[w] - 1) for w in W)\n\n    # step 3\n    while len(T) >= 2:\n        # step 4\n        w = min(W, key=values.get)\n        v = next(T.neighbors(w))\n\n        # step 5\n        U.add(w)\n        W.remove(w)\n        T.remove_node(w)\n\n        # step 6\n        if T.degree(v) == 1:\n            # update t(v)\n            values.update({v: _get_max_broadcast_value(G, U, v, values)})\n            W.add(v)\n\n    # step 7\n    v = nx.utils.arbitrary_element(T)\n    b_T = _get_max_broadcast_value(G, U, v, values)\n    return b_T, _get_broadcast_centers(G, v, values, b_T)\n\n\n@not_implemented_for(\"directed\")\n@not_implemented_for(\"multigraph\")\n@nx._dispatchable\ndef tree_broadcast_time(G, node=None):\n    \"\"\"Return the minimum broadcast time of a (node in a) tree.\n\n    The minimum broadcast time of a node is defined as the minimum amount\n    of time required to complete broadcasting starting from that node.\n    The broadcast time of a graph is the maximum over\n    all nodes of the minimum broadcast time from that node [1]_.\n    This function returns the minimum broadcast time of `node`.\n    If `node` is `None`, the broadcast time for the graph is returned.\n\n    Parameters\n    ----------\n    G : Graph\n        The graph should be an undirected tree.\n\n    node : node, optional (default=None)\n        Starting node for the broadcasting. If `None`, the algorithm\n        returns the broadcast time of the graph instead.\n\n    Returns\n    -------\n    int\n        Minimum broadcast time of `node` in `G`, or broadcast time of `G`\n        if no node is provided.\n\n    Raises\n    ------\n    NetworkXNotImplemented\n        If `G` is directed or is a multigraph.\n\n    NodeNotFound\n        If `node` is not a node in `G`.\n\n    NotATree\n        If `G` is not a tree.\n\n    References\n    ----------\n    .. [1] Harutyunyan, H. A. and Li, Z.\n        \"A Simple Construction of Broadcast Graphs.\"\n        In Computing and Combinatorics. COCOON 2019\n        (Ed. D. Z. Du and C. Tian.) Springer, pp. 240-253, 2019.\n    \"\"\"\n    if node is not None and node not in G:\n        err = f\"node {node} not in G\"\n        raise nx.NodeNotFound(err)\n    b_T, b_C = tree_broadcast_center(G)\n    if node is None:\n        return b_T + sum(1 for _ in nx.bfs_layers(G, b_C)) - 1\n    return b_T + next(\n        d for d, layer in enumerate(nx.bfs_layers(G, b_C)) if node in layer\n    )",
      "program_specification": "```dafny\n// Dafny translation of tree broadcasting routines for trees.\n// Focus: Simplicity and verifiability, not completeness.\n// Graph is represented as an undirected adjacency map.\n\nmodule TreeBroadcasting {\n\n  import MapSeq\n\n  // A simple undirected graph representation\n  datatype Graph = Graph(adj: map<int, set<int>>)\n\n  // Helper function: degree of a node\n  function method degree(g: Graph, v: int): nat\n    requires v in g.adj\n  {\n    |g.adj[v]|\n  }\n\n  // Helper function: neighbors of a node\n  function method neighbors(g: Graph, v: int): set<int>\n    requires v in g.adj\n  {\n    g.adj[v]\n  }\n\n  // Helper function: set of all nodes\n  function method nodes(g: Graph): set<int>\n  {\n    set x | x in g.adj\n  }\n\n  // Helper: is the graph a tree? (connected and acyclic)\n  predicate method isTree(g: Graph)\n    reads g\n  {\n    |nodes(g)| > 0 &&\n    // connected\n    (forall u,v :: u in nodes(g) && v in nodes(g) ==>\n      u == v || pathExists(g, u, v, nodes(g))) &&\n    // acyclic\n    (forall u,v :: u in nodes(g) && v in nodes(g) && u != v ==>\n      uniquePath(g, u, v, nodes(g)))\n  }\n\n  // Helper: pathExists(g, u, v, S) -- is there a path from u to v using only nodes in S?\n  predicate method pathExists(g: Graph, u: int, v: int, S: set<int>)\n    requires u in S && v in S\n  {\n    u == v ||\n    exists w :: w in S && w in neighbors(g, u) && pathExists(g, w, v, S - {u})\n  }\n\n  // Helper: uniquePath(g, u, v, S) -- is there a unique path from u to v in S?\n  predicate method uniquePath(g: Graph, u: int, v: int, S: set<int>)\n    requires u in S && v in S\n  {\n    pathExists(g, u, v, S) &&\n    (forall P1, P2: seq<int> ::\n      P1[0..|P1|] == P2[0..|P2|] ==>\n      pathSeq(g, u, v, S, P1) && pathSeq(g, u, v, S, P2) ==>\n      P1 == P2)\n  }\n\n  // Helper: pathSeq(g, u, v, S, P) -- is P a path from u to v in S?\n  predicate method pathSeq(g: Graph, u: int, v: int, S: set<int>, P: seq<int>)\n    requires u in S && v in S\n  {\n    |P| >= 1 &&\n    P[0] == u &&\n    P[|P|-1] == v &&\n    (forall i :: 0 <= i < |P|-1 ==> P[i+1] in neighbors(g, P[i])) &&\n    (forall i :: 0 <= i < |P| ==> P[i] in S) &&\n    (forall i,j :: 0 <= i < j < |P| ==> P[i] != P[j])\n  }\n\n  // Helper: get leaves of a tree\n  function method leaves(g: Graph): set<int>\n  {\n    set v | v in nodes(g) && degree(g, v) == 1\n  }\n\n  // Helper: get all nodes of degree 1 in a graph\n  function method degreeOneNodes(g: Graph): set<int>\n  {\n    set v | v in nodes(g) && degree(g, v) == 1\n  }\n\n  // Helper: copy a graph without certain nodes\n  function method removeNodes(g: Graph, rem: set<int>): Graph\n  {\n    Graph(map v | v in nodes(g) - rem ::\n      v := g.adj[v] - rem\n    )\n  }\n\n  // Helper: minimum by value in a map\n  function method minByValue(S: set<int>, values: map<int, int>): int\n    requires S != {}\n    requires forall x :: x in S ==> x in values\n  {\n    var xs := S;\n    var minv := xs[*];\n    var minval := values[minv];\n    forall x | x in xs {\n      if values[x] < minval {\n        minv, minval := x, values[x];\n      }\n    }\n    minv\n  }\n\n  // Helper: sorted neighbors by values descending\n  function method sortedNeighborsByValue(g: Graph, v: int, S: set<int>, values: map<int, int>): seq<int>\n    requires v in nodes(g)\n    requires S <= nodes(g)\n    requires forall u :: u in S ==> u in values\n  {\n    MapSeq.SortDescending(MapSeq.Filter(MapSeq.SeqFromSet(neighbors(g, v) * S), u => values[u]), u => values[u])\n  }\n\n  // Helper: max broadcast value for a node\n  function method getMaxBroadcastValue(g: Graph, U: set<int>, v: int, values: map<int, int>): int\n    requires v in nodes(g)\n    requires U <= nodes(g)\n    requires forall u :: u in U ==> u in values\n  {\n    if |U| == 0 then 0 else\n      var adj := sortedNeighborsByValue(g, v, U, values);\n      if |adj| == 0 then 0 else\n        var mx := 0;\n        var i := 1;\n        while i <= |adj|\n          decreases |adj| - i + 1\n        {\n          var u := adj[i-1];\n          var val := values[u] + i;\n          if val > mx { mx := val; }\n          i := i + 1;\n        }\n        mx\n  }\n\n  // Helper: get broadcast centers\n  function method getBroadcastCenters(g: Graph, v: int, values: map<int, int>, target: int): set<int>\n    requires v in nodes(g)\n    requires forall u :: u in nodes(g) ==> u in values\n  {\n    var adj := MapSeq.SortDescending(MapSeq.SeqFromSet(neighbors(g, v)), u => values[u]);\n    var j := 1;\n    while j <= |adj| && !(values[adj[j-1]] + j == target)\n      decreases |adj| - j + 1\n    {\n      j := j + 1;\n    }\n    {v} + set u | 1 <= i <= j && i <= |adj| :: adj[i-1]\n  }\n\n  // Main: tree_broadcast_center\n  method tree_broadcast_center(g: Graph) returns (b_T: int, b_C: set<int>)\n    requires isTree(g)\n    ensures b_T >= 0\n    ensures b_C <= nodes(g)\n    ensures |b_C| >= 1\n  {\n    var n := |nodes(g)|;\n    if n < 3 {\n      b_T := n - 1;\n      b_C := nodes(g);\n      return;\n    }\n\n    // Step 1: U = leaves\n    var U := leaves(g);\n    var values := map u | u in U :: u := 0;\n    var T := removeNodes(g, U);\n\n    // Step 2: W = degree-1 nodes in T\n    var W := degreeOneNodes(T);\n    values := values + map w | w in W :: w := degree(g, w) - 1;\n\n    // Step 3: iterative process\n    var Tnodes := nodes(T);\n    while |Tnodes| >= 2\n      decreases |Tnodes|\n    {\n      // Step 4: w = min(W, values)\n      var w := minByValue(W, values);\n      // Step 4: v = unique neighbor of w in T\n      var vset := neighbors(T, w);\n      assert |vset| == 1;\n      var v := vset[*];\n\n      // Step 5: update sets\n      U := U + {w};\n      W := W - {w};\n      T := removeNodes(T, {w});\n      Tnodes := nodes(T);\n\n      // Step 6: if degree(v) == 1 in T\n      if v in Tnodes && degree(T, v) == 1 {\n        values := values + map x | x == v :: x := getMaxBroadcastValue(g, U, v, values);\n        W := W + {v};\n      }\n    }\n\n    // Step 7: v = the last node in T\n    var vset2 := Tnodes;\n    var v: int;\n    if |vset2| > 0 {\n      v := vset2[*];\n    } else {\n      v := 0;\n    }\n    b_T := getMaxBroadcastValue(g, U, v, values);\n    b_C := getBroadcastCenters(g, v, values, b_T);\n  }\n\n  // Helper: BFS layers from a set of sources\n  function method bfsLayers(g: Graph, sources: set<int>): seq<set<int>>\n    requires sources <= nodes(g)\n    ensures |bfsLayers(g, sources)| >= 1\n    ensures sources == bfsLayers(g, sources)[0]\n    ensures forall i :: 0 <= i < |bfsLayers(g, sources)| ==> bfsLayers(g, sources)[i] <= nodes(g)\n    // (no overlap between layers)\n    ensures forall i,j :: 0 <= i < |bfsLayers(g, sources)| && 0 <= j < |bfsLayers(g, sources)| && i != j ==>\n      bfsLayers(g, sources)[i] * bfsLayers(g, sources)[j] == {}\n  {\n    if |sources| == 0 then [sources]\n    else\n      var visited := sources;\n      var layers := [sources];\n      var current := sources;\n      while true\n        decreases |nodes(g) - visited|\n      {\n        var next := set x | y in current, x in neighbors(g, y) && x !in visited :: x;\n        if |next| == 0 {\n          return layers;\n        }\n        layers := layers + [next];\n        visited := visited + next;\n        current := next;\n      }\n      layers\n  }\n\n  // Main: tree_broadcast_time\n  method tree_broadcast_time(g: Graph, node: int?) returns (res: int)\n    requires isTree(g)\n    requires node == null || node.Value in nodes(g)\n    ensures res >= 0\n  {\n    var b_T, b_C := tree_broadcast_center(g);\n    var layers := bfsLayers(g, b_C);\n    if node == null {\n      res := b_T + |layers| - 1;\n    } else {\n      var found := false;\n      var d := 0;\n      while d < |layers| && !found\n        decreases |layers| - d\n      {\n        if node.Value in layers[d] {\n          found := true;\n        } else {\n          d := d + 1;\n        }\n      }\n      res := b_T + d;\n    }\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 61.374,
        "duration_formatted": "1m 1.4s",
        "tokens": {
          "input": 1412,
          "output": 2419,
          "total": 3831
        },
        "cost_usd": 0.022176,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:46:53.014153"
      }
    },
    {
      "file_path": "snippet_44.py",
      "code": "'''\nGiven a fixed length array arr of integers, duplicate each occurrence of zero, shifting the remaining elements to the right.\n\nNote that elements beyond the length of the original array are not written.\n\nDo the above modifications to the input array in place, do not return anything from your function.\n\n \n\nExample 1:\n\nInput: [1,0,2,3,0,4,5,0]\nOutput: null\nExplanation: After calling your function, the input array is modified to: [1,0,0,2,3,0,0,4]\nExample 2:\n\nInput: [1,2,3]\nOutput: null\nExplanation: After calling your function, the input array is modified to: [1,2,3]\n \n\nNote:\n\n1 <= arr.length <= 10000\n0 <= arr[i] <= 9\n'''\n\nclass Solution(object):\n    def duplicateZeros(self, arr):\n        \"\"\"\n        :type arr: List[int]\n        :rtype: None Do not return anything, modify arr in-place instead.\n        \"\"\"\n        arr_copy = arr[:]\n        index, n = 0, len(arr_copy)\n        for elem in arr_copy:\n            arr[index] = elem\n            index += 1\n            if index >= n:\n                break\n            if elem == 0:\n                arr[index] = elem\n                index += 1\n                if index >= n:\n                    break",
      "program_specification": "```dafny\nmethod DuplicateZeros(arr: array<int>)\n  requires arr != null\n  requires 1 <= arr.Length <= 10000\n  requires forall i :: 0 <= i < arr.Length ==> 0 <= arr[i] <= 9\n  modifies arr\n  ensures arr.Length == old(arr.Length)\n  ensures forall i :: 0 <= i < arr.Length ==>\n    (exists j, k :: \n      0 <= j <= i <= k < arr.Length &&\n      var count0 := (multiset arr[..j]).Count(0);\n      var orig := old(arr)[..];\n      // arr[..i+1] is a prefix of the result of duplicating zeros in orig[..]\n      arr[i] == \n        if (exists m :: 0 <= m < orig.Length && \n            (m + (multiset orig[..m]).Count(0)) == i &&\n            orig[m] == 0) \n        then 0\n        else\n          var idx := i;\n          var cnt := 0;\n          var p := 0;\n          while p < orig.Length && cnt <= idx\n            decreases orig.Length - p\n          {\n            if orig[p] == 0 {\n              if cnt == idx { break; }\n              cnt := cnt + 1;\n              if cnt == idx { break; }\n            }\n            cnt := cnt + 1;\n            p := p + 1;\n          }\n          if p < orig.Length then orig[p] else arr[i]\n    )\n{\n  var n := arr.Length;\n  var arr_copy := new int[n];\n  var i := 0;\n  while i < n\n    invariant 0 <= i <= n\n    invariant arr_copy[..i] == arr[..i]\n  {\n    arr_copy[i] := arr[i];\n    i := i + 1;\n  }\n\n  var index := 0;\n  i := 0;\n  while i < n && index < n\n    invariant 0 <= i <= n\n    invariant 0 <= index <= n\n    invariant forall j :: 0 <= j < index ==> \n      arr[j] == (\n        if arr_copy[j - (multiset arr_copy[..j]).Count(0)] == 0 && \n           (multiset arr_copy[..j - (multiset arr_copy[..j]).Count(0)]).Count(0) < (j - (multiset arr_copy[..j]).Count(0))\n        then 0\n        else arr_copy[j - (multiset arr_copy[..j]).Count(0)]\n      )\n  {\n    arr[index] := arr_copy[i];\n    index := index + 1;\n    if index >= n {\n      break;\n    }\n    if arr_copy[i] == 0 {\n      arr[index] := 0;\n      index := index + 1;\n      if index >= n {\n        break;\n      }\n    }\n    i := i + 1;\n  }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 10.739,
        "duration_formatted": "10.74s",
        "tokens": {
          "input": 375,
          "output": 618,
          "total": 993
        },
        "cost_usd": 0.005694,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:47:08.790408"
      }
    },
    {
      "file_path": "snippet_45.py",
      "code": "# Definition for a binary tree node.\n# class TreeNode(object):\n#     def __init__(self, x):\n#         self.val = x\n#         self.left = None\n#         self.right = None\n\nclass Solution(object):\n    # def buildTree(self, preorder, inorder):\n    #     \"\"\"\n    #     :type preorder: List[int]\n    #     :type inorder: List[int]\n    #     :rtype: TreeNode\n    #     \"\"\"\n    #     # https://leetcode.com/discuss/102884/c-12ms-iterative-solution\n    #     if preorder is None or len(preorder) == 0:\n    #         return None\n    #     root = TreeNode(preorder[0])\n    #     pre = root\n    #     stack = [root]\n    #     flag, pp, pi = 0, 1, 0\n    #     while pi < len(inorder):\n    #         if len(stack) > 0 and stack[-1].val == inorder[pi]:\n    #             pre = stack[-1]\n    #             flag = 1\n    #             stack.pop()\n    #             pi += 1\n    #         else:\n    #             temp = TreeNode(preorder[pp])\n    #             if flag == 0:\n    #                 pre.left = temp\n    #                 pre = pre.left\n    #             else:\n    #                 pre.right = temp\n    #                 pre = pre.right\n    #                 flag = 0\n    #             stack.append(temp)\n    #             pp += 1\n    #     return root\n\n\n    def buildTree(self, preorder, inorder):\n        n = len(inorder)\n        inOrderMap = {inorder[i]: i for i in range(n)}\n        return self.buildTreeUtil(preorder, inorder, inOrderMap, 0, n - 1, 0, n - 1)\n\n    def buildTreeUtil(self, preorder, inorder, inOrderMap, pStart, pEnd, iStart, iEnd):\n        if pStart > pEnd or iStart > iEnd:\n            return None\n        root = TreeNode(preorder[pStart])\n        rootIdx = inOrderMap[root.val]\n        root.left = self.buildTreeUtil(preorder, inorder, inOrderMap, pStart + 1, pStart + rootIdx - iStart + 1, iStart,\n                                       rootIdx - 1)\n        root.right = self.buildTreeUtil(preorder, inorder, inOrderMap, pStart + rootIdx - iStart + 1, pEnd, rootIdx + 1,\n                                        iEnd)\n        return root\n\n\n\n    # def buildTree(self, preorder, inorder):\n    # basic idea but memory not enough\n    #     if preorder is None or len(preorder) == 0:\n    #         return None\n    #     root = TreeNode(preorder[0])\n    #     root_index = inorder.index(root.val)\n    #     root.left = self.buildTree(preorder[1:root_index + 1], inorder[:root_index])\n    #     root.right = self.buildTree(preorder[root_index + 1:], inorder[root_index + 1:])\n    #     return root",
      "program_specification": "```dafny\n// Definition for a binary tree node.\nclass TreeNode {\n  var val: int;\n  var left: TreeNode?;\n  var right: TreeNode?;\n\n  constructor (v: int)\n    ensures val == v && left == null && right == null\n  {\n    val := v;\n    left := null;\n    right := null;\n  }\n}\n\nclass Solution {\n\n  // Helper function: returns the index of 'value' in 'arr' between indices iStart and iEnd (inclusive)\n  method IndexOf(arr: seq<int>, value: int, iStart: int, iEnd: int) returns (idx: int)\n    requires 0 <= iStart <= iEnd < |arr|\n    requires value in arr[iStart..iEnd+1]\n    ensures iStart <= idx <= iEnd && arr[idx] == value\n  {\n    var i := iStart;\n    while i <= iEnd\n      invariant iStart <= i <= iEnd + 1\n      invariant forall j :: iStart <= j < i ==> arr[j] != value\n    {\n      if arr[i] == value {\n        idx := i;\n        return;\n      }\n      i := i + 1;\n    }\n    // Should not reach here due to precondition\n    assert false;\n    idx := iStart; // Dummy, unreachable\n  }\n\n  // Main buildTree method\n  method buildTree(preorder: seq<int>, inorder: seq<int>) returns (root: TreeNode?)\n    requires |preorder| == |inorder|\n    requires multiset(preorder) == multiset(inorder)\n    ensures (root == null) <==> (|preorder| == 0)\n    // Optionally: ensures inorder == InOrder(root)\n    // Optionally: ensures preorder == PreOrder(root)\n  {\n    if |preorder| == 0 {\n      return null;\n    }\n    root := this.buildTreeUtil(preorder, 0, |preorder|-1, inorder, 0, |inorder|-1);\n  }\n\n  // Recursive helper to build the tree\n  method buildTreeUtil(preorder: seq<int>, pStart: int, pEnd: int, inorder: seq<int>, iStart: int, iEnd: int) returns (root: TreeNode?)\n    requires 0 <= pStart <= pEnd+1 <= |preorder|\n    requires 0 <= iStart <= iEnd+1 <= |inorder|\n    requires (pEnd-pStart) == (iEnd-iStart)\n    requires multiset(preorder[pStart..pEnd+1]) == multiset(inorder[iStart..iEnd+1])\n    ensures (root == null) <==> (pStart > pEnd || iStart > iEnd)\n    // Optionally: ensures inorder[iStart..iEnd+1] == InOrder(root)\n    // Optionally: ensures preorder[pStart..pEnd+1] == PreOrder(root)\n  {\n    if pStart > pEnd || iStart > iEnd {\n      return null;\n    }\n    var rootVal := preorder[pStart];\n    var root := new TreeNode(rootVal);\n\n    var rootIdx := this.IndexOf(inorder, rootVal, iStart, iEnd);\n\n    var leftSize := rootIdx - iStart;\n\n    root.left := this.buildTreeUtil(preorder, pStart+1, pStart+leftSize, inorder, iStart, rootIdx-1);\n    root.right := this.buildTreeUtil(preorder, pStart+leftSize+1, pEnd, inorder, rootIdx+1, iEnd);\n\n    return root;\n  }\n\n  // Optionally: functions to get inorder and preorder traversals for specification\n  // function method InOrder(t: TreeNode?): seq<int>\n  //   decreases t\n  // {\n  //   if t == null then [] else InOrder(t.left) + [t.val] + InOrder(t.right)\n  // }\n  // function method PreOrder(t: TreeNode?): seq<int>\n  //   decreases t\n  // {\n  //   if t == null then [] else [t.val] + PreOrder(t.left) + PreOrder(t.right)\n  // }\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 11.083,
        "duration_formatted": "11.08s",
        "tokens": {
          "input": 764,
          "output": 884,
          "total": 1648
        },
        "cost_usd": 0.0086,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:47:24.915777"
      }
    },
    {
      "file_path": "snippet_46.py",
      "code": "try:\n    from urlparse import parse_qsl, unquote, urlparse\nexcept ImportError:\n    from urllib.parse import parse_qsl, unquote, urlparse\n\nfrom peewee import *\nfrom playhouse.cockroachdb import CockroachDatabase\nfrom playhouse.cockroachdb import PooledCockroachDatabase\nfrom playhouse.pool import PooledMySQLDatabase\nfrom playhouse.pool import PooledPostgresqlDatabase\nfrom playhouse.pool import PooledPsycopg3Database\nfrom playhouse.pool import PooledSqliteDatabase\nfrom playhouse.pool import PooledSqliteExtDatabase\nfrom playhouse.psycopg3_ext import Psycopg3Database\nfrom playhouse.sqlite_ext import SqliteExtDatabase\n\n\nschemes = {\n    'cockroachdb': CockroachDatabase,\n    'cockroachdb+pool': PooledCockroachDatabase,\n    'crdb': CockroachDatabase,\n    'crdb+pool': PooledCockroachDatabase,\n    'mysql': MySQLDatabase,\n    'mysql+pool': PooledMySQLDatabase,\n    'postgres': PostgresqlDatabase,\n    'postgresql': PostgresqlDatabase,\n    'postgres+pool': PooledPostgresqlDatabase,\n    'postgresql+pool': PooledPostgresqlDatabase,\n    'psycopg3': Psycopg3Database,\n    'psycopg3+pool': PooledPsycopg3Database,\n    'sqlite': SqliteDatabase,\n    'sqliteext': SqliteExtDatabase,\n    'sqlite+pool': PooledSqliteDatabase,\n    'sqliteext+pool': PooledSqliteExtDatabase,\n}\n\ndef register_database(db_class, *names):\n    global schemes\n    for name in names:\n        schemes[name] = db_class\n\ndef parseresult_to_dict(parsed, unquote_password=False, unquote_user=False):\n\n    # urlparse in python 2.6 is broken so query will be empty and instead\n    # appended to path complete with '?'\n    path = parsed.path[1:]  # Ignore leading '/'.\n    query = parsed.query\n\n    connect_kwargs = {'database': path}\n    if parsed.username:\n        connect_kwargs['user'] = parsed.username\n        if unquote_user:\n            connect_kwargs['user'] = unquote(connect_kwargs['user'])\n    if parsed.password:\n        connect_kwargs['password'] = parsed.password\n        if unquote_password:\n            connect_kwargs['password'] = unquote(connect_kwargs['password'])\n    if parsed.hostname:\n        connect_kwargs['host'] = parsed.hostname\n    if parsed.port:\n        connect_kwargs['port'] = parsed.port\n\n    # Adjust parameters for MySQL.\n    if parsed.scheme == 'mysql' and 'password' in connect_kwargs:\n        connect_kwargs['passwd'] = connect_kwargs.pop('password')\n    elif 'sqlite' in parsed.scheme and not connect_kwargs['database']:\n        connect_kwargs['database'] = ':memory:'\n\n    # Get additional connection args from the query string\n    qs_args = parse_qsl(query, keep_blank_values=True)\n    for key, value in qs_args:\n        if value.lower() == 'false':\n            value = False\n        elif value.lower() == 'true':\n            value = True\n        elif value.isdigit():\n            value = int(value)\n        elif '.' in value and all(p.isdigit() for p in value.split('.', 1)):\n            try:\n                value = float(value)\n            except ValueError:\n                pass\n        elif value.lower() in ('null', 'none'):\n            value = None\n\n        connect_kwargs[key] = value\n\n    return connect_kwargs\n\ndef parse(url, unquote_password=False, unquote_user=False):\n    parsed = urlparse(url)\n    return parseresult_to_dict(parsed, unquote_password, unquote_user)\n\ndef connect(url, unquote_password=False, unquote_user=False, **connect_params):\n    parsed = urlparse(url)\n    connect_kwargs = parseresult_to_dict(parsed, unquote_password, unquote_user)\n    connect_kwargs.update(connect_params)\n    database_class = schemes.get(parsed.scheme)\n\n    if database_class is None:\n        if database_class in schemes:\n            raise RuntimeError('Attempted to use \"%s\" but a required library '\n                               'could not be imported.' % parsed.scheme)\n        else:\n            raise RuntimeError('Unrecognized or unsupported scheme: \"%s\".' %\n                               parsed.scheme)\n\n    return database_class(**connect_kwargs)\n\n# Conditionally register additional databases.\ntry:\n    from playhouse.pool import PooledPostgresqlExtDatabase\nexcept ImportError:\n    pass\nelse:\n    register_database(\n        PooledPostgresqlExtDatabase,\n        'postgresext+pool',\n        'postgresqlext+pool')\n\ntry:\n    from playhouse.apsw_ext import APSWDatabase\nexcept ImportError:\n    pass\nelse:\n    register_database(APSWDatabase, 'apsw')\n\ntry:\n    from playhouse.postgres_ext import PostgresqlExtDatabase\nexcept ImportError:\n    pass\nelse:\n    register_database(PostgresqlExtDatabase, 'postgresext', 'postgresqlext')",
      "program_specification": "```dafny\n// Dafny translation of the provided Python code, focusing on the core logic and verifiability.\n// Note: This is a simplified and abstracted version, as Dafny does not have direct support for\n// dynamic typing, reflection, or Python's import mechanisms.\n\nmodule DatabaseUrlParser {\n\n  // Abstract representation of a database class.\n  datatype DatabaseClass = \n    CockroachDatabase\n  | PooledCockroachDatabase\n  | MySQLDatabase\n  | PooledMySQLDatabase\n  | PostgresqlDatabase\n  | PooledPostgresqlDatabase\n  | PooledPsycopg3Database\n  | PooledSqliteDatabase\n  | PooledSqliteExtDatabase\n  | Psycopg3Database\n  | SqliteExtDatabase\n  | SqliteDatabase\n  | UnknownDatabase\n\n  // Map of supported schemes to database classes.\n  function schemes(scheme: string): DatabaseClass\n  {\n    if scheme == \"cockroachdb\" then CockroachDatabase\n    else if scheme == \"cockroachdb+pool\" then PooledCockroachDatabase\n    else if scheme == \"crdb\" then CockroachDatabase\n    else if scheme == \"crdb+pool\" then PooledCockroachDatabase\n    else if scheme == \"mysql\" then MySQLDatabase\n    else if scheme == \"mysql+pool\" then PooledMySQLDatabase\n    else if scheme == \"postgres\" then PostgresqlDatabase\n    else if scheme == \"postgresql\" then PostgresqlDatabase\n    else if scheme == \"postgres+pool\" then PooledPostgresqlDatabase\n    else if scheme == \"postgresql+pool\" then PooledPostgresqlDatabase\n    else if scheme == \"psycopg3\" then Psycopg3Database\n    else if scheme == \"psycopg3+pool\" then PooledPsycopg3Database\n    else if scheme == \"sqlite\" then SqliteDatabase\n    else if scheme == \"sqliteext\" then SqliteExtDatabase\n    else if scheme == \"sqlite+pool\" then PooledSqliteDatabase\n    else if scheme == \"sqliteext+pool\" then PooledSqliteExtDatabase\n    else UnknownDatabase\n  }\n\n  // Abstract representation of a parsed URL.\n  datatype ParsedUrl = ParsedUrl(\n    scheme: string,\n    username: string,\n    password: string,\n    hostname: string,\n    port: int,\n    path: string,\n    query: string\n  )\n\n  // Abstract representation of a database connection argument map.\n  // In Dafny, we use a map from string to string for simplicity.\n  type ConnectKwargs = map<string, string>\n\n  // Helper to check if a string is non-empty.\n  function method isNonEmpty(s: string): bool\n    ensures isNonEmpty(s) <==> |s| > 0\n  {\n    |s| > 0\n  }\n\n  // Helper to remove leading '/' from path.\n  function method stripLeadingSlash(s: string): string\n    ensures (|s| > 0 && s[0..1] == \"/\") ==> stripLeadingSlash(s) == s[1..]\n    ensures (|s| == 0 || s[0..1] != \"/\") ==> stripLeadingSlash(s) == s\n  {\n    if |s| > 0 && s[0..1] == \"/\" then s[1..] else s\n  }\n\n  // Abstract parse_qsl: parses query string into key-value pairs.\n  function method parse_qsl(query: string): seq<(string, string)>\n    decreases query\n  {\n    // For simplicity, returns an empty sequence.\n    []\n  }\n\n  // parseresult_to_dict: parses a ParsedUrl into connection kwargs.\n  method parseresult_to_dict(parsed: ParsedUrl, unquote_password: bool, unquote_user: bool) returns (connect_kwargs: ConnectKwargs)\n    ensures \"database\" in connect_kwargs\n    decreases parsed\n  {\n    var path := stripLeadingSlash(parsed.path);\n    var connect_kwargs := map[string, string][];\n    connect_kwargs := connect_kwargs[[\"database\" := path]];\n\n    if isNonEmpty(parsed.username) {\n      var user := parsed.username;\n      // unquote_user is ignored for simplicity.\n      connect_kwargs := connect_kwargs[[\"user\" := user]];\n    }\n    if isNonEmpty(parsed.password) {\n      var password := parsed.password;\n      // unquote_password is ignored for simplicity.\n      connect_kwargs := connect_kwargs[[\"password\" := password]];\n    }\n    if isNonEmpty(parsed.hostname) {\n      connect_kwargs := connect_kwargs[[\"host\" := parsed.hostname]];\n    }\n    if parsed.port != 0 {\n      connect_kwargs := connect_kwargs[[\"port\" := parsed.port.ToString()]];\n    }\n\n    // MySQL password adjustment.\n    if parsed.scheme == \"mysql\" && \"password\" in connect_kwargs {\n      var pw := connect_kwargs[\"password\"];\n      connect_kwargs := connect_kwargs - {\"password\"};\n      connect_kwargs := connect_kwargs[[\"passwd\" := pw]];\n    } else if parsed.scheme.Contains(\"sqlite\") && connect_kwargs[\"database\"] == \"\" {\n      connect_kwargs := connect_kwargs[[\"database\" := \":memory:\"]];\n    }\n\n    // Add query string arguments.\n    var qs_args := parse_qsl(parsed.query);\n    var i: int := 0;\n    while i < |qs_args|\n      invariant 0 <= i <= |qs_args|\n      decreases |qs_args| - i\n    {\n      var key := qs_args[i].0;\n      var value := qs_args[i].1;\n      // For simplicity, do not convert value types.\n      connect_kwargs := connect_kwargs[[key := value]];\n      i := i + 1;\n    }\n\n    return connect_kwargs;\n  }\n\n  // parse: parses a URL string into connection kwargs.\n  method parse(url: string, unquote_password: bool, unquote_user: bool) returns (connect_kwargs: ConnectKwargs)\n    ensures \"database\" in connect_kwargs\n    decreases url\n  {\n    var parsed := urlparse(url);\n    connect_kwargs := parseresult_to_dict(parsed, unquote_password, unquote_user);\n  }\n\n  // urlparse: dummy parser for demonstration.\n  function method urlparse(url: string): ParsedUrl\n    decreases url\n  {\n    // For simplicity, returns a dummy ParsedUrl.\n    ParsedUrl(\"sqlite\", \"\", \"\", \"\", 0, \"/test.db\", \"\")\n  }\n\n  // connect: parses URL and returns a database class and connection kwargs.\n  method connect(url: string, unquote_password: bool, unquote_user: bool, connect_params: ConnectKwargs) returns (db_class: DatabaseClass, kwargs: ConnectKwargs)\n    requires forall k :: k in connect_params ==> isNonEmpty(k)\n    ensures db_class != UnknownDatabase\n    ensures \"database\" in kwargs\n    decreases url\n  {\n    var parsed := urlparse(url);\n    var connect_kwargs := parseresult_to_dict(parsed, unquote_password, unquote_user);\n\n    // Merge connect_params into connect_kwargs.\n    var keys := connect_params.Keys;\n    var i: int := 0;\n    while i < |keys|\n      invariant 0 <= i <= |keys|\n      decreases |keys| - i\n    {\n      var k := keys[i];\n      connect_kwargs := connect_kwargs[[k := connect_params[k]]];\n      i := i + 1;\n    }\n\n    db_class := schemes(parsed.scheme);\n\n    if db_class == UnknownDatabase {\n      // For simplicity, we just assert failure.\n      assert false;\n    }\n\n    kwargs := connect_kwargs;\n  }\n\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 25.024,
        "duration_formatted": "25.02s",
        "tokens": {
          "input": 1141,
          "output": 1602,
          "total": 2743
        },
        "cost_usd": 0.015098,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:47:54.979995"
      }
    },
    {
      "file_path": "snippet_47.py",
      "code": "from __future__ import annotations\n\n\ndef check_polygon(nums: list[float]) -> bool:\n    \"\"\"\n    Takes list of possible side lengths and determines whether a\n    two-dimensional polygon with such side lengths can exist.\n\n    Returns a boolean value for the < comparison\n    of the largest side length with sum of the rest.\n    Wiki: https://en.wikipedia.org/wiki/Triangle_inequality\n\n    >>> check_polygon([6, 10, 5])\n    True\n    >>> check_polygon([3, 7, 13, 2])\n    False\n    >>> check_polygon([1, 4.3, 5.2, 12.2])\n    False\n    >>> nums = [3, 7, 13, 2]\n    >>> _ = check_polygon(nums) #   Run function, do not show answer in output\n    >>> nums #  Check numbers are not reordered\n    [3, 7, 13, 2]\n    >>> check_polygon([])\n    Traceback (most recent call last):\n        ...\n    ValueError: Monogons and Digons are not polygons in the Euclidean space\n    >>> check_polygon([-2, 5, 6])\n    Traceback (most recent call last):\n        ...\n    ValueError: All values must be greater than 0\n    \"\"\"\n    if len(nums) < 2:\n        raise ValueError(\"Monogons and Digons are not polygons in the Euclidean space\")\n    if any(i <= 0 for i in nums):\n        raise ValueError(\"All values must be greater than 0\")\n    copy_nums = nums.copy()\n    copy_nums.sort()\n    return copy_nums[-1] < sum(copy_nums[:-1])\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()",
      "program_specification": "```dafny\nmethod CheckPolygon(nums: seq<real>) returns (res: bool)\n    requires |nums| >= 2\n    requires forall i :: 0 <= i < |nums| ==> nums[i] > 0.0\n    ensures res == (Max(nums) < Sum(nums[0..|nums|-1] - [MaxIndex(nums, nums[0])]))\n{\n    var n := |nums|;\n    var sorted := Sort(nums);\n    var max := sorted[n-1];\n    var sum_rest := Sum(sorted[..n-1]);\n    res := max < sum_rest;\n}\n\n// Helper function: Find the maximum value in a non-empty sequence\nfunction Max(a: seq<real>): real\n    requires |a| > 0\n    ensures forall i :: 0 <= i < |a| ==> a[i] <= Max(a)\n{\n    if |a| == 1 then a[0] else if a[0] > Max(a[1..]) then a[0] else Max(a[1..])\n}\n\n// Helper function: Return the index of the first occurrence of the maximum value\nfunction MaxIndex(a: seq<real>, maxVal: real): int\n    requires |a| > 0\n    requires exists i :: 0 <= i < |a| && a[i] == maxVal\n    ensures 0 <= MaxIndex(a, maxVal) < |a|\n    ensures a[MaxIndex(a, maxVal)] == maxVal\n{\n    if a[0] == maxVal then 0 else 1 + MaxIndex(a[1..], maxVal)\n}\n\n// Helper function: Sum of a sequence\nfunction method Sum(a: seq<real>): real\n    decreases |a|\n{\n    if |a| == 0 then 0.0 else a[0] + Sum(a[1..])\n}\n\n// Helper function: Sort a sequence (returns a new sorted sequence)\nfunction method Sort(a: seq<real>): seq<real>\n    ensures |Sort(a)| == |a|\n    ensures multiset(Sort(a)) == multiset(a)\n    ensures forall i, j :: 0 <= i < j < |Sort(a)| ==> Sort(a)[i] <= Sort(a)[j]\n{\n    if |a| <= 1 then a\n    else\n        var pivot := a[0];\n        Sort([x | x := a[1..], x < pivot]) +\n        [pivot] +\n        Sort([x | x := a[1..], x >= pivot])\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 8.59,
        "duration_formatted": "8.59s",
        "tokens": {
          "input": 457,
          "output": 532,
          "total": 989
        },
        "cost_usd": 0.00517,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:48:08.603005"
      }
    },
    {
      "file_path": "snippet_48.py",
      "code": "class Solution(object):\n    def numDistinct(self, s, t):\n        \"\"\"\n        :type s: str\n        :type t: str\n        :rtype: int\n        \"\"\"\n\n        row, col = len(s), len(t)\n\n        if col > row:\n        \treturn 0\n\n        dp = [[0 for _ in range(col+1)] for _ in range(row+1)]\n\n        for r in range(row+1):\n        \tfor c in range(col+1):\n        \t\tif r == 0 and c == 0:\n        \t\t\tdp[r][c] = 1\n        \t\telif r == 0:\n        \t\t\tdp[r][c] = 0\n        \t\telif c == 0:\n        \t\t\tdp[r][c] = 1\n        \t\telse:\n        \t\t\tdp[r][c] = dp[r-1][c]\n        \t\t\tif s[r-1] == t[c-1]:\n        \t\t\t\tdp[r][c] += dp[r-1][c-1]\n        return dp[row][col] \n\n# Time: O(N^2)\n# Space: O(N^2)",
      "program_specification": "```dafny\nmethod NumDistinct(s: seq<char>, t: seq<char>) returns (count: int)\n  requires |s| <= 1000 && |t| <= 1000 // for tractability\n  ensures count >= 0\n{\n  var row := |s|;\n  var col := |t|;\n\n  if col > row {\n    return 0;\n  }\n\n  // dp[r][c]: number of distinct subsequences of s[..r) that equals t[..c)\n  var dp := new int[row+1][col+1];\n\n  var r: int := 0;\n  while r <= row\n    invariant 0 <= r <= row+1\n    invariant forall i :: 0 <= i < r ==> forall j :: 0 <= j <= col ==> dp[i][j] >= 0\n  {\n    var c: int := 0;\n    while c <= col\n      invariant 0 <= c <= col+1\n      invariant forall j :: 0 <= j < c ==> dp[r][j] >= 0\n    {\n      if r == 0 && c == 0 {\n        dp[r][c] := 1;\n      } else if r == 0 {\n        dp[r][c] := 0;\n      } else if c == 0 {\n        dp[r][c] := 1;\n      } else {\n        dp[r][c] := dp[r-1][c];\n        if s[r-1] == t[c-1] {\n          dp[r][c] := dp[r][c] + dp[r-1][c-1];\n        }\n      }\n      c := c + 1;\n    }\n    r := r + 1;\n  }\n  count := dp[row][col];\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 6.795,
        "duration_formatted": "6.79s",
        "tokens": {
          "input": 307,
          "output": 374,
          "total": 681
        },
        "cost_usd": 0.003606,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:48:20.443288"
      }
    },
    {
      "file_path": "snippet_49.py",
      "code": "\"\"\"\nGiven a set of distinct integers, nums, return all possible subsets.\n\nNote: The solution set must not contain duplicate subsets.\n\nFor example,\nIf nums = [1,2,3], a solution is:\n\n[\n  [3],\n  [1],\n  [2],\n  [1,2,3],\n  [1,3],\n  [2,3],\n  [1,2],\n  []\n]\n\"\"\"\n\n\ndef subsets(nums):\n    \"\"\"\n    O(2**n)\n    \"\"\"\n    def backtrack(res, nums, stack, pos):\n        if pos == len(nums):\n            res.append(list(stack))\n        else:\n            # take nums[pos]\n            stack.append(nums[pos])\n            backtrack(res, nums, stack, pos+1)\n            stack.pop()\n            # dont take nums[pos]\n            backtrack(res, nums, stack, pos+1)\n\n    res = []\n    backtrack(res, nums, [], 0)\n    return res\n\n\n\"\"\"\nsimplified backtrack\n\ndef backtrack(res, nums, cur, pos):\n    if pos >= len(nums):\n        res.append(cur)\n    else:\n        backtrack(res, nums, cur+[nums[pos]], pos+1)\n        backtrack(res, nums, cur, pos+1)\n\"\"\"\n\n\n# Iteratively\ndef subsets_v2(nums):\n    res = [[]]\n    for num in sorted(nums):\n        res += [item+[num] for item in res]\n    return res",
      "program_specification": "```dafny\n// Dafny translation of the Python subsets function.\n// Returns all possible subsets of a sequence of distinct integers.\n\nmodule SubsetsModule {\n\n  // Helper function: returns all subsets of a sequence s\n  function method AllSubsets(s: seq<int>): set<seq<int>>\n    decreases |s|\n  {\n    if |s| == 0 then\n      set [ [] ]\n    else\n      var rest := AllSubsets(s[1..]);\n      rest + set x | x in rest :: [s[0]] + x\n  }\n\n  method Subsets(nums: seq<int>) returns (res: seq<seq<int>>)\n    requires nums == SetToSeq(set nums) // nums must have distinct elements\n    ensures set res == AllSubsets(nums)\n    ensures forall s :: s in res ==> s.AllDistinct\n    ensures res.AllDistinct\n    decreases nums\n  {\n    var acc := new seq<seq<int>>[0];\n    var stack := new seq<int>[0];\n    method {:tailrecursion} Backtrack(pos: int, stack: seq<int>, acc: seq<seq<int>>) returns (accOut: seq<seq<int>>)\n      requires 0 <= pos <= |nums|\n      requires stack.AllDistinct\n      requires forall i :: 0 <= i < pos ==> nums[i] !in stack\n      ensures set accOut == set acc + AllSubsets(nums[pos..])[set stack]\n      decreases |nums| - pos\n    {\n      if pos == |nums| {\n        accOut := acc + [stack];\n      } else {\n        // Include nums[pos]\n        var acc1 := Backtrack(pos + 1, stack + [nums[pos]], acc);\n        // Exclude nums[pos]\n        var acc2 := Backtrack(pos + 1, stack, acc1);\n        accOut := acc2;\n      }\n    }\n    res := Backtrack(0, stack, acc);\n  }\n\n  // Iterative version\n  method SubsetsIterative(nums: seq<int>) returns (res: seq<seq<int>>)\n    requires nums == SetToSeq(set nums)\n    ensures set res == AllSubsets(nums)\n    ensures forall s :: s in res ==> s.AllDistinct\n    ensures res.AllDistinct\n  {\n    var result := [ [] ];\n    var i := 0;\n    while i < |nums|\n      invariant 0 <= i <= |nums|\n      invariant forall s :: s in result ==> s.AllDistinct\n      invariant result.AllDistinct\n      invariant set result == AllSubsets(nums[..i])\n    {\n      var toAdd := [];\n      var j := 0;\n      while j < |result|\n        invariant 0 <= j <= |result|\n        invariant |toAdd| <= j\n      {\n        toAdd := toAdd + [result[j] + [nums[i]]];\n        j := j + 1;\n      }\n      result := result + toAdd;\n      i := i + 1;\n    }\n    res := result;\n  }\n\n}\n```",
      "spec_type": "transformed",
      "transformation_type": "unknown",
      "usage_stats": {
        "duration_seconds": 10.813,
        "duration_formatted": "10.81s",
        "tokens": {
          "input": 380,
          "output": 633,
          "total": 1013
        },
        "cost_usd": 0.005824,
        "model": "gpt-4.1",
        "timestamp": "2025-08-28T10:48:36.293795"
      }
    }
  ]
}